{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from itertools import repeat\n",
    "import data, data.gene_datasets\n",
    "import sklearn, sklearn.model_selection, sklearn.metrics, sklearn.linear_model, sklearn.neural_network, sklearn.tree\n",
    "import numpy as np\n",
    "import matplotlib, matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import gene_inference\n",
    "#from gene_inference.infer_genes import infer_all_genes, sample_neighbors\n",
    "import models, models.graphLayer\n",
    "from models.models import CGN\n",
    "import data, data.gene_datasets\n",
    "from data.graph import Graph\n",
    "from data.utils import split_dataset\n",
    "import optimization\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from analysis.metrics import record_metrics_for_epoch\n",
    "import analysis\n",
    "reload(analysis.metrics)\n",
    "reload(gene_inference);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting one-hot labels to integers\n"
     ]
    }
   ],
   "source": [
    "#tcgatissue = data.gene_datasets.TCGATissue(data_dir='./genomics/TCGA/', data_file='TCGA_tissue_ppi.hdf5')\n",
    "tcgatissue = data.gene_datasets.TCGATissue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "opt = Object()\n",
    "opt.seed = 0\n",
    "opt.nb_class = None\n",
    "opt.nb_examples = None\n",
    "opt.nb_nodes = None\n",
    "opt.graph = \"pathway\"\n",
    "opt.dataset = tcgatissue\n",
    "opt.add_self = True\n",
    "opt.norm_adj = True\n",
    "opt.add_connectivity = False\n",
    "opt.num_layer = 1\n",
    "opt.cuda = True\n",
    "opt.pool_graph = \"ignore\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "path = \"/data/lisa/data/genomics/graph/pancan-tissue-graph.hdf5\"\n",
    "graph.load_graph(path)\n",
    "#graph.intersection_with(tcgatissue)\n",
    "g = nx.from_numpy_matrix(graph.adj)\n",
    "mapping = dict(zip(range(0, len(tcgatissue.df.columns)), tcgatissue.df.columns))\n",
    "g = nx.relabel_nodes(g, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def sample_neighbors(g, gene, num_neighbors, include_self=True):\n",
    "#     results = set([])\n",
    "#     if include_self:\n",
    "#         results = set([gene])\n",
    "#     all_nodes = set(g.nodes)\n",
    "#     first_degree = set(g.neighbors(gene))\n",
    "#     second_degree = set()\n",
    "#     for x in g.neighbors(gene):\n",
    "#         second_degree = second_degree.union(set(g.neighbors(x)))\n",
    "#     while len(results) < num_neighbors:\n",
    "#         if len(first_degree) - len(results) > 0:\n",
    "#             unique = sorted(first_degree - results)\n",
    "#             results.add(unique.pop())\n",
    "#         elif len(second_degree) - len(results) > 0:\n",
    "#             unique = sorted(second_degree - results)\n",
    "#             results.add(unique.pop())\n",
    "#         else:\n",
    "#             unique = sorted(all_nodes - results)\n",
    "#             results.add(unique.pop())\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_neighbors(g, gene, num_neighbors, include_self=True):\n",
    "    results = set([])\n",
    "    if include_self:\n",
    "        results = set([gene])\n",
    "    all_nodes = set(g.nodes)\n",
    "    first_degree = set(g.neighbors(gene))\n",
    "    second_degree = set()\n",
    "    for x in g.neighbors(gene):\n",
    "        second_degree = second_degree.union(set(g.neighbors(x)))\n",
    "    while len(results) < num_neighbors:\n",
    "        if len(first_degree) - len(results) > 0:\n",
    "            unique = first_degree - results\n",
    "            results.add(np.random.choice(list(unique)))\n",
    "        elif len(second_degree) - len(results) > 0:\n",
    "            unique = second_degree - results\n",
    "            results.add(np.random.choice(list(unique)))\n",
    "        else:\n",
    "            unique = all_nodes - results\n",
    "            results.add(np.random.choice(list(unique)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sample_neighbors(g, \"RPL5\", 5, include_self=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn, sklearn.model_selection, sklearn.metrics, sklearn.linear_model, sklearn.neural_network, sklearn.tree\n",
    "import numpy as np\n",
    "\n",
    "class Method:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "class SkLearn(Method):\n",
    "    \n",
    "    def __init__(self, model, penalty=False):\n",
    "        self.model = model\n",
    "        self.penalty = penalty\n",
    "        \n",
    "    def loop(self, dataset, seed, train_size, test_size, adj=None):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(dataset.df, dataset.labels, stratify=dataset.labels, train_size=train_size, test_size=test_size, random_state=seed)\n",
    "\n",
    "        if self.model == \"LR\":\n",
    "            model = sklearn.linear_model.LogisticRegression()\n",
    "            if self.penalty:\n",
    "                model = sklearn.linear_model.LogisticRegression(penalty='l1', tol=0.0001)\n",
    "        elif self.model == \"DT\":\n",
    "            model = sklearn.tree.DecisionTreeClassifier()\n",
    "        elif self.model == \"MLP\":\n",
    "            model = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(32,3), learning_rate_init=0.001, early_stopping=False,  max_iter=1000)\n",
    "        else:\n",
    "            print \"incorrect label\"\n",
    "        \n",
    "        model = model.fit(X_train, y_train)\n",
    "        return sklearn.metrics.roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "\n",
    "class PyTorch(Method):    \n",
    "    \n",
    "    def __init__(self, model, num_epochs=100, num_channel=64, num_layer=3, add_emb=32, use_gate=False, dropout=True, cuda=True):\n",
    "        self.model = model\n",
    "        self.batch_size = 10\n",
    "        self.num_channel = num_channel\n",
    "        self.num_layer = num_layer\n",
    "        self.add_emb = add_emb\n",
    "        self.use_gate = use_gate\n",
    "        self.dropout = dropout\n",
    "        self.cuda = cuda\n",
    "        self.num_epochs = num_epochs\n",
    "        self.patience = 10\n",
    "        \n",
    "    def loop(self, dataset, seed, train_size, test_size, adj=None):\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(dataset.df, dataset.labels, stratify=dataset.labels, train_size=train_size, test_size=test_size, random_state=seed)\n",
    "    \n",
    "        #split train into valid and train\n",
    "        local_X_train, local_X_valid, local_y_train, local_y_valid = sklearn.model_selection.train_test_split(X_train, y_train, stratify=y_train, train_size=0.60, random_state=seed)\n",
    "        local_X_train = torch.FloatTensor(np.expand_dims(local_X_train, axis=2))\n",
    "        local_X_valid = torch.FloatTensor(np.expand_dims(local_X_valid, axis=2))\n",
    "        X_test = torch.FloatTensor(np.expand_dims(X_test, axis=2))\n",
    "        \n",
    "        local_y_train = torch.FloatTensor(local_y_train)\n",
    "\n",
    "        criterion = optimization.get_criterion(dataset)\n",
    "        patience = self.patience\n",
    "        opt.num_layer = self.num_layer\n",
    "        adj_transform, aggregate_function = models.graphLayer.get_transform(opt, adj)\n",
    "        \n",
    "        if self.model == \"CGN\":\n",
    "            model = models.models.CGN(\n",
    "                    nb_nodes=len(dataset.df.columns), \n",
    "                    input_dim=1,\n",
    "                    channels=[self.num_channel] * self.num_layer,\n",
    "                    adj=adj,\n",
    "                    out_dim=2,\n",
    "                    on_cuda=self.cuda,\n",
    "                    add_emb=self.add_emb,\n",
    "                    transform_adj=adj_transform,\n",
    "                    aggregate_adj=aggregate_function,\n",
    "                    use_gate=self.use_gate,\n",
    "                    dropout=self.dropout,\n",
    "                    )\n",
    "        elif self.model == \"MLP\":\n",
    "            model = models.models.MLP(\n",
    "                    len(dataset.df.columns), \n",
    "                    channels=[self.num_channel] * self.num_layer, \n",
    "                    out_dim=2, \n",
    "                    on_cuda=self.cuda, \n",
    "                    dropout=self.dropout)\n",
    "            \n",
    "        if self.cuda:\n",
    "            torch.cuda.manual_seed(seed)\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "            model.cuda()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "        max_valid = 0\n",
    "        max_valid_test = 0\n",
    "        for t in range(0, self.num_epochs):\n",
    "            start_timer = time.time()\n",
    "            \n",
    "            for base_x in range(0,local_X_train.shape[0], self.batch_size):\n",
    "                inputs, labels = local_X_train[base_x:base_x+self.batch_size], local_y_train[base_x:base_x+self.batch_size]\n",
    "\n",
    "                inputs = Variable(inputs, requires_grad=False).float()\n",
    "                if self.cuda:\n",
    "                    inputs = inputs.cuda()\n",
    "                    labels = labels.cuda()\n",
    "\n",
    "                model.train()\n",
    "                y_pred = model(inputs)\n",
    "\n",
    "                # Compute and print loss\n",
    "                crit_loss = optimization.compute_loss(criterion, y_pred, labels)\n",
    "                total_loss = crit_loss\n",
    "\n",
    "                # Zero gradients, perform a backward pass, and update the weights.\n",
    "                optimizer.zero_grad()\n",
    "                crit_loss.backward()\n",
    "                optimizer.step()\n",
    "                model.eval()\n",
    "\n",
    "            auc = {}\n",
    "            res = []\n",
    "            for base_x in range(0,local_X_train.shape[0], self.batch_size):\n",
    "                inputs = Variable(local_X_train[base_x:base_x+self.batch_size], requires_grad=False).float()\n",
    "                res.append(model(inputs.cuda())[:,1].data.cpu().numpy())\n",
    "            auc['train'] = sklearn.metrics.roc_auc_score(local_y_train.numpy(), np.asarray(res).flatten())\n",
    "            \n",
    "            res = []\n",
    "            for base_x in range(0,local_X_valid.shape[0], self.batch_size):\n",
    "                inputs = Variable(local_X_valid[base_x:base_x+self.batch_size], requires_grad=False).float()\n",
    "                res.append(model(inputs.cuda())[:,1].data.cpu().numpy())\n",
    "            auc['valid'] = sklearn.metrics.roc_auc_score(local_y_valid, np.asarray(res).flatten())\n",
    "            \n",
    "            res = []\n",
    "            for base_x in range(0,X_test.shape[0], self.batch_size):\n",
    "                inputs = Variable(X_test[base_x:base_x+self.batch_size], requires_grad=False).float()\n",
    "                res.append(model(inputs.cuda())[:,1].data.cpu().numpy())\n",
    "            auc['test'] = sklearn.metrics.roc_auc_score(y_test, np.asarray(res).flatten())\n",
    "            \n",
    "            \n",
    "            time_this_epoch = time.time() - start_timer\n",
    "\n",
    "#eval on cpu\n",
    "#             auc['train'] = sklearn.metrics.roc_auc_score(local_y_train.numpy(), model(Variable(local_X_train.cpu(), requires_grad=False).float())[:,1].cpu().data.numpy())\n",
    "#             auc['valid'] = sklearn.metrics.roc_auc_score(local_y_valid, model(Variable(local_X_valid.cpu(), requires_grad=False).float())[:,1].cpu().data.numpy())\n",
    "#             auc['test'] = sklearn.metrics.roc_auc_score(y_test, model(Variable(X_test.cpu(), requires_grad=False).float())[:,1].cpu().data.numpy())\n",
    "            \n",
    "            summary = [ t, crit_loss.data[0], auc['train'], auc['valid'], time_this_epoch ]\n",
    "            summary = \"epoch {}, cross_loss: {:.03f}, auc_train: {:0.3f}, auc_valid:{:0.3f}, time: {:.02f} sec\".format(*summary)\n",
    "            print summary\n",
    "\n",
    "            patience = patience - 1\n",
    "            if patience == 0:\n",
    "                return max_valid_test\n",
    "                break\n",
    "            if (max_valid < auc['valid']) and t > 5:\n",
    "                max_valid = auc['valid']\n",
    "                max_valid_test = auc['test']\n",
    "                patience = self.patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#             model = models.models.MLP(\n",
    "#                     20, \n",
    "#                     channels=[32] * 1,\n",
    "#                     out_dim=2, \n",
    "#                     on_cuda=True, \n",
    "#                     dropout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adj_transform, aggregate_function = models.graphLayer.get_transform(opt, nx.to_numpy_matrix(g))\n",
    "# model = models.models.CGN(\n",
    "#                     nb_nodes=len(tcgatissue.df.columns), \n",
    "#                     input_dim=1,\n",
    "#                     channels=[32] * 3,\n",
    "#                     adj=nx.to_numpy_matrix(g),\n",
    "#                     out_dim=2,\n",
    "#                     on_cuda=True,\n",
    "#                     add_emb=False,\n",
    "#                 transform_adj=adj_transform,\n",
    "#                     aggregate_adj=aggregate_function,\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tcgatissue.data[:10,:20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# torch.FloatTensor(tcgatissue.data[:10,:20])[0].view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# res = [model(Variable(x.view(1,1,-1), requires_grad=False)).cpu().data.numpy()[0][1] for x in torch.FloatTensor(tcgatissue.data[:10,:20])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model(Variable(tcgatissue.data, requires_grad=False).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#             model = models.models.CGN(\n",
    "#                     nb_nodes=len(tcgatissue.df.columns), \n",
    "#                     input_dim=1,\n",
    "#                     channels=[32] * 3,\n",
    "#                     adj=nx.to_numpy_matrix(g),\n",
    "#                     out_dim=2,\n",
    "#                     on_cuda=True,\n",
    "#                     add_emb=False,\n",
    "#                 transform_adj=None,\n",
    "#                     aggregate_adj=None,\n",
    "#                     )\n",
    "# model(Variable(local_X_train, requires_grad=False).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def method_comparison(results, dataset, models, gene, search_num_genes, trials, search_train_size, test_size):\n",
    "    \n",
    "    dataset = data.gene_datasets.TCGATissue()\n",
    "    dataset.df = dataset.df - dataset.df.mean()\n",
    "    \n",
    "    mean = dataset.df[gene].mean()\n",
    "    dataset.labels = [1 if x > mean else 0 for x in dataset.df[gene]]\n",
    "    full_df = dataset.df.copy(deep=True)\n",
    "    \n",
    "    #print \"Max ex \", int(np.log2(max_genes))+1\n",
    "    for train_size in search_train_size:\n",
    "        for ex in search_num_genes:#[16,24,32,48,64,128,256]:#range(4, int(np.log2(max_genes))+1):\n",
    "\n",
    "            num_genes = ex#2**ex\n",
    "            num_genes = np.min([num_genes, tcgatissue.df.shape[1]])\n",
    "            print ex, num_genes\n",
    "\n",
    "            neighbors = sample_neighbors(g, gene, num_genes, include_self=False)\n",
    "            print \"neighbors\", len(neighbors)\n",
    "\n",
    "            if gene in neighbors:\n",
    "                neighbors.remove(gene)\n",
    "\n",
    "            dataset.df = dataset.df[list(neighbors)]\n",
    "            dataset.data = dataset.df.as_matrix()\n",
    "\n",
    "            neighborhood = np.asarray(nx.to_numpy_matrix(nx.Graph(g.subgraph(neighbors))))\n",
    "\n",
    "            for model in models:\n",
    "                for seed in range(trials):\n",
    "\n",
    "                    #have we already done it?\n",
    "                    already_done = results[\"df\"][(results[\"df\"].gene_name == gene) & \n",
    "                                                 (results[\"df\"].model == model['key']) &\n",
    "                                                 (results[\"df\"].num_genes == num_genes) &\n",
    "                                                 (results[\"df\"].seed == seed) &\n",
    "                                                 (results[\"df\"].train_size == train_size)].shape[0] > 0\n",
    "\n",
    "                    if already_done:\n",
    "                        print \"already done:\", model['key'], num_genes, seed\n",
    "                        continue\n",
    "                    print \"doing:\", model['key'], num_genes, seed\n",
    "\n",
    "                    result = model['method'].loop(dataset=dataset, seed=seed, train_size=train_size, test_size=test_size, adj=neighborhood)\n",
    "\n",
    "                    experiment = {\"gene_name\": gene,\n",
    "                            \"model\": model['key'],\n",
    "                            \"num_genes\": num_genes, \n",
    "                            \"seed\":seed,\n",
    "                            \"train_size\": train_size,\n",
    "                            \"auc\":result\n",
    "                            }\n",
    "\n",
    "                    results[\"df\"] = results[\"df\"].append(experiment, ignore_index=True)\n",
    "                    pickle.dump(results, open(\"results-temp.pkl\", \"wb\"))\n",
    "            dataset.df = full_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "m = [\n",
    "#    {'key': 'LR-L1', 'method': SkLearn(\"LR\", penalty=True)},\n",
    "#    {'key': 'MLP', 'method': mlp},\n",
    "#    {'key': 'DT', 'method': SkLearn(\"DT\")},\n",
    "   {'key': 'CGN_3_layer_64_channel_emb_32_dropout', 'method': PyTorch(\"CGN\")},\n",
    "   {'key': 'MLP-dropout', 'method': PyTorch(\"MLP\", dropout=True)},\n",
    "#   {'key': 'MLP', 'method': PyTorch(\"MLP\", dropout=False)},\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = {\"df\": pd.DataFrame(columns=['auc','gene_name', 'model', 'num_genes', 'seed', 'train_size'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#results = pickle.load(open(\"results-temp.pkl\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting one-hot labels to integers\n",
      "100 100\n",
      "neighbors 100\n",
      "doing: CGN_3_layer_64_channel_emb_32_dropout 100 0\n",
      "Doing drop-out\n",
      "epoch 0, cross_loss: 0.725, auc_train: 0.925, auc_valid:0.800, time: 0.80 sec\n",
      "epoch 1, cross_loss: 0.753, auc_train: 0.956, auc_valid:0.852, time: 0.34 sec\n",
      "epoch 2, cross_loss: 0.707, auc_train: 0.959, auc_valid:0.858, time: 0.34 sec\n",
      "epoch 3, cross_loss: 0.672, auc_train: 0.953, auc_valid:0.848, time: 0.34 sec\n",
      "epoch 4, cross_loss: 0.668, auc_train: 0.954, auc_valid:0.847, time: 0.33 sec\n",
      "epoch 5, cross_loss: 0.664, auc_train: 0.954, auc_valid:0.847, time: 0.34 sec\n",
      "epoch 6, cross_loss: 0.648, auc_train: 0.950, auc_valid:0.840, time: 0.33 sec\n",
      "epoch 7, cross_loss: 0.613, auc_train: 0.949, auc_valid:0.837, time: 0.34 sec\n",
      "epoch 8, cross_loss: 0.522, auc_train: 0.949, auc_valid:0.835, time: 0.34 sec\n",
      "epoch 9, cross_loss: 0.462, auc_train: 0.950, auc_valid:0.837, time: 0.34 sec\n",
      "epoch 10, cross_loss: 0.299, auc_train: 0.952, auc_valid:0.840, time: 0.34 sec\n",
      "epoch 11, cross_loss: 0.240, auc_train: 0.952, auc_valid:0.837, time: 0.34 sec\n",
      "epoch 12, cross_loss: 0.201, auc_train: 0.951, auc_valid:0.842, time: 0.33 sec\n",
      "epoch 13, cross_loss: 0.255, auc_train: 0.960, auc_valid:0.847, time: 0.33 sec\n",
      "epoch 14, cross_loss: 0.189, auc_train: 0.961, auc_valid:0.847, time: 0.33 sec\n",
      "epoch 15, cross_loss: 0.140, auc_train: 0.966, auc_valid:0.847, time: 0.33 sec\n",
      "epoch 16, cross_loss: 0.154, auc_train: 0.969, auc_valid:0.845, time: 0.34 sec\n",
      "epoch 17, cross_loss: 0.202, auc_train: 0.976, auc_valid:0.850, time: 0.34 sec\n",
      "epoch 18, cross_loss: 0.115, auc_train: 0.979, auc_valid:0.860, time: 0.33 sec\n",
      "epoch 19, cross_loss: 0.173, auc_train: 0.982, auc_valid:0.860, time: 0.33 sec\n",
      "epoch 20, cross_loss: 0.065, auc_train: 0.988, auc_valid:0.860, time: 0.33 sec\n",
      "epoch 21, cross_loss: 0.112, auc_train: 0.989, auc_valid:0.857, time: 0.33 sec\n",
      "epoch 22, cross_loss: 0.021, auc_train: 0.991, auc_valid:0.865, time: 0.33 sec\n",
      "epoch 23, cross_loss: 0.067, auc_train: 0.993, auc_valid:0.850, time: 0.34 sec\n",
      "epoch 24, cross_loss: 0.042, auc_train: 0.993, auc_valid:0.855, time: 0.33 sec\n",
      "epoch 25, cross_loss: 0.354, auc_train: 0.997, auc_valid:0.845, time: 0.33 sec\n",
      "epoch 26, cross_loss: 0.035, auc_train: 0.998, auc_valid:0.828, time: 0.33 sec\n",
      "epoch 27, cross_loss: 0.163, auc_train: 1.000, auc_valid:0.820, time: 0.34 sec\n",
      "epoch 28, cross_loss: 0.057, auc_train: 1.000, auc_valid:0.812, time: 0.34 sec\n",
      "epoch 29, cross_loss: 0.247, auc_train: 1.000, auc_valid:0.818, time: 0.34 sec\n",
      "epoch 30, cross_loss: 0.021, auc_train: 1.000, auc_valid:0.820, time: 0.34 sec\n",
      "epoch 31, cross_loss: 0.091, auc_train: 1.000, auc_valid:0.828, time: 0.34 sec\n",
      "epoch 32, cross_loss: 0.025, auc_train: 1.000, auc_valid:0.843, time: 0.34 sec\n",
      "doing: CGN_3_layer_64_channel_emb_32_dropout 100 1\n",
      "Doing drop-out\n",
      "epoch 0, cross_loss: 0.750, auc_train: 0.932, auc_valid:0.948, time: 0.34 sec\n",
      "epoch 1, cross_loss: 0.626, auc_train: 0.951, auc_valid:0.970, time: 0.34 sec\n",
      "epoch 2, cross_loss: 0.659, auc_train: 0.951, auc_valid:0.972, time: 0.33 sec\n",
      "epoch 3, cross_loss: 0.706, auc_train: 0.953, auc_valid:0.955, time: 0.34 sec\n",
      "epoch 4, cross_loss: 0.693, auc_train: 0.953, auc_valid:0.955, time: 0.34 sec\n",
      "epoch 5, cross_loss: 0.652, auc_train: 0.954, auc_valid:0.953, time: 0.34 sec\n",
      "epoch 6, cross_loss: 0.604, auc_train: 0.954, auc_valid:0.955, time: 0.34 sec\n",
      "epoch 7, cross_loss: 0.571, auc_train: 0.954, auc_valid:0.955, time: 0.34 sec\n",
      "epoch 8, cross_loss: 0.498, auc_train: 0.953, auc_valid:0.955, time: 0.33 sec\n",
      "epoch 9, cross_loss: 0.470, auc_train: 0.952, auc_valid:0.960, time: 0.34 sec\n",
      "epoch 10, cross_loss: 0.470, auc_train: 0.953, auc_valid:0.958, time: 0.33 sec\n",
      "epoch 11, cross_loss: 0.478, auc_train: 0.956, auc_valid:0.960, time: 0.33 sec\n",
      "epoch 12, cross_loss: 0.505, auc_train: 0.957, auc_valid:0.963, time: 0.33 sec\n",
      "epoch 13, cross_loss: 0.521, auc_train: 0.967, auc_valid:0.958, time: 0.34 sec\n",
      "epoch 14, cross_loss: 0.521, auc_train: 0.972, auc_valid:0.950, time: 0.33 sec\n",
      "epoch 15, cross_loss: 0.264, auc_train: 0.974, auc_valid:0.953, time: 0.33 sec\n",
      "epoch 16, cross_loss: 0.554, auc_train: 0.973, auc_valid:0.953, time: 0.33 sec\n",
      "epoch 17, cross_loss: 0.598, auc_train: 0.974, auc_valid:0.950, time: 0.33 sec\n",
      "epoch 18, cross_loss: 0.418, auc_train: 0.979, auc_valid:0.948, time: 0.33 sec\n",
      "epoch 19, cross_loss: 0.378, auc_train: 0.982, auc_valid:0.948, time: 0.33 sec\n",
      "epoch 20, cross_loss: 0.680, auc_train: 0.986, auc_valid:0.948, time: 0.33 sec\n",
      "epoch 21, cross_loss: 0.301, auc_train: 0.988, auc_valid:0.940, time: 0.33 sec\n",
      "epoch 22, cross_loss: 0.315, auc_train: 0.989, auc_valid:0.933, time: 0.33 sec\n",
      "doing: CGN_3_layer_64_channel_emb_32_dropout 100 2\n",
      "Doing drop-out\n",
      "epoch 0, cross_loss: 0.695, auc_train: 0.907, auc_valid:0.807, time: 0.34 sec\n",
      "epoch 1, cross_loss: 0.689, auc_train: 0.944, auc_valid:0.870, time: 0.33 sec\n",
      "epoch 2, cross_loss: 0.691, auc_train: 0.952, auc_valid:0.905, time: 0.34 sec\n",
      "epoch 3, cross_loss: 0.687, auc_train: 0.957, auc_valid:0.917, time: 0.33 sec\n",
      "epoch 4, cross_loss: 0.686, auc_train: 0.959, auc_valid:0.927, time: 0.33 sec\n",
      "epoch 5, cross_loss: 0.642, auc_train: 0.960, auc_valid:0.938, time: 0.34 sec\n",
      "epoch 6, cross_loss: 0.641, auc_train: 0.963, auc_valid:0.938, time: 0.34 sec\n",
      "epoch 7, cross_loss: 0.582, auc_train: 0.966, auc_valid:0.938, time: 0.33 sec\n",
      "epoch 8, cross_loss: 0.521, auc_train: 0.966, auc_valid:0.943, time: 0.33 sec\n",
      "epoch 9, cross_loss: 0.416, auc_train: 0.964, auc_valid:0.945, time: 0.33 sec\n",
      "epoch 10, cross_loss: 0.338, auc_train: 0.963, auc_valid:0.948, time: 0.34 sec\n",
      "epoch 11, cross_loss: 0.241, auc_train: 0.968, auc_valid:0.948, time: 0.34 sec\n",
      "epoch 12, cross_loss: 0.155, auc_train: 0.970, auc_valid:0.950, time: 0.34 sec\n",
      "epoch 13, cross_loss: 0.064, auc_train: 0.974, auc_valid:0.953, time: 0.34 sec\n",
      "epoch 14, cross_loss: 0.063, auc_train: 0.978, auc_valid:0.955, time: 0.33 sec\n",
      "epoch 15, cross_loss: 0.116, auc_train: 0.980, auc_valid:0.953, time: 0.33 sec\n",
      "epoch 16, cross_loss: 0.076, auc_train: 0.986, auc_valid:0.953, time: 0.33 sec\n",
      "epoch 17, cross_loss: 0.036, auc_train: 0.991, auc_valid:0.953, time: 0.33 sec\n",
      "epoch 18, cross_loss: 0.033, auc_train: 0.994, auc_valid:0.953, time: 0.34 sec\n",
      "epoch 19, cross_loss: 0.077, auc_train: 0.997, auc_valid:0.953, time: 0.33 sec\n",
      "epoch 20, cross_loss: 0.028, auc_train: 0.998, auc_valid:0.948, time: 0.33 sec\n",
      "epoch 21, cross_loss: 0.201, auc_train: 0.999, auc_valid:0.948, time: 0.33 sec\n",
      "epoch 22, cross_loss: 0.113, auc_train: 1.000, auc_valid:0.947, time: 0.33 sec\n",
      "epoch 23, cross_loss: 0.039, auc_train: 1.000, auc_valid:0.948, time: 0.33 sec\n",
      "epoch 24, cross_loss: 0.039, auc_train: 1.000, auc_valid:0.950, time: 0.33 sec\n",
      "doing: CGN_3_layer_64_channel_emb_32_dropout 100 3\n",
      "Doing drop-out\n",
      "epoch 0, cross_loss: 0.730, auc_train: 0.874, auc_valid:0.658, time: 0.34 sec\n",
      "epoch 1, cross_loss: 0.680, auc_train: 0.892, auc_valid:0.690, time: 0.33 sec\n",
      "epoch 2, cross_loss: 0.709, auc_train: 0.891, auc_valid:0.735, time: 0.33 sec\n",
      "epoch 3, cross_loss: 0.639, auc_train: 0.903, auc_valid:0.755, time: 0.33 sec\n",
      "epoch 4, cross_loss: 0.648, auc_train: 0.913, auc_valid:0.770, time: 0.33 sec\n",
      "epoch 5, cross_loss: 0.704, auc_train: 0.924, auc_valid:0.818, time: 0.33 sec\n",
      "epoch 6, cross_loss: 0.562, auc_train: 0.939, auc_valid:0.837, time: 0.34 sec\n",
      "epoch 7, cross_loss: 0.491, auc_train: 0.947, auc_valid:0.880, time: 0.33 sec\n",
      "epoch 8, cross_loss: 0.469, auc_train: 0.952, auc_valid:0.903, time: 0.33 sec\n",
      "epoch 9, cross_loss: 0.404, auc_train: 0.949, auc_valid:0.912, time: 0.34 sec\n",
      "epoch 10, cross_loss: 0.326, auc_train: 0.960, auc_valid:0.915, time: 0.34 sec\n",
      "epoch 11, cross_loss: 0.341, auc_train: 0.970, auc_valid:0.912, time: 0.33 sec\n",
      "epoch 12, cross_loss: 0.457, auc_train: 0.978, auc_valid:0.922, time: 0.34 sec\n",
      "epoch 13, cross_loss: 0.572, auc_train: 0.986, auc_valid:0.938, time: 0.33 sec\n",
      "epoch 14, cross_loss: 0.399, auc_train: 0.992, auc_valid:0.945, time: 0.34 sec\n",
      "epoch 15, cross_loss: 0.209, auc_train: 0.997, auc_valid:0.945, time: 0.34 sec\n",
      "epoch 16, cross_loss: 0.138, auc_train: 1.000, auc_valid:0.940, time: 0.34 sec\n",
      "epoch 17, cross_loss: 0.238, auc_train: 1.000, auc_valid:0.945, time: 0.34 sec\n",
      "epoch 18, cross_loss: 0.065, auc_train: 1.000, auc_valid:0.950, time: 0.33 sec\n",
      "epoch 19, cross_loss: 0.251, auc_train: 1.000, auc_valid:0.948, time: 0.33 sec\n",
      "epoch 20, cross_loss: 0.071, auc_train: 1.000, auc_valid:0.950, time: 0.33 sec\n",
      "epoch 21, cross_loss: 0.174, auc_train: 1.000, auc_valid:0.950, time: 0.33 sec\n",
      "epoch 22, cross_loss: 0.101, auc_train: 1.000, auc_valid:0.957, time: 0.33 sec\n",
      "epoch 23, cross_loss: 0.164, auc_train: 1.000, auc_valid:0.952, time: 0.33 sec\n",
      "epoch 24, cross_loss: 0.045, auc_train: 1.000, auc_valid:0.960, time: 0.33 sec\n",
      "epoch 25, cross_loss: 0.040, auc_train: 1.000, auc_valid:0.968, time: 0.34 sec\n",
      "epoch 26, cross_loss: 0.106, auc_train: 1.000, auc_valid:0.963, time: 0.33 sec\n",
      "epoch 27, cross_loss: 0.099, auc_train: 1.000, auc_valid:0.960, time: 0.33 sec\n",
      "epoch 28, cross_loss: 0.023, auc_train: 1.000, auc_valid:0.965, time: 0.33 sec\n",
      "epoch 29, cross_loss: 0.167, auc_train: 1.000, auc_valid:0.963, time: 0.33 sec\n",
      "epoch 30, cross_loss: 0.004, auc_train: 1.000, auc_valid:0.963, time: 0.34 sec\n",
      "epoch 31, cross_loss: 0.015, auc_train: 1.000, auc_valid:0.963, time: 0.33 sec\n",
      "epoch 32, cross_loss: 0.018, auc_train: 1.000, auc_valid:0.960, time: 0.33 sec\n",
      "epoch 33, cross_loss: 0.012, auc_train: 1.000, auc_valid:0.960, time: 0.33 sec\n",
      "epoch 34, cross_loss: 0.044, auc_train: 1.000, auc_valid:0.960, time: 0.33 sec\n",
      "epoch 35, cross_loss: 0.013, auc_train: 1.000, auc_valid:0.960, time: 0.33 sec\n",
      "doing: CGN_3_layer_64_channel_emb_32_dropout 100 4\n",
      "Doing drop-out\n",
      "epoch 0, cross_loss: 0.784, auc_train: 0.693, auc_valid:0.660, time: 0.34 sec\n",
      "epoch 1, cross_loss: 0.661, auc_train: 0.770, auc_valid:0.725, time: 0.33 sec\n",
      "epoch 2, cross_loss: 0.675, auc_train: 0.825, auc_valid:0.802, time: 0.33 sec\n",
      "epoch 3, cross_loss: 0.679, auc_train: 0.863, auc_valid:0.840, time: 0.34 sec\n",
      "epoch 4, cross_loss: 0.682, auc_train: 0.883, auc_valid:0.873, time: 0.34 sec\n",
      "epoch 5, cross_loss: 0.666, auc_train: 0.897, auc_valid:0.892, time: 0.33 sec\n",
      "epoch 6, cross_loss: 0.644, auc_train: 0.910, auc_valid:0.890, time: 0.33 sec\n",
      "epoch 7, cross_loss: 0.611, auc_train: 0.918, auc_valid:0.900, time: 0.33 sec\n",
      "epoch 8, cross_loss: 0.510, auc_train: 0.917, auc_valid:0.900, time: 0.34 sec\n",
      "epoch 9, cross_loss: 0.406, auc_train: 0.921, auc_valid:0.905, time: 0.34 sec\n",
      "epoch 10, cross_loss: 0.354, auc_train: 0.922, auc_valid:0.905, time: 0.33 sec\n",
      "epoch 11, cross_loss: 0.381, auc_train: 0.924, auc_valid:0.905, time: 0.34 sec\n",
      "epoch 12, cross_loss: 0.409, auc_train: 0.935, auc_valid:0.902, time: 0.33 sec\n",
      "epoch 13, cross_loss: 0.183, auc_train: 0.952, auc_valid:0.910, time: 0.33 sec\n",
      "epoch 14, cross_loss: 0.233, auc_train: 0.963, auc_valid:0.915, time: 0.33 sec\n",
      "epoch 15, cross_loss: 0.148, auc_train: 0.972, auc_valid:0.917, time: 0.33 sec\n",
      "epoch 16, cross_loss: 0.131, auc_train: 0.981, auc_valid:0.922, time: 0.33 sec\n",
      "epoch 17, cross_loss: 0.190, auc_train: 0.983, auc_valid:0.927, time: 0.33 sec\n",
      "epoch 18, cross_loss: 0.084, auc_train: 0.988, auc_valid:0.932, time: 0.33 sec\n",
      "epoch 19, cross_loss: 0.103, auc_train: 0.990, auc_valid:0.935, time: 0.33 sec\n",
      "epoch 20, cross_loss: 0.168, auc_train: 0.993, auc_valid:0.935, time: 0.33 sec\n",
      "epoch 21, cross_loss: 0.117, auc_train: 0.994, auc_valid:0.932, time: 0.33 sec\n",
      "epoch 22, cross_loss: 0.222, auc_train: 0.999, auc_valid:0.932, time: 0.33 sec\n",
      "epoch 23, cross_loss: 0.074, auc_train: 1.000, auc_valid:0.938, time: 0.33 sec\n",
      "epoch 24, cross_loss: 0.111, auc_train: 1.000, auc_valid:0.935, time: 0.33 sec\n",
      "epoch 25, cross_loss: 0.056, auc_train: 1.000, auc_valid:0.940, time: 0.33 sec\n",
      "epoch 26, cross_loss: 0.104, auc_train: 1.000, auc_valid:0.948, time: 0.33 sec\n",
      "epoch 27, cross_loss: 0.044, auc_train: 1.000, auc_valid:0.948, time: 0.33 sec\n",
      "epoch 28, cross_loss: 0.089, auc_train: 1.000, auc_valid:0.948, time: 0.33 sec\n",
      "epoch 29, cross_loss: 0.048, auc_train: 1.000, auc_valid:0.948, time: 0.33 sec\n",
      "epoch 30, cross_loss: 0.049, auc_train: 1.000, auc_valid:0.953, time: 0.33 sec\n",
      "epoch 31, cross_loss: 0.008, auc_train: 1.000, auc_valid:0.958, time: 0.33 sec\n",
      "epoch 32, cross_loss: 0.055, auc_train: 1.000, auc_valid:0.955, time: 0.33 sec\n",
      "epoch 33, cross_loss: 0.024, auc_train: 1.000, auc_valid:0.953, time: 0.34 sec\n",
      "epoch 34, cross_loss: 0.034, auc_train: 1.000, auc_valid:0.948, time: 0.34 sec\n",
      "epoch 35, cross_loss: 0.044, auc_train: 1.000, auc_valid:0.948, time: 0.33 sec\n",
      "epoch 36, cross_loss: 0.096, auc_train: 1.000, auc_valid:0.948, time: 0.33 sec\n",
      "epoch 37, cross_loss: 0.037, auc_train: 1.000, auc_valid:0.953, time: 0.33 sec\n",
      "epoch 38, cross_loss: 0.122, auc_train: 1.000, auc_valid:0.953, time: 0.34 sec\n",
      "epoch 39, cross_loss: 0.022, auc_train: 1.000, auc_valid:0.958, time: 0.34 sec\n",
      "epoch 40, cross_loss: 0.016, auc_train: 1.000, auc_valid:0.960, time: 0.34 sec\n",
      "epoch 41, cross_loss: 0.004, auc_train: 1.000, auc_valid:0.963, time: 0.34 sec\n",
      "epoch 42, cross_loss: 0.027, auc_train: 1.000, auc_valid:0.963, time: 0.33 sec\n",
      "epoch 43, cross_loss: 0.062, auc_train: 1.000, auc_valid:0.958, time: 0.33 sec\n",
      "epoch 44, cross_loss: 0.006, auc_train: 1.000, auc_valid:0.963, time: 0.33 sec\n",
      "epoch 45, cross_loss: 0.004, auc_train: 1.000, auc_valid:0.963, time: 0.33 sec\n",
      "epoch 46, cross_loss: 0.308, auc_train: 1.000, auc_valid:0.958, time: 0.33 sec\n",
      "epoch 47, cross_loss: 0.054, auc_train: 1.000, auc_valid:0.960, time: 0.33 sec\n",
      "epoch 48, cross_loss: 0.029, auc_train: 1.000, auc_valid:0.958, time: 0.33 sec\n",
      "epoch 49, cross_loss: 0.049, auc_train: 1.000, auc_valid:0.958, time: 0.33 sec\n",
      "epoch 50, cross_loss: 0.002, auc_train: 1.000, auc_valid:0.958, time: 0.33 sec\n",
      "epoch 51, cross_loss: 0.008, auc_train: 1.000, auc_valid:0.958, time: 0.33 sec\n",
      "doing: MLP-dropout 100 0\n",
      "Doing Drop-out\n",
      "epoch 0, cross_loss: 0.617, auc_train: 0.694, auc_valid:0.367, time: 0.12 sec\n",
      "epoch 1, cross_loss: 0.657, auc_train: 0.881, auc_valid:0.495, time: 0.11 sec\n",
      "epoch 2, cross_loss: 0.657, auc_train: 0.950, auc_valid:0.613, time: 0.11 sec\n",
      "epoch 3, cross_loss: 0.642, auc_train: 0.964, auc_valid:0.650, time: 0.11 sec\n",
      "epoch 4, cross_loss: 0.642, auc_train: 0.969, auc_valid:0.700, time: 0.12 sec\n",
      "epoch 5, cross_loss: 0.557, auc_train: 0.968, auc_valid:0.728, time: 0.11 sec\n",
      "epoch 6, cross_loss: 0.516, auc_train: 0.968, auc_valid:0.755, time: 0.11 sec\n",
      "epoch 7, cross_loss: 0.535, auc_train: 0.966, auc_valid:0.773, time: 0.11 sec\n",
      "epoch 8, cross_loss: 0.524, auc_train: 0.967, auc_valid:0.777, time: 0.11 sec\n",
      "epoch 9, cross_loss: 0.501, auc_train: 0.969, auc_valid:0.790, time: 0.11 sec\n",
      "epoch 10, cross_loss: 0.390, auc_train: 0.970, auc_valid:0.795, time: 0.11 sec\n",
      "epoch 11, cross_loss: 0.328, auc_train: 0.971, auc_valid:0.797, time: 0.11 sec\n",
      "epoch 12, cross_loss: 0.323, auc_train: 0.972, auc_valid:0.800, time: 0.11 sec\n",
      "epoch 13, cross_loss: 0.316, auc_train: 0.977, auc_valid:0.805, time: 0.11 sec\n",
      "epoch 14, cross_loss: 0.287, auc_train: 0.979, auc_valid:0.812, time: 0.11 sec\n",
      "epoch 15, cross_loss: 0.196, auc_train: 0.983, auc_valid:0.820, time: 0.11 sec\n",
      "epoch 16, cross_loss: 0.318, auc_train: 0.988, auc_valid:0.825, time: 0.11 sec\n",
      "epoch 17, cross_loss: 0.109, auc_train: 0.992, auc_valid:0.833, time: 0.11 sec\n",
      "epoch 18, cross_loss: 0.207, auc_train: 0.996, auc_valid:0.838, time: 0.11 sec\n",
      "epoch 19, cross_loss: 0.156, auc_train: 0.996, auc_valid:0.840, time: 0.11 sec\n",
      "epoch 20, cross_loss: 0.085, auc_train: 0.997, auc_valid:0.845, time: 0.11 sec\n",
      "epoch 21, cross_loss: 0.050, auc_train: 1.000, auc_valid:0.843, time: 0.11 sec\n",
      "epoch 22, cross_loss: 0.035, auc_train: 1.000, auc_valid:0.843, time: 0.12 sec\n",
      "epoch 23, cross_loss: 0.119, auc_train: 1.000, auc_valid:0.850, time: 0.11 sec\n",
      "epoch 24, cross_loss: 0.112, auc_train: 1.000, auc_valid:0.850, time: 0.11 sec\n",
      "epoch 25, cross_loss: 0.084, auc_train: 1.000, auc_valid:0.853, time: 0.11 sec\n",
      "epoch 26, cross_loss: 0.062, auc_train: 1.000, auc_valid:0.853, time: 0.11 sec\n",
      "epoch 27, cross_loss: 0.085, auc_train: 1.000, auc_valid:0.853, time: 0.11 sec\n",
      "epoch 28, cross_loss: 0.016, auc_train: 1.000, auc_valid:0.855, time: 0.11 sec\n",
      "epoch 29, cross_loss: 0.008, auc_train: 1.000, auc_valid:0.858, time: 0.11 sec\n",
      "epoch 30, cross_loss: 0.117, auc_train: 1.000, auc_valid:0.858, time: 0.11 sec\n",
      "epoch 31, cross_loss: 0.007, auc_train: 1.000, auc_valid:0.860, time: 0.11 sec\n",
      "epoch 32, cross_loss: 0.022, auc_train: 1.000, auc_valid:0.860, time: 0.12 sec\n",
      "epoch 33, cross_loss: 0.098, auc_train: 1.000, auc_valid:0.858, time: 0.11 sec\n",
      "epoch 34, cross_loss: 0.005, auc_train: 1.000, auc_valid:0.855, time: 0.11 sec\n",
      "epoch 35, cross_loss: 0.261, auc_train: 1.000, auc_valid:0.843, time: 0.11 sec\n",
      "epoch 36, cross_loss: 0.003, auc_train: 1.000, auc_valid:0.843, time: 0.11 sec\n",
      "epoch 37, cross_loss: 0.005, auc_train: 1.000, auc_valid:0.843, time: 0.11 sec\n",
      "epoch 38, cross_loss: 0.002, auc_train: 1.000, auc_valid:0.843, time: 0.11 sec\n",
      "epoch 39, cross_loss: 0.003, auc_train: 1.000, auc_valid:0.843, time: 0.11 sec\n",
      "epoch 40, cross_loss: 0.001, auc_train: 1.000, auc_valid:0.843, time: 0.11 sec\n",
      "epoch 41, cross_loss: 0.002, auc_train: 1.000, auc_valid:0.848, time: 0.11 sec\n",
      "doing: MLP-dropout 100 1\n",
      "Doing Drop-out\n",
      "epoch 0, cross_loss: 0.723, auc_train: 0.645, auc_valid:0.728, time: 0.11 sec\n",
      "epoch 1, cross_loss: 0.734, auc_train: 0.825, auc_valid:0.810, time: 0.11 sec\n",
      "epoch 2, cross_loss: 0.689, auc_train: 0.898, auc_valid:0.843, time: 0.12 sec\n",
      "epoch 3, cross_loss: 0.632, auc_train: 0.922, auc_valid:0.873, time: 0.12 sec\n",
      "epoch 4, cross_loss: 0.703, auc_train: 0.942, auc_valid:0.900, time: 0.12 sec\n",
      "epoch 5, cross_loss: 0.710, auc_train: 0.952, auc_valid:0.910, time: 0.11 sec\n",
      "epoch 6, cross_loss: 0.655, auc_train: 0.953, auc_valid:0.920, time: 0.12 sec\n",
      "epoch 7, cross_loss: 0.649, auc_train: 0.956, auc_valid:0.920, time: 0.11 sec\n",
      "epoch 8, cross_loss: 0.492, auc_train: 0.958, auc_valid:0.920, time: 0.11 sec\n",
      "epoch 9, cross_loss: 0.468, auc_train: 0.958, auc_valid:0.925, time: 0.11 sec\n",
      "epoch 10, cross_loss: 0.427, auc_train: 0.961, auc_valid:0.927, time: 0.11 sec\n",
      "epoch 11, cross_loss: 0.693, auc_train: 0.969, auc_valid:0.935, time: 0.11 sec\n",
      "epoch 12, cross_loss: 0.367, auc_train: 0.971, auc_valid:0.932, time: 0.12 sec\n",
      "epoch 13, cross_loss: 0.393, auc_train: 0.976, auc_valid:0.935, time: 0.11 sec\n",
      "epoch 14, cross_loss: 0.361, auc_train: 0.977, auc_valid:0.938, time: 0.12 sec\n",
      "epoch 15, cross_loss: 0.838, auc_train: 0.982, auc_valid:0.940, time: 0.11 sec\n",
      "epoch 16, cross_loss: 0.482, auc_train: 0.984, auc_valid:0.940, time: 0.11 sec\n",
      "epoch 17, cross_loss: 0.390, auc_train: 0.990, auc_valid:0.938, time: 0.11 sec\n",
      "epoch 18, cross_loss: 0.489, auc_train: 0.992, auc_valid:0.930, time: 0.11 sec\n",
      "epoch 19, cross_loss: 0.177, auc_train: 0.993, auc_valid:0.925, time: 0.11 sec\n",
      "epoch 20, cross_loss: 0.207, auc_train: 0.997, auc_valid:0.930, time: 0.11 sec\n",
      "epoch 21, cross_loss: 0.183, auc_train: 0.998, auc_valid:0.930, time: 0.11 sec\n",
      "epoch 22, cross_loss: 0.339, auc_train: 1.000, auc_valid:0.927, time: 0.11 sec\n",
      "epoch 23, cross_loss: 0.159, auc_train: 1.000, auc_valid:0.932, time: 0.11 sec\n",
      "epoch 24, cross_loss: 0.067, auc_train: 1.000, auc_valid:0.932, time: 0.11 sec\n",
      "epoch 25, cross_loss: 0.162, auc_train: 1.000, auc_valid:0.935, time: 0.11 sec\n",
      "doing: MLP-dropout 100 2\n",
      "Doing Drop-out\n",
      "epoch 0, cross_loss: 0.693, auc_train: 0.832, auc_valid:0.847, time: 0.11 sec\n",
      "epoch 1, cross_loss: 0.679, auc_train: 0.875, auc_valid:0.885, time: 0.11 sec\n",
      "epoch 2, cross_loss: 0.674, auc_train: 0.893, auc_valid:0.900, time: 0.11 sec\n",
      "epoch 3, cross_loss: 0.707, auc_train: 0.914, auc_valid:0.920, time: 0.11 sec\n",
      "epoch 4, cross_loss: 0.658, auc_train: 0.925, auc_valid:0.935, time: 0.11 sec\n",
      "epoch 5, cross_loss: 0.663, auc_train: 0.934, auc_valid:0.940, time: 0.11 sec\n",
      "epoch 6, cross_loss: 0.564, auc_train: 0.942, auc_valid:0.950, time: 0.11 sec\n",
      "epoch 7, cross_loss: 0.590, auc_train: 0.952, auc_valid:0.953, time: 0.11 sec\n",
      "epoch 8, cross_loss: 0.560, auc_train: 0.957, auc_valid:0.953, time: 0.11 sec\n",
      "epoch 9, cross_loss: 0.460, auc_train: 0.959, auc_valid:0.955, time: 0.11 sec\n",
      "epoch 10, cross_loss: 0.486, auc_train: 0.962, auc_valid:0.958, time: 0.11 sec\n",
      "epoch 11, cross_loss: 0.462, auc_train: 0.966, auc_valid:0.958, time: 0.11 sec\n",
      "epoch 12, cross_loss: 0.357, auc_train: 0.972, auc_valid:0.955, time: 0.11 sec\n",
      "epoch 13, cross_loss: 0.228, auc_train: 0.981, auc_valid:0.955, time: 0.11 sec\n",
      "epoch 14, cross_loss: 0.251, auc_train: 0.984, auc_valid:0.953, time: 0.11 sec\n",
      "epoch 15, cross_loss: 0.230, auc_train: 0.987, auc_valid:0.953, time: 0.11 sec\n",
      "epoch 16, cross_loss: 0.244, auc_train: 0.992, auc_valid:0.955, time: 0.11 sec\n",
      "epoch 17, cross_loss: 0.178, auc_train: 0.994, auc_valid:0.960, time: 0.11 sec\n",
      "epoch 18, cross_loss: 0.073, auc_train: 0.997, auc_valid:0.958, time: 0.11 sec\n",
      "epoch 19, cross_loss: 0.130, auc_train: 0.999, auc_valid:0.950, time: 0.11 sec\n",
      "epoch 20, cross_loss: 0.059, auc_train: 0.999, auc_valid:0.950, time: 0.11 sec\n",
      "epoch 21, cross_loss: 0.055, auc_train: 1.000, auc_valid:0.953, time: 0.11 sec\n",
      "epoch 22, cross_loss: 0.018, auc_train: 1.000, auc_valid:0.953, time: 0.11 sec\n",
      "epoch 23, cross_loss: 0.033, auc_train: 1.000, auc_valid:0.953, time: 0.11 sec\n",
      "epoch 24, cross_loss: 0.120, auc_train: 1.000, auc_valid:0.953, time: 0.11 sec\n",
      "epoch 25, cross_loss: 0.007, auc_train: 1.000, auc_valid:0.955, time: 0.11 sec\n",
      "epoch 26, cross_loss: 0.083, auc_train: 1.000, auc_valid:0.955, time: 0.11 sec\n",
      "epoch 27, cross_loss: 0.004, auc_train: 1.000, auc_valid:0.955, time: 0.11 sec\n",
      "doing: MLP-dropout 100 3\n",
      "Doing Drop-out\n",
      "epoch 0, cross_loss: 0.723, auc_train: 0.623, auc_valid:0.652, time: 0.11 sec\n",
      "epoch 1, cross_loss: 0.677, auc_train: 0.796, auc_valid:0.760, time: 0.11 sec\n",
      "epoch 2, cross_loss: 0.699, auc_train: 0.879, auc_valid:0.818, time: 0.11 sec\n",
      "epoch 3, cross_loss: 0.628, auc_train: 0.918, auc_valid:0.860, time: 0.11 sec\n",
      "epoch 4, cross_loss: 0.674, auc_train: 0.938, auc_valid:0.877, time: 0.11 sec\n",
      "epoch 5, cross_loss: 0.599, auc_train: 0.951, auc_valid:0.895, time: 0.11 sec\n",
      "epoch 6, cross_loss: 0.565, auc_train: 0.961, auc_valid:0.903, time: 0.11 sec\n",
      "epoch 7, cross_loss: 0.490, auc_train: 0.966, auc_valid:0.905, time: 0.11 sec\n",
      "epoch 8, cross_loss: 0.530, auc_train: 0.972, auc_valid:0.907, time: 0.11 sec\n",
      "epoch 9, cross_loss: 0.576, auc_train: 0.981, auc_valid:0.912, time: 0.11 sec\n",
      "epoch 10, cross_loss: 0.422, auc_train: 0.986, auc_valid:0.912, time: 0.11 sec\n",
      "epoch 11, cross_loss: 0.293, auc_train: 0.990, auc_valid:0.912, time: 0.11 sec\n",
      "epoch 12, cross_loss: 0.499, auc_train: 0.993, auc_valid:0.915, time: 0.11 sec\n",
      "epoch 13, cross_loss: 0.264, auc_train: 0.997, auc_valid:0.922, time: 0.11 sec\n",
      "epoch 14, cross_loss: 0.150, auc_train: 0.999, auc_valid:0.925, time: 0.11 sec\n",
      "epoch 15, cross_loss: 0.223, auc_train: 1.000, auc_valid:0.927, time: 0.11 sec\n",
      "epoch 16, cross_loss: 0.173, auc_train: 1.000, auc_valid:0.932, time: 0.11 sec\n",
      "epoch 17, cross_loss: 0.164, auc_train: 1.000, auc_valid:0.945, time: 0.11 sec\n",
      "epoch 18, cross_loss: 0.097, auc_train: 1.000, auc_valid:0.950, time: 0.11 sec\n",
      "epoch 19, cross_loss: 0.128, auc_train: 1.000, auc_valid:0.950, time: 0.11 sec\n",
      "epoch 20, cross_loss: 0.105, auc_train: 1.000, auc_valid:0.948, time: 0.11 sec\n",
      "epoch 21, cross_loss: 0.077, auc_train: 1.000, auc_valid:0.948, time: 0.11 sec\n",
      "epoch 22, cross_loss: 0.074, auc_train: 1.000, auc_valid:0.948, time: 0.12 sec\n",
      "epoch 23, cross_loss: 0.055, auc_train: 1.000, auc_valid:0.950, time: 0.11 sec\n",
      "epoch 24, cross_loss: 0.009, auc_train: 1.000, auc_valid:0.948, time: 0.11 sec\n",
      "epoch 25, cross_loss: 0.010, auc_train: 1.000, auc_valid:0.945, time: 0.11 sec\n",
      "epoch 26, cross_loss: 0.013, auc_train: 1.000, auc_valid:0.945, time: 0.11 sec\n",
      "epoch 27, cross_loss: 0.011, auc_train: 1.000, auc_valid:0.943, time: 0.11 sec\n",
      "epoch 28, cross_loss: 0.017, auc_train: 1.000, auc_valid:0.945, time: 0.11 sec\n",
      "doing: MLP-dropout 100 4\n",
      "Doing Drop-out\n",
      "epoch 0, cross_loss: 0.731, auc_train: 0.756, auc_valid:0.810, time: 0.12 sec\n",
      "epoch 1, cross_loss: 0.676, auc_train: 0.820, auc_valid:0.863, time: 0.11 sec\n",
      "epoch 2, cross_loss: 0.670, auc_train: 0.854, auc_valid:0.885, time: 0.11 sec\n",
      "epoch 3, cross_loss: 0.657, auc_train: 0.879, auc_valid:0.897, time: 0.11 sec\n",
      "epoch 4, cross_loss: 0.655, auc_train: 0.908, auc_valid:0.907, time: 0.11 sec\n",
      "epoch 5, cross_loss: 0.658, auc_train: 0.923, auc_valid:0.917, time: 0.12 sec\n",
      "epoch 6, cross_loss: 0.583, auc_train: 0.934, auc_valid:0.922, time: 0.12 sec\n",
      "epoch 7, cross_loss: 0.601, auc_train: 0.939, auc_valid:0.910, time: 0.11 sec\n",
      "epoch 8, cross_loss: 0.591, auc_train: 0.945, auc_valid:0.905, time: 0.12 sec\n",
      "epoch 9, cross_loss: 0.494, auc_train: 0.956, auc_valid:0.907, time: 0.11 sec\n",
      "epoch 10, cross_loss: 0.514, auc_train: 0.959, auc_valid:0.907, time: 0.12 sec\n",
      "epoch 11, cross_loss: 0.449, auc_train: 0.963, auc_valid:0.908, time: 0.11 sec\n",
      "epoch 12, cross_loss: 0.411, auc_train: 0.971, auc_valid:0.908, time: 0.11 sec\n",
      "epoch 13, cross_loss: 0.259, auc_train: 0.978, auc_valid:0.920, time: 0.11 sec\n",
      "epoch 14, cross_loss: 0.292, auc_train: 0.981, auc_valid:0.925, time: 0.12 sec\n",
      "epoch 15, cross_loss: 0.310, auc_train: 0.984, auc_valid:0.932, time: 0.11 sec\n",
      "epoch 16, cross_loss: 0.274, auc_train: 0.984, auc_valid:0.932, time: 0.11 sec\n",
      "epoch 17, cross_loss: 0.222, auc_train: 0.989, auc_valid:0.935, time: 0.11 sec\n",
      "epoch 18, cross_loss: 0.209, auc_train: 0.993, auc_valid:0.935, time: 0.11 sec\n",
      "epoch 19, cross_loss: 0.160, auc_train: 0.996, auc_valid:0.940, time: 0.11 sec\n",
      "epoch 20, cross_loss: 0.135, auc_train: 0.998, auc_valid:0.940, time: 0.11 sec\n",
      "epoch 21, cross_loss: 0.096, auc_train: 0.998, auc_valid:0.945, time: 0.11 sec\n",
      "epoch 22, cross_loss: 0.058, auc_train: 0.998, auc_valid:0.948, time: 0.11 sec\n",
      "epoch 23, cross_loss: 0.107, auc_train: 0.998, auc_valid:0.948, time: 0.11 sec\n",
      "epoch 24, cross_loss: 0.064, auc_train: 1.000, auc_valid:0.948, time: 0.11 sec\n",
      "epoch 25, cross_loss: 0.033, auc_train: 1.000, auc_valid:0.948, time: 0.11 sec\n",
      "epoch 26, cross_loss: 0.040, auc_train: 1.000, auc_valid:0.948, time: 0.11 sec\n",
      "epoch 27, cross_loss: 0.014, auc_train: 1.000, auc_valid:0.945, time: 0.11 sec\n",
      "epoch 28, cross_loss: 0.013, auc_train: 1.000, auc_valid:0.943, time: 0.11 sec\n",
      "epoch 29, cross_loss: 0.062, auc_train: 1.000, auc_valid:0.940, time: 0.11 sec\n",
      "epoch 30, cross_loss: 0.023, auc_train: 1.000, auc_valid:0.943, time: 0.11 sec\n",
      "epoch 31, cross_loss: 0.027, auc_train: 1.000, auc_valid:0.943, time: 0.11 sec\n",
      "epoch 32, cross_loss: 0.059, auc_train: 1.000, auc_valid:0.945, time: 0.11 sec\n",
      "200 200\n",
      "neighbors 200\n",
      "doing: CGN_3_layer_64_channel_emb_32_dropout 200 0\n",
      "Doing drop-out\n",
      "epoch 0, cross_loss: 0.817, auc_train: 0.895, auc_valid:0.810, time: 0.36 sec\n",
      "epoch 1, cross_loss: 0.746, auc_train: 0.927, auc_valid:0.805, time: 0.35 sec\n",
      "epoch 2, cross_loss: 0.680, auc_train: 0.930, auc_valid:0.800, time: 0.35 sec\n",
      "epoch 3, cross_loss: 0.649, auc_train: 0.940, auc_valid:0.797, time: 0.35 sec\n",
      "epoch 4, cross_loss: 0.680, auc_train: 0.944, auc_valid:0.797, time: 0.35 sec\n",
      "epoch 5, cross_loss: 0.644, auc_train: 0.943, auc_valid:0.802, time: 0.35 sec\n",
      "epoch 6, cross_loss: 0.561, auc_train: 0.943, auc_valid:0.810, time: 0.35 sec\n",
      "epoch 7, cross_loss: 0.452, auc_train: 0.943, auc_valid:0.818, time: 0.35 sec\n",
      "epoch 8, cross_loss: 0.408, auc_train: 0.949, auc_valid:0.825, time: 0.35 sec\n",
      "epoch 9, cross_loss: 0.289, auc_train: 0.950, auc_valid:0.833, time: 0.35 sec\n",
      "epoch 10, cross_loss: 0.231, auc_train: 0.951, auc_valid:0.837, time: 0.35 sec\n",
      "epoch 11, cross_loss: 0.220, auc_train: 0.960, auc_valid:0.837, time: 0.35 sec\n",
      "epoch 12, cross_loss: 0.238, auc_train: 0.964, auc_valid:0.853, time: 0.35 sec\n",
      "epoch 13, cross_loss: 0.177, auc_train: 0.971, auc_valid:0.865, time: 0.35 sec\n",
      "epoch 14, cross_loss: 0.264, auc_train: 0.977, auc_valid:0.870, time: 0.35 sec\n",
      "epoch 15, cross_loss: 0.144, auc_train: 0.982, auc_valid:0.867, time: 0.35 sec\n",
      "epoch 16, cross_loss: 0.183, auc_train: 0.988, auc_valid:0.870, time: 0.35 sec\n",
      "epoch 17, cross_loss: 0.085, auc_train: 0.997, auc_valid:0.868, time: 0.35 sec\n",
      "epoch 18, cross_loss: 0.024, auc_train: 1.000, auc_valid:0.858, time: 0.35 sec\n",
      "epoch 19, cross_loss: 0.200, auc_train: 1.000, auc_valid:0.858, time: 0.35 sec\n",
      "epoch 20, cross_loss: 0.185, auc_train: 1.000, auc_valid:0.858, time: 0.35 sec\n",
      "epoch 21, cross_loss: 0.185, auc_train: 1.000, auc_valid:0.855, time: 0.35 sec\n",
      "epoch 22, cross_loss: 0.020, auc_train: 1.000, auc_valid:0.862, time: 0.35 sec\n",
      "epoch 23, cross_loss: 0.084, auc_train: 1.000, auc_valid:0.865, time: 0.35 sec\n",
      "epoch 24, cross_loss: 0.042, auc_train: 1.000, auc_valid:0.870, time: 0.35 sec\n",
      "doing: CGN_3_layer_64_channel_emb_32_dropout 200 1\n",
      "Doing drop-out\n",
      "epoch 0, cross_loss: 0.669, auc_train: 0.908, auc_valid:0.932, time: 0.35 sec\n",
      "epoch 1, cross_loss: 0.618, auc_train: 0.939, auc_valid:0.965, time: 0.35 sec\n",
      "epoch 2, cross_loss: 0.710, auc_train: 0.943, auc_valid:0.972, time: 0.35 sec\n",
      "epoch 3, cross_loss: 0.681, auc_train: 0.948, auc_valid:0.965, time: 0.35 sec\n",
      "epoch 4, cross_loss: 0.640, auc_train: 0.952, auc_valid:0.963, time: 0.35 sec\n",
      "epoch 5, cross_loss: 0.613, auc_train: 0.948, auc_valid:0.965, time: 0.35 sec\n",
      "epoch 6, cross_loss: 0.613, auc_train: 0.949, auc_valid:0.965, time: 0.35 sec\n",
      "epoch 7, cross_loss: 0.483, auc_train: 0.952, auc_valid:0.965, time: 0.35 sec\n",
      "epoch 8, cross_loss: 0.425, auc_train: 0.954, auc_valid:0.968, time: 0.35 sec\n",
      "epoch 9, cross_loss: 0.480, auc_train: 0.956, auc_valid:0.970, time: 0.35 sec\n",
      "epoch 10, cross_loss: 0.572, auc_train: 0.963, auc_valid:0.970, time: 0.35 sec\n",
      "epoch 11, cross_loss: 0.671, auc_train: 0.968, auc_valid:0.970, time: 0.35 sec\n",
      "epoch 12, cross_loss: 0.502, auc_train: 0.969, auc_valid:0.970, time: 0.35 sec\n",
      "epoch 13, cross_loss: 0.393, auc_train: 0.976, auc_valid:0.968, time: 0.35 sec\n",
      "epoch 14, cross_loss: 0.378, auc_train: 0.980, auc_valid:0.958, time: 0.35 sec\n",
      "epoch 15, cross_loss: 0.660, auc_train: 0.983, auc_valid:0.953, time: 0.35 sec\n",
      "epoch 16, cross_loss: 0.362, auc_train: 0.988, auc_valid:0.953, time: 0.35 sec\n",
      "epoch 17, cross_loss: 0.539, auc_train: 0.989, auc_valid:0.950, time: 0.35 sec\n",
      "epoch 18, cross_loss: 0.356, auc_train: 0.990, auc_valid:0.950, time: 0.35 sec\n",
      "epoch 19, cross_loss: 0.343, auc_train: 0.992, auc_valid:0.955, time: 0.35 sec\n",
      "epoch 20, cross_loss: 0.216, auc_train: 0.998, auc_valid:0.955, time: 0.35 sec\n",
      "doing: CGN_3_layer_64_channel_emb_32_dropout 200 2\n",
      "Doing drop-out\n",
      "epoch 0, cross_loss: 0.660, auc_train: 0.868, auc_valid:0.812, time: 0.35 sec\n",
      "epoch 1, cross_loss: 0.693, auc_train: 0.942, auc_valid:0.915, time: 0.37 sec\n",
      "epoch 2, cross_loss: 0.711, auc_train: 0.956, auc_valid:0.943, time: 0.36 sec\n",
      "epoch 3, cross_loss: 0.671, auc_train: 0.960, auc_valid:0.955, time: 0.35 sec\n",
      "epoch 4, cross_loss: 0.672, auc_train: 0.961, auc_valid:0.953, time: 0.35 sec\n",
      "epoch 5, cross_loss: 0.624, auc_train: 0.959, auc_valid:0.950, time: 0.35 sec\n",
      "epoch 6, cross_loss: 0.601, auc_train: 0.960, auc_valid:0.955, time: 0.35 sec\n",
      "epoch 7, cross_loss: 0.486, auc_train: 0.961, auc_valid:0.955, time: 0.35 sec\n",
      "epoch 8, cross_loss: 0.426, auc_train: 0.963, auc_valid:0.955, time: 0.35 sec\n",
      "epoch 9, cross_loss: 0.236, auc_train: 0.967, auc_valid:0.955, time: 0.35 sec\n",
      "epoch 10, cross_loss: 0.199, auc_train: 0.971, auc_valid:0.958, time: 0.35 sec\n",
      "epoch 11, cross_loss: 0.103, auc_train: 0.976, auc_valid:0.960, time: 0.35 sec\n",
      "epoch 12, cross_loss: 0.063, auc_train: 0.979, auc_valid:0.963, time: 0.35 sec\n",
      "epoch 13, cross_loss: 0.052, auc_train: 0.984, auc_valid:0.958, time: 0.35 sec\n",
      "epoch 14, cross_loss: 0.046, auc_train: 0.989, auc_valid:0.958, time: 0.35 sec\n",
      "epoch 15, cross_loss: 0.032, auc_train: 0.996, auc_valid:0.953, time: 0.35 sec\n",
      "epoch 16, cross_loss: 0.034, auc_train: 0.999, auc_valid:0.950, time: 0.35 sec\n",
      "epoch 17, cross_loss: 0.023, auc_train: 1.000, auc_valid:0.950, time: 0.35 sec\n",
      "epoch 18, cross_loss: 0.012, auc_train: 1.000, auc_valid:0.945, time: 0.35 sec\n",
      "epoch 19, cross_loss: 0.020, auc_train: 1.000, auc_valid:0.945, time: 0.35 sec\n",
      "epoch 20, cross_loss: 0.016, auc_train: 1.000, auc_valid:0.940, time: 0.35 sec\n",
      "epoch 21, cross_loss: 0.006, auc_train: 1.000, auc_valid:0.938, time: 0.35 sec\n",
      "epoch 22, cross_loss: 0.026, auc_train: 1.000, auc_valid:0.935, time: 0.35 sec\n",
      "doing: CGN_3_layer_64_channel_emb_32_dropout 200 3\n",
      "Doing drop-out\n",
      "epoch 0, cross_loss: 0.789, auc_train: 0.934, auc_valid:0.870, time: 0.35 sec\n",
      "epoch 1, cross_loss: 0.763, auc_train: 0.937, auc_valid:0.912, time: 0.35 sec\n",
      "epoch 2, cross_loss: 0.731, auc_train: 0.938, auc_valid:0.922, time: 0.35 sec\n",
      "epoch 3, cross_loss: 0.726, auc_train: 0.941, auc_valid:0.922, time: 0.35 sec\n",
      "epoch 4, cross_loss: 0.733, auc_train: 0.947, auc_valid:0.920, time: 0.35 sec\n",
      "epoch 5, cross_loss: 0.641, auc_train: 0.949, auc_valid:0.920, time: 0.35 sec\n",
      "epoch 6, cross_loss: 0.646, auc_train: 0.948, auc_valid:0.922, time: 0.36 sec\n",
      "epoch 7, cross_loss: 0.582, auc_train: 0.949, auc_valid:0.922, time: 0.35 sec\n",
      "epoch 8, cross_loss: 0.510, auc_train: 0.948, auc_valid:0.922, time: 0.35 sec\n",
      "epoch 9, cross_loss: 0.517, auc_train: 0.952, auc_valid:0.927, time: 0.35 sec\n",
      "epoch 10, cross_loss: 0.421, auc_train: 0.961, auc_valid:0.932, time: 0.35 sec\n",
      "epoch 11, cross_loss: 0.496, auc_train: 0.971, auc_valid:0.938, time: 0.35 sec\n",
      "epoch 12, cross_loss: 0.443, auc_train: 0.983, auc_valid:0.943, time: 0.35 sec\n",
      "epoch 13, cross_loss: 0.376, auc_train: 0.990, auc_valid:0.948, time: 0.35 sec\n",
      "epoch 14, cross_loss: 0.358, auc_train: 0.998, auc_valid:0.952, time: 0.35 sec\n",
      "epoch 15, cross_loss: 0.261, auc_train: 1.000, auc_valid:0.958, time: 0.35 sec\n",
      "epoch 16, cross_loss: 0.224, auc_train: 1.000, auc_valid:0.963, time: 0.35 sec\n",
      "epoch 17, cross_loss: 0.114, auc_train: 1.000, auc_valid:0.967, time: 0.35 sec\n",
      "epoch 18, cross_loss: 0.155, auc_train: 1.000, auc_valid:0.970, time: 0.35 sec\n",
      "epoch 19, cross_loss: 0.080, auc_train: 1.000, auc_valid:0.970, time: 0.35 sec\n",
      "epoch 20, cross_loss: 0.028, auc_train: 1.000, auc_valid:0.970, time: 0.35 sec\n",
      "epoch 21, cross_loss: 0.035, auc_train: 1.000, auc_valid:0.970, time: 0.35 sec\n",
      "epoch 22, cross_loss: 0.020, auc_train: 1.000, auc_valid:0.972, time: 0.35 sec\n",
      "epoch 23, cross_loss: 0.035, auc_train: 1.000, auc_valid:0.972, time: 0.35 sec\n",
      "epoch 24, cross_loss: 0.052, auc_train: 1.000, auc_valid:0.970, time: 0.35 sec\n",
      "epoch 25, cross_loss: 0.053, auc_train: 1.000, auc_valid:0.973, time: 0.35 sec\n",
      "epoch 26, cross_loss: 0.011, auc_train: 1.000, auc_valid:0.973, time: 0.35 sec\n",
      "epoch 27, cross_loss: 0.019, auc_train: 1.000, auc_valid:0.973, time: 0.35 sec\n",
      "epoch 28, cross_loss: 0.043, auc_train: 1.000, auc_valid:0.973, time: 0.35 sec\n",
      "epoch 29, cross_loss: 0.011, auc_train: 1.000, auc_valid:0.973, time: 0.35 sec\n",
      "epoch 30, cross_loss: 0.005, auc_train: 1.000, auc_valid:0.970, time: 0.35 sec\n",
      "epoch 31, cross_loss: 0.004, auc_train: 1.000, auc_valid:0.970, time: 0.35 sec\n",
      "epoch 32, cross_loss: 0.021, auc_train: 1.000, auc_valid:0.970, time: 0.35 sec\n",
      "epoch 33, cross_loss: 0.005, auc_train: 1.000, auc_valid:0.973, time: 0.35 sec\n",
      "epoch 34, cross_loss: 0.053, auc_train: 1.000, auc_valid:0.973, time: 0.35 sec\n",
      "epoch 35, cross_loss: 0.027, auc_train: 1.000, auc_valid:0.978, time: 0.35 sec\n",
      "doing: CGN_3_layer_64_channel_emb_32_dropout 200 4\n",
      "Doing drop-out\n",
      "epoch 0, cross_loss: 0.715, auc_train: 0.846, auc_valid:0.893, time: 0.35 sec\n",
      "epoch 1, cross_loss: 0.672, auc_train: 0.877, auc_valid:0.910, time: 0.35 sec\n",
      "epoch 2, cross_loss: 0.709, auc_train: 0.897, auc_valid:0.900, time: 0.35 sec\n",
      "epoch 3, cross_loss: 0.707, auc_train: 0.907, auc_valid:0.915, time: 0.35 sec\n",
      "epoch 4, cross_loss: 0.694, auc_train: 0.908, auc_valid:0.910, time: 0.35 sec\n",
      "epoch 5, cross_loss: 0.646, auc_train: 0.912, auc_valid:0.910, time: 0.35 sec\n",
      "epoch 6, cross_loss: 0.639, auc_train: 0.911, auc_valid:0.910, time: 0.35 sec\n",
      "epoch 7, cross_loss: 0.572, auc_train: 0.913, auc_valid:0.910, time: 0.35 sec\n",
      "epoch 8, cross_loss: 0.478, auc_train: 0.914, auc_valid:0.907, time: 0.35 sec\n",
      "epoch 9, cross_loss: 0.425, auc_train: 0.920, auc_valid:0.910, time: 0.35 sec\n",
      "epoch 10, cross_loss: 0.380, auc_train: 0.927, auc_valid:0.918, time: 0.35 sec\n",
      "epoch 11, cross_loss: 0.323, auc_train: 0.935, auc_valid:0.922, time: 0.35 sec\n",
      "epoch 12, cross_loss: 0.235, auc_train: 0.950, auc_valid:0.925, time: 0.35 sec\n",
      "epoch 13, cross_loss: 0.397, auc_train: 0.963, auc_valid:0.927, time: 0.35 sec\n",
      "epoch 14, cross_loss: 0.335, auc_train: 0.974, auc_valid:0.930, time: 0.35 sec\n",
      "epoch 15, cross_loss: 0.275, auc_train: 0.986, auc_valid:0.930, time: 0.35 sec\n",
      "epoch 16, cross_loss: 0.127, auc_train: 0.992, auc_valid:0.922, time: 0.35 sec\n",
      "epoch 17, cross_loss: 0.063, auc_train: 0.999, auc_valid:0.922, time: 0.35 sec\n",
      "epoch 18, cross_loss: 0.113, auc_train: 1.000, auc_valid:0.925, time: 0.35 sec\n",
      "epoch 19, cross_loss: 0.149, auc_train: 1.000, auc_valid:0.930, time: 0.35 sec\n",
      "epoch 20, cross_loss: 0.142, auc_train: 1.000, auc_valid:0.932, time: 0.35 sec\n",
      "epoch 21, cross_loss: 0.100, auc_train: 1.000, auc_valid:0.935, time: 0.35 sec\n",
      "epoch 22, cross_loss: 0.183, auc_train: 1.000, auc_valid:0.935, time: 0.35 sec\n",
      "epoch 23, cross_loss: 0.072, auc_train: 1.000, auc_valid:0.938, time: 0.35 sec\n",
      "epoch 24, cross_loss: 0.064, auc_train: 1.000, auc_valid:0.940, time: 0.35 sec\n",
      "epoch 25, cross_loss: 0.035, auc_train: 1.000, auc_valid:0.943, time: 0.35 sec\n",
      "epoch 26, cross_loss: 0.028, auc_train: 1.000, auc_valid:0.948, time: 0.35 sec\n",
      "epoch 27, cross_loss: 0.041, auc_train: 1.000, auc_valid:0.950, time: 0.35 sec\n",
      "epoch 28, cross_loss: 0.065, auc_train: 1.000, auc_valid:0.948, time: 0.35 sec\n",
      "epoch 29, cross_loss: 0.335, auc_train: 1.000, auc_valid:0.948, time: 0.35 sec\n",
      "epoch 30, cross_loss: 0.092, auc_train: 1.000, auc_valid:0.950, time: 0.35 sec\n",
      "epoch 31, cross_loss: 0.023, auc_train: 1.000, auc_valid:0.950, time: 0.35 sec\n",
      "epoch 32, cross_loss: 0.010, auc_train: 1.000, auc_valid:0.948, time: 0.35 sec\n",
      "epoch 33, cross_loss: 0.042, auc_train: 1.000, auc_valid:0.943, time: 0.35 sec\n",
      "epoch 34, cross_loss: 0.054, auc_train: 1.000, auc_valid:0.948, time: 0.35 sec\n",
      "epoch 35, cross_loss: 0.056, auc_train: 1.000, auc_valid:0.948, time: 0.35 sec\n",
      "epoch 36, cross_loss: 0.004, auc_train: 1.000, auc_valid:0.945, time: 0.35 sec\n",
      "epoch 37, cross_loss: 0.112, auc_train: 1.000, auc_valid:0.948, time: 0.35 sec\n",
      "epoch 38, cross_loss: 0.035, auc_train: 1.000, auc_valid:0.948, time: 0.35 sec\n",
      "epoch 39, cross_loss: 0.004, auc_train: 1.000, auc_valid:0.948, time: 0.35 sec\n",
      "epoch 40, cross_loss: 0.002, auc_train: 1.000, auc_valid:0.948, time: 0.35 sec\n",
      "doing: MLP-dropout 200 0\n",
      "Doing Drop-out\n",
      "epoch 0, cross_loss: 0.651, auc_train: 0.860, auc_valid:0.585, time: 0.11 sec\n",
      "epoch 1, cross_loss: 0.673, auc_train: 0.920, auc_valid:0.703, time: 0.11 sec\n",
      "epoch 2, cross_loss: 0.673, auc_train: 0.941, auc_valid:0.740, time: 0.11 sec\n",
      "epoch 3, cross_loss: 0.588, auc_train: 0.948, auc_valid:0.780, time: 0.11 sec\n",
      "epoch 4, cross_loss: 0.468, auc_train: 0.953, auc_valid:0.792, time: 0.11 sec\n",
      "epoch 5, cross_loss: 0.390, auc_train: 0.954, auc_valid:0.807, time: 0.12 sec\n",
      "epoch 6, cross_loss: 0.362, auc_train: 0.961, auc_valid:0.807, time: 0.12 sec\n",
      "epoch 7, cross_loss: 0.297, auc_train: 0.962, auc_valid:0.810, time: 0.12 sec\n",
      "epoch 8, cross_loss: 0.314, auc_train: 0.968, auc_valid:0.812, time: 0.11 sec\n",
      "epoch 9, cross_loss: 0.321, auc_train: 0.970, auc_valid:0.820, time: 0.12 sec\n",
      "epoch 10, cross_loss: 0.228, auc_train: 0.972, auc_valid:0.820, time: 0.11 sec\n",
      "epoch 11, cross_loss: 0.366, auc_train: 0.978, auc_valid:0.820, time: 0.12 sec\n",
      "epoch 12, cross_loss: 0.240, auc_train: 0.991, auc_valid:0.830, time: 0.11 sec\n",
      "epoch 13, cross_loss: 0.192, auc_train: 0.999, auc_valid:0.838, time: 0.12 sec\n",
      "epoch 14, cross_loss: 0.144, auc_train: 1.000, auc_valid:0.847, time: 0.12 sec\n",
      "epoch 15, cross_loss: 0.023, auc_train: 1.000, auc_valid:0.850, time: 0.12 sec\n",
      "epoch 16, cross_loss: 0.032, auc_train: 1.000, auc_valid:0.850, time: 0.12 sec\n",
      "epoch 17, cross_loss: 0.025, auc_train: 1.000, auc_valid:0.853, time: 0.12 sec\n",
      "epoch 18, cross_loss: 0.077, auc_train: 1.000, auc_valid:0.855, time: 0.11 sec\n",
      "epoch 19, cross_loss: 0.117, auc_train: 1.000, auc_valid:0.863, time: 0.12 sec\n",
      "epoch 20, cross_loss: 0.012, auc_train: 1.000, auc_valid:0.870, time: 0.12 sec\n",
      "epoch 21, cross_loss: 0.012, auc_train: 1.000, auc_valid:0.873, time: 0.12 sec\n",
      "epoch 22, cross_loss: 0.019, auc_train: 1.000, auc_valid:0.878, time: 0.11 sec\n",
      "epoch 23, cross_loss: 0.153, auc_train: 1.000, auc_valid:0.877, time: 0.12 sec\n",
      "epoch 24, cross_loss: 0.008, auc_train: 1.000, auc_valid:0.857, time: 0.12 sec\n",
      "epoch 25, cross_loss: 0.032, auc_train: 1.000, auc_valid:0.855, time: 0.12 sec\n",
      "epoch 26, cross_loss: 0.002, auc_train: 1.000, auc_valid:0.853, time: 0.11 sec\n",
      "epoch 27, cross_loss: 0.004, auc_train: 1.000, auc_valid:0.855, time: 0.12 sec\n",
      "epoch 28, cross_loss: 0.007, auc_train: 1.000, auc_valid:0.860, time: 0.11 sec\n",
      "epoch 29, cross_loss: 0.014, auc_train: 1.000, auc_valid:0.867, time: 0.12 sec\n",
      "epoch 30, cross_loss: 0.034, auc_train: 1.000, auc_valid:0.877, time: 0.12 sec\n",
      "epoch 31, cross_loss: 0.002, auc_train: 1.000, auc_valid:0.875, time: 0.12 sec\n",
      "epoch 32, cross_loss: 0.002, auc_train: 1.000, auc_valid:0.875, time: 0.12 sec\n",
      "doing: MLP-dropout 200 1\n",
      "Doing Drop-out\n",
      "epoch 0, cross_loss: 0.722, auc_train: 0.711, auc_valid:0.768, time: 0.12 sec\n",
      "epoch 1, cross_loss: 0.719, auc_train: 0.889, auc_valid:0.840, time: 0.12 sec\n",
      "epoch 2, cross_loss: 0.685, auc_train: 0.934, auc_valid:0.895, time: 0.12 sec\n",
      "epoch 3, cross_loss: 0.698, auc_train: 0.945, auc_valid:0.917, time: 0.12 sec\n",
      "epoch 4, cross_loss: 0.639, auc_train: 0.953, auc_valid:0.927, time: 0.12 sec\n",
      "epoch 5, cross_loss: 0.652, auc_train: 0.956, auc_valid:0.938, time: 0.12 sec\n",
      "epoch 6, cross_loss: 0.438, auc_train: 0.957, auc_valid:0.940, time: 0.12 sec\n",
      "epoch 7, cross_loss: 0.424, auc_train: 0.962, auc_valid:0.945, time: 0.12 sec\n",
      "epoch 8, cross_loss: 0.541, auc_train: 0.964, auc_valid:0.950, time: 0.12 sec\n",
      "epoch 9, cross_loss: 0.363, auc_train: 0.969, auc_valid:0.945, time: 0.12 sec\n",
      "epoch 10, cross_loss: 0.468, auc_train: 0.976, auc_valid:0.943, time: 0.12 sec\n",
      "epoch 11, cross_loss: 0.300, auc_train: 0.981, auc_valid:0.943, time: 0.11 sec\n",
      "epoch 12, cross_loss: 0.596, auc_train: 0.984, auc_valid:0.945, time: 0.12 sec\n",
      "epoch 13, cross_loss: 0.333, auc_train: 0.987, auc_valid:0.945, time: 0.12 sec\n",
      "epoch 14, cross_loss: 0.248, auc_train: 0.987, auc_valid:0.945, time: 0.12 sec\n",
      "epoch 15, cross_loss: 0.247, auc_train: 0.987, auc_valid:0.945, time: 0.12 sec\n",
      "epoch 16, cross_loss: 0.384, auc_train: 0.990, auc_valid:0.940, time: 0.12 sec\n",
      "epoch 17, cross_loss: 0.479, auc_train: 0.993, auc_valid:0.938, time: 0.12 sec\n",
      "epoch 18, cross_loss: 0.158, auc_train: 0.999, auc_valid:0.940, time: 0.12 sec\n",
      "doing: MLP-dropout 200 2\n",
      "Doing Drop-out\n",
      "epoch 0, cross_loss: 0.653, auc_train: 0.713, auc_valid:0.750, time: 0.12 sec\n",
      "epoch 1, cross_loss: 0.648, auc_train: 0.930, auc_valid:0.880, time: 0.12 sec\n",
      "epoch 2, cross_loss: 0.638, auc_train: 0.971, auc_valid:0.935, time: 0.12 sec\n",
      "epoch 3, cross_loss: 0.616, auc_train: 0.987, auc_valid:0.935, time: 0.12 sec\n",
      "epoch 4, cross_loss: 0.574, auc_train: 0.991, auc_valid:0.938, time: 0.12 sec\n",
      "epoch 5, cross_loss: 0.454, auc_train: 0.992, auc_valid:0.948, time: 0.12 sec\n",
      "epoch 6, cross_loss: 0.392, auc_train: 0.996, auc_valid:0.955, time: 0.11 sec\n",
      "epoch 7, cross_loss: 0.343, auc_train: 0.996, auc_valid:0.965, time: 0.12 sec\n",
      "epoch 8, cross_loss: 0.205, auc_train: 0.997, auc_valid:0.968, time: 0.12 sec\n",
      "epoch 9, cross_loss: 0.171, auc_train: 0.999, auc_valid:0.968, time: 0.12 sec\n",
      "epoch 10, cross_loss: 0.081, auc_train: 1.000, auc_valid:0.968, time: 0.11 sec\n",
      "epoch 11, cross_loss: 0.089, auc_train: 1.000, auc_valid:0.963, time: 0.12 sec\n",
      "epoch 12, cross_loss: 0.063, auc_train: 1.000, auc_valid:0.955, time: 0.11 sec\n",
      "epoch 13, cross_loss: 0.064, auc_train: 1.000, auc_valid:0.953, time: 0.12 sec\n",
      "epoch 14, cross_loss: 0.064, auc_train: 1.000, auc_valid:0.953, time: 0.11 sec\n",
      "epoch 15, cross_loss: 0.028, auc_train: 1.000, auc_valid:0.953, time: 0.12 sec\n",
      "epoch 16, cross_loss: 0.031, auc_train: 1.000, auc_valid:0.953, time: 0.12 sec\n",
      "epoch 17, cross_loss: 0.029, auc_train: 1.000, auc_valid:0.953, time: 0.12 sec\n",
      "epoch 18, cross_loss: 0.000, auc_train: 1.000, auc_valid:0.953, time: 0.11 sec\n",
      "doing: MLP-dropout 200 3\n",
      "Doing Drop-out\n",
      "epoch 0, cross_loss: 0.663, auc_train: 0.853, auc_valid:0.693, time: 0.12 sec\n",
      "epoch 1, cross_loss: 0.705, auc_train: 0.938, auc_valid:0.775, time: 0.12 sec\n",
      "epoch 2, cross_loss: 0.641, auc_train: 0.966, auc_valid:0.833, time: 0.12 sec\n",
      "epoch 3, cross_loss: 0.620, auc_train: 0.976, auc_valid:0.877, time: 0.12 sec\n",
      "epoch 4, cross_loss: 0.606, auc_train: 0.977, auc_valid:0.892, time: 0.12 sec\n",
      "epoch 5, cross_loss: 0.601, auc_train: 0.981, auc_valid:0.902, time: 0.12 sec\n",
      "epoch 6, cross_loss: 0.521, auc_train: 0.983, auc_valid:0.907, time: 0.12 sec\n",
      "epoch 7, cross_loss: 0.499, auc_train: 0.987, auc_valid:0.917, time: 0.12 sec\n",
      "epoch 8, cross_loss: 0.488, auc_train: 0.989, auc_valid:0.925, time: 0.12 sec\n",
      "epoch 9, cross_loss: 0.461, auc_train: 0.992, auc_valid:0.930, time: 0.12 sec\n",
      "epoch 10, cross_loss: 0.465, auc_train: 0.996, auc_valid:0.935, time: 0.12 sec\n",
      "epoch 11, cross_loss: 0.340, auc_train: 1.000, auc_valid:0.938, time: 0.11 sec\n",
      "epoch 12, cross_loss: 0.267, auc_train: 1.000, auc_valid:0.942, time: 0.11 sec\n",
      "epoch 13, cross_loss: 0.297, auc_train: 1.000, auc_valid:0.948, time: 0.11 sec\n",
      "epoch 14, cross_loss: 0.181, auc_train: 1.000, auc_valid:0.948, time: 0.11 sec\n",
      "epoch 15, cross_loss: 0.154, auc_train: 1.000, auc_valid:0.952, time: 0.11 sec\n",
      "epoch 16, cross_loss: 0.130, auc_train: 1.000, auc_valid:0.952, time: 0.11 sec\n",
      "epoch 17, cross_loss: 0.099, auc_train: 1.000, auc_valid:0.957, time: 0.11 sec\n",
      "epoch 18, cross_loss: 0.074, auc_train: 1.000, auc_valid:0.952, time: 0.11 sec\n",
      "epoch 19, cross_loss: 0.072, auc_train: 1.000, auc_valid:0.952, time: 0.11 sec\n",
      "epoch 20, cross_loss: 0.059, auc_train: 1.000, auc_valid:0.955, time: 0.11 sec\n",
      "epoch 21, cross_loss: 0.034, auc_train: 1.000, auc_valid:0.955, time: 0.11 sec\n",
      "epoch 22, cross_loss: 0.048, auc_train: 1.000, auc_valid:0.955, time: 0.11 sec\n",
      "epoch 23, cross_loss: 0.042, auc_train: 1.000, auc_valid:0.952, time: 0.11 sec\n",
      "epoch 24, cross_loss: 0.003, auc_train: 1.000, auc_valid:0.952, time: 0.11 sec\n",
      "epoch 25, cross_loss: 0.010, auc_train: 1.000, auc_valid:0.952, time: 0.11 sec\n",
      "epoch 26, cross_loss: 0.011, auc_train: 1.000, auc_valid:0.952, time: 0.11 sec\n",
      "epoch 27, cross_loss: 0.007, auc_train: 1.000, auc_valid:0.952, time: 0.11 sec\n",
      "doing: MLP-dropout 200 4\n",
      "Doing Drop-out\n",
      "epoch 0, cross_loss: 0.664, auc_train: 0.560, auc_valid:0.547, time: 0.12 sec\n",
      "epoch 1, cross_loss: 0.676, auc_train: 0.714, auc_valid:0.770, time: 0.11 sec\n",
      "epoch 2, cross_loss: 0.657, auc_train: 0.834, auc_valid:0.885, time: 0.11 sec\n",
      "epoch 3, cross_loss: 0.643, auc_train: 0.881, auc_valid:0.905, time: 0.11 sec\n",
      "epoch 4, cross_loss: 0.642, auc_train: 0.905, auc_valid:0.915, time: 0.11 sec\n",
      "epoch 5, cross_loss: 0.618, auc_train: 0.921, auc_valid:0.917, time: 0.11 sec\n",
      "epoch 6, cross_loss: 0.525, auc_train: 0.937, auc_valid:0.915, time: 0.12 sec\n",
      "epoch 7, cross_loss: 0.519, auc_train: 0.949, auc_valid:0.920, time: 0.11 sec\n",
      "epoch 8, cross_loss: 0.398, auc_train: 0.954, auc_valid:0.920, time: 0.11 sec\n",
      "epoch 9, cross_loss: 0.307, auc_train: 0.959, auc_valid:0.925, time: 0.11 sec\n",
      "epoch 10, cross_loss: 0.300, auc_train: 0.968, auc_valid:0.930, time: 0.11 sec\n",
      "epoch 11, cross_loss: 0.264, auc_train: 0.977, auc_valid:0.938, time: 0.11 sec\n",
      "epoch 12, cross_loss: 0.290, auc_train: 0.983, auc_valid:0.938, time: 0.12 sec\n",
      "epoch 13, cross_loss: 0.230, auc_train: 0.989, auc_valid:0.940, time: 0.11 sec\n",
      "epoch 14, cross_loss: 0.226, auc_train: 0.992, auc_valid:0.943, time: 0.11 sec\n",
      "epoch 15, cross_loss: 0.119, auc_train: 0.997, auc_valid:0.943, time: 0.11 sec\n",
      "epoch 16, cross_loss: 0.175, auc_train: 1.000, auc_valid:0.943, time: 0.11 sec\n",
      "epoch 17, cross_loss: 0.072, auc_train: 1.000, auc_valid:0.945, time: 0.11 sec\n",
      "epoch 18, cross_loss: 0.181, auc_train: 1.000, auc_valid:0.945, time: 0.12 sec\n",
      "epoch 19, cross_loss: 0.042, auc_train: 1.000, auc_valid:0.945, time: 0.11 sec\n",
      "epoch 20, cross_loss: 0.069, auc_train: 1.000, auc_valid:0.945, time: 0.12 sec\n",
      "epoch 21, cross_loss: 0.003, auc_train: 1.000, auc_valid:0.945, time: 0.11 sec\n",
      "epoch 22, cross_loss: 0.026, auc_train: 1.000, auc_valid:0.945, time: 0.12 sec\n",
      "epoch 23, cross_loss: 0.021, auc_train: 1.000, auc_valid:0.945, time: 0.11 sec\n",
      "epoch 24, cross_loss: 0.017, auc_train: 1.000, auc_valid:0.945, time: 0.12 sec\n",
      "epoch 25, cross_loss: 0.008, auc_train: 1.000, auc_valid:0.943, time: 0.11 sec\n",
      "epoch 26, cross_loss: 0.028, auc_train: 1.000, auc_valid:0.943, time: 0.12 sec\n",
      "epoch 27, cross_loss: 0.005, auc_train: 1.000, auc_valid:0.943, time: 0.12 sec\n",
      "500 500\n",
      "neighbors 500\n",
      "doing: CGN_3_layer_64_channel_emb_32_dropout 500 0\n",
      "Doing drop-out\n",
      "epoch 0, cross_loss: 1.382, auc_train: 0.901, auc_valid:0.640, time: 0.42 sec\n",
      "epoch 1, cross_loss: 0.604, auc_train: 0.929, auc_valid:0.720, time: 0.41 sec\n",
      "epoch 2, cross_loss: 0.654, auc_train: 0.929, auc_valid:0.725, time: 0.41 sec\n",
      "epoch 3, cross_loss: 0.719, auc_train: 0.934, auc_valid:0.700, time: 0.41 sec\n",
      "epoch 4, cross_loss: 0.720, auc_train: 0.935, auc_valid:0.713, time: 0.41 sec\n",
      "epoch 5, cross_loss: 0.653, auc_train: 0.940, auc_valid:0.725, time: 0.41 sec\n",
      "epoch 6, cross_loss: 0.579, auc_train: 0.940, auc_valid:0.723, time: 0.41 sec\n",
      "epoch 7, cross_loss: 0.558, auc_train: 0.941, auc_valid:0.728, time: 0.41 sec\n",
      "epoch 8, cross_loss: 0.459, auc_train: 0.942, auc_valid:0.745, time: 0.41 sec\n",
      "epoch 9, cross_loss: 0.357, auc_train: 0.943, auc_valid:0.758, time: 0.41 sec\n",
      "epoch 10, cross_loss: 0.389, auc_train: 0.951, auc_valid:0.767, time: 0.41 sec\n",
      "epoch 11, cross_loss: 0.264, auc_train: 0.960, auc_valid:0.787, time: 0.41 sec\n",
      "epoch 12, cross_loss: 0.188, auc_train: 0.970, auc_valid:0.795, time: 0.41 sec\n",
      "epoch 13, cross_loss: 0.246, auc_train: 0.980, auc_valid:0.807, time: 0.41 sec\n",
      "epoch 14, cross_loss: 0.127, auc_train: 0.986, auc_valid:0.835, time: 0.41 sec\n",
      "epoch 15, cross_loss: 0.156, auc_train: 0.994, auc_valid:0.845, time: 0.41 sec\n",
      "epoch 16, cross_loss: 0.168, auc_train: 1.000, auc_valid:0.853, time: 0.41 sec\n",
      "epoch 17, cross_loss: 0.127, auc_train: 1.000, auc_valid:0.853, time: 0.41 sec\n",
      "epoch 18, cross_loss: 0.083, auc_train: 1.000, auc_valid:0.870, time: 0.41 sec\n",
      "epoch 19, cross_loss: 0.057, auc_train: 1.000, auc_valid:0.882, time: 0.58 sec\n",
      "epoch 20, cross_loss: 0.153, auc_train: 1.000, auc_valid:0.880, time: 0.41 sec\n",
      "epoch 21, cross_loss: 0.062, auc_train: 1.000, auc_valid:0.880, time: 0.41 sec\n",
      "epoch 22, cross_loss: 0.075, auc_train: 1.000, auc_valid:0.885, time: 0.42 sec\n",
      "epoch 23, cross_loss: 0.032, auc_train: 1.000, auc_valid:0.887, time: 0.41 sec\n",
      "epoch 24, cross_loss: 0.040, auc_train: 1.000, auc_valid:0.890, time: 0.41 sec\n",
      "epoch 25, cross_loss: 0.022, auc_train: 1.000, auc_valid:0.893, time: 0.41 sec\n",
      "epoch 26, cross_loss: 0.010, auc_train: 1.000, auc_valid:0.893, time: 0.41 sec\n",
      "epoch 27, cross_loss: 0.030, auc_train: 1.000, auc_valid:0.895, time: 0.41 sec\n",
      "epoch 28, cross_loss: 0.001, auc_train: 1.000, auc_valid:0.890, time: 0.41 sec\n",
      "epoch 29, cross_loss: 0.116, auc_train: 1.000, auc_valid:0.885, time: 0.41 sec\n",
      "epoch 30, cross_loss: 0.004, auc_train: 1.000, auc_valid:0.882, time: 0.41 sec\n",
      "epoch 31, cross_loss: 0.006, auc_train: 1.000, auc_valid:0.880, time: 0.41 sec\n",
      "epoch 32, cross_loss: 0.020, auc_train: 1.000, auc_valid:0.887, time: 0.41 sec\n",
      "epoch 33, cross_loss: 0.006, auc_train: 1.000, auc_valid:0.885, time: 0.57 sec\n",
      "epoch 34, cross_loss: 0.005, auc_train: 1.000, auc_valid:0.890, time: 0.41 sec\n",
      "epoch 35, cross_loss: 0.322, auc_train: 1.000, auc_valid:0.885, time: 0.41 sec\n",
      "epoch 36, cross_loss: 0.003, auc_train: 1.000, auc_valid:0.858, time: 0.41 sec\n",
      "epoch 37, cross_loss: 0.000, auc_train: 1.000, auc_valid:0.858, time: 0.41 sec\n",
      "doing: CGN_3_layer_64_channel_emb_32_dropout 500 1\n",
      "Doing drop-out\n",
      "epoch 0, cross_loss: 0.626, auc_train: 0.908, auc_valid:0.930, time: 0.41 sec\n",
      "epoch 1, cross_loss: 0.845, auc_train: 0.956, auc_valid:0.950, time: 0.41 sec\n",
      "epoch 2, cross_loss: 0.674, auc_train: 0.966, auc_valid:0.952, time: 0.41 sec\n",
      "epoch 3, cross_loss: 0.626, auc_train: 0.970, auc_valid:0.948, time: 0.41 sec\n",
      "epoch 4, cross_loss: 0.647, auc_train: 0.970, auc_valid:0.943, time: 0.41 sec\n",
      "epoch 5, cross_loss: 0.645, auc_train: 0.972, auc_valid:0.945, time: 0.41 sec\n",
      "epoch 6, cross_loss: 0.524, auc_train: 0.972, auc_valid:0.943, time: 0.41 sec\n",
      "epoch 7, cross_loss: 0.478, auc_train: 0.974, auc_valid:0.943, time: 0.41 sec\n",
      "epoch 8, cross_loss: 0.374, auc_train: 0.976, auc_valid:0.950, time: 0.42 sec\n",
      "epoch 9, cross_loss: 0.339, auc_train: 0.980, auc_valid:0.953, time: 0.41 sec\n",
      "epoch 10, cross_loss: 0.272, auc_train: 0.987, auc_valid:0.950, time: 0.41 sec\n",
      "epoch 11, cross_loss: 0.237, auc_train: 0.993, auc_valid:0.945, time: 0.41 sec\n",
      "epoch 12, cross_loss: 0.283, auc_train: 0.998, auc_valid:0.940, time: 0.41 sec\n",
      "epoch 13, cross_loss: 0.227, auc_train: 1.000, auc_valid:0.930, time: 0.41 sec\n",
      "epoch 14, cross_loss: 0.184, auc_train: 1.000, auc_valid:0.910, time: 0.41 sec\n",
      "epoch 15, cross_loss: 0.084, auc_train: 1.000, auc_valid:0.907, time: 0.41 sec\n",
      "epoch 16, cross_loss: 0.185, auc_train: 1.000, auc_valid:0.907, time: 0.41 sec\n",
      "epoch 17, cross_loss: 0.042, auc_train: 1.000, auc_valid:0.905, time: 0.41 sec\n",
      "epoch 18, cross_loss: 0.117, auc_train: 1.000, auc_valid:0.907, time: 0.41 sec\n",
      "epoch 19, cross_loss: 0.266, auc_train: 1.000, auc_valid:0.907, time: 0.41 sec\n",
      "doing: CGN_3_layer_64_channel_emb_32_dropout 500 2\n",
      "Doing drop-out\n",
      "epoch 0, cross_loss: 0.693, auc_train: 0.892, auc_valid:0.830, time: 0.41 sec\n",
      "epoch 1, cross_loss: 0.759, auc_train: 0.949, auc_valid:0.900, time: 0.41 sec\n",
      "epoch 2, cross_loss: 0.708, auc_train: 0.970, auc_valid:0.943, time: 0.41 sec\n",
      "epoch 3, cross_loss: 0.673, auc_train: 0.980, auc_valid:0.953, time: 0.41 sec\n",
      "epoch 4, cross_loss: 0.682, auc_train: 0.983, auc_valid:0.952, time: 0.41 sec\n",
      "epoch 5, cross_loss: 0.633, auc_train: 0.980, auc_valid:0.960, time: 0.49 sec\n",
      "epoch 6, cross_loss: 0.608, auc_train: 0.982, auc_valid:0.965, time: 0.41 sec\n",
      "epoch 7, cross_loss: 0.588, auc_train: 0.983, auc_valid:0.970, time: 0.41 sec\n",
      "epoch 8, cross_loss: 0.525, auc_train: 0.987, auc_valid:0.965, time: 0.41 sec\n",
      "epoch 9, cross_loss: 0.330, auc_train: 0.989, auc_valid:0.970, time: 0.41 sec\n",
      "epoch 10, cross_loss: 0.198, auc_train: 0.993, auc_valid:0.970, time: 0.41 sec\n"
     ]
    }
   ],
   "source": [
    "method_comparison(results, tcgatissue, m, gene=\"RPL5\", search_num_genes=[100,200,500,1000, 1500, 2000], trials=5, search_train_size=[100], test_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#pickle.dump(results, open(\"results2.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#results = pickle.load(open(\"results.pkl\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#results[\"df\"] = results[\"df\"].drop(results[\"df\"][results[\"df\"].num_genes == 56].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_name</th>\n",
       "      <th>model</th>\n",
       "      <th>train_size</th>\n",
       "      <th>num_genes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">RPL5</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">CGN_3_layer_64_channel_emb_32_dropout</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">200</th>\n",
       "      <th>100</th>\n",
       "      <td>0.932477</td>\n",
       "      <td>0.013174</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.939379</td>\n",
       "      <td>0.010205</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.941932</td>\n",
       "      <td>0.008958</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.932656</td>\n",
       "      <td>0.009829</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">MLP-dropout</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">200</th>\n",
       "      <th>100</th>\n",
       "      <td>0.927516</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.928672</td>\n",
       "      <td>0.010674</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.930138</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.917372</td>\n",
       "      <td>0.012166</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          mean  \\\n",
       "gene_name model                                 train_size num_genes             \n",
       "RPL5      CGN_3_layer_64_channel_emb_32_dropout 200        100        0.932477   \n",
       "                                                           200        0.939379   \n",
       "                                                           500        0.941932   \n",
       "                                                           1000       0.932656   \n",
       "          MLP-dropout                           200        100        0.927516   \n",
       "                                                           200        0.928672   \n",
       "                                                           500        0.930138   \n",
       "                                                           1000       0.917372   \n",
       "\n",
       "                                                                           std  \\\n",
       "gene_name model                                 train_size num_genes             \n",
       "RPL5      CGN_3_layer_64_channel_emb_32_dropout 200        100        0.013174   \n",
       "                                                           200        0.010205   \n",
       "                                                           500        0.008958   \n",
       "                                                           1000       0.009829   \n",
       "          MLP-dropout                           200        100        0.005014   \n",
       "                                                           200        0.010674   \n",
       "                                                           500        0.002825   \n",
       "                                                           1000       0.012166   \n",
       "\n",
       "                                                                      count  \n",
       "gene_name model                                 train_size num_genes         \n",
       "RPL5      CGN_3_layer_64_channel_emb_32_dropout 200        100            3  \n",
       "                                                           200            3  \n",
       "                                                           500            3  \n",
       "                                                           1000           3  \n",
       "          MLP-dropout                           200        100            3  \n",
       "                                                           200            3  \n",
       "                                                           500            3  \n",
       "                                                           1000           3  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = results[\"df\"].groupby(['gene_name', 'model','train_size','num_genes'])['auc'].agg(['mean','std', 'count'])\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#results[\"df\"].groupby(['gene_name', 'model','num_genes'])['auc'].mean().groupby([\"model\"]).plot(legend=True, sharex=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>train_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CGN_3_layer_64_channel_emb_32_dropout</th>\n",
       "      <th>200</th>\n",
       "      <td>0.939379</td>\n",
       "      <td>0.010205</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-dropout</th>\n",
       "      <th>200</th>\n",
       "      <td>0.928672</td>\n",
       "      <td>0.010674</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       auc                \n",
       "                                                      mean       std count\n",
       "model                                 train_size                          \n",
       "CGN_3_layer_64_channel_emb_32_dropout 200         0.939379  0.010205     3\n",
       "MLP-dropout                           200         0.928672  0.010674     3"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"df\"][results[\"df\"].num_genes==200].groupby(['model','train_size']).agg(['mean','std', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEXCAYAAACQ3VJYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f02fecfcb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "for model in results[\"df\"][\"model\"].unique():\n",
    "    q = results[\"df\"][results[\"df\"].num_genes==500].groupby(['model','train_size'])['auc']\n",
    "    index = q.mean()[model].index\n",
    "    mean = q.mean()[model]\n",
    "    stderr = q.std()[model]/np.sqrt(q.count()[model])\n",
    "    plt.errorbar(index, mean,label=model, xerr=0, yerr=stderr)\n",
    "\n",
    "plt.title(\"Gene Inference with varying numbers of nodes\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlabel(\"train_size\")\n",
    "#plt.xscale(\"log\")\n",
    "plt.xticks(index)\n",
    "formatter = matplotlib.ticker.ScalarFormatter()\n",
    "plt.gca().xaxis.set_major_formatter(formatter)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0315894850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "for model in results[\"df\"][\"model\"].unique():\n",
    "    q = results[\"df\"][results[\"df\"].train_size==200].groupby(['model','num_genes'])['auc']\n",
    "    index = q.mean()[model].index\n",
    "    mean = q.mean()[model]\n",
    "    stderr = q.std()[model]/np.sqrt(q.count()[model])\n",
    "    plt.errorbar(index, mean,label=model, xerr=0, yerr=stderr)\n",
    "\n",
    "plt.title(\"Gene Inference with varying numbers of nodes\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlabel(\"number of nodes\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xticks(sorted(results[\"df\"][\"num_genes\"].unique()))\n",
    "formatter = matplotlib.ticker.ScalarFormatter()\n",
    "plt.gca().xaxis.set_major_formatter(formatter)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff76ebf4110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "for model in results[\"df\"][\"model\"].unique():\n",
    "    index = results[\"df\"].groupby(['model','num_genes'])['auc'].mean()[model].index\n",
    "    mean = results[\"df\"].groupby(['model','num_genes'])['auc'].mean()[model]\n",
    "    stderr = results[\"df\"].groupby(['model','num_genes'])['auc'].std()[model]\n",
    "    plt.errorbar(index, mean,label=model, xerr=0, yerr=stderr)\n",
    "\n",
    "plt.title(\"Gene Inference with varying numbers of nodes\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlabel(\"number of nodes\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xticks(sorted(results[\"df\"][\"num_genes\"].unique()))\n",
    "formatter = matplotlib.ticker.ScalarFormatter()\n",
    "plt.gca().xaxis.set_major_formatter(formatter)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#results_df = pd.DataFrame(columns=['model', 'num_genes', 'gene_name', 'auc', 'std'])\n",
    "#results_df = results_df.append(data=pd.DataFrame(pd.DataFrame(data={'model':\"LR\", 'num_genes': 10.0, 'gene_name': \"RPL5\", 'auc':0.57, 'std': 0.01}, index=[0]))\n",
    "len([\"LR\", \"MLP\", \"Decision Tree\", \"CGN_3_layer_64_channel_emb_32_dropout\", \"LR\", \"MLP\", \"Decision Tree\", \"CGN_3_layer_64_channel_emb_32_dropout\", \"LR\", \"MLP\", \"Decision Tree\", \"CGN_3_layer_64_channel_emb_32_dropout\", \"LR\", \"MLP\", \"Decision Tree\", \"CGN_3_layer_64_channel_emb_32_dropout\", \"LR\", \"MLP\", \"Decision Tree\", \"CGN_3_layer_64_channel_emb_32_dropout\", \"LR\", \"MLP\", \"Decision Tree\", \"CGN_3_layer_64_channel_emb_32_dropout\"])\n",
    "len([10.0, 10.0, 10.0, 10.0, 510.0, 510.0, 510.0, 510.0, 1010.0, 1010.0, 1010.0, 1010.0, 1510.0, 1510.0, 1510.0, 1510.0, 2010.0, 2010.0, 2010.0, 2010.0, 2510.0, 2510.0, 2510.0, 2510.0, 3010.0, 3010.0, 3010.0, 3010.0])\n",
    "len([0.57, 0.56, 0.55, 0.64, 0.81, 0.83, .79, .94, .81, .80, .78, .94, .80, .74, .77, .93, .78, .79, .78, .92, .77, .77, .76, .92, .76, .71, .76, .92])\n",
    "len([0.01, 0.04, 0.03, 0.01, 0.02, 0.01, 0.03, 0.00, 0.01, 0.03, 0.02, 0.01, 0.03, 0.12, 0.02, 0.00, 0.03, 0.02, 0.03, 0.01, 0.02, 0.05, 0.04, 0.01, 0.02 ,0.11, 0.02, 0.00])\n",
    "results_df = pd.DataFrame(data={'model':[\"LR\", \"MLP\", \"Decision Tree\", \"CGN_3_layer_64_channel_emb_32_dropout\", \"LR\", \"MLP\", \"Decision Tree\", \"CGN_3_layer_64_channel_emb_32_dropout\", \"LR\", \"MLP\", \"Decision Tree\", \"CGN_3_layer_64_channel_emb_32_dropout\", \"LR\", \"MLP\", \"Decision Tree\", \"CGN_3_layer_64_channel_emb_32_dropout\", \"LR\", \"MLP\", \"Decision Tree\", \"CGN_3_layer_64_channel_emb_32_dropout\", \"LR\", \"MLP\", \"Decision Tree\", \"CGN_3_layer_64_channel_emb_32_dropout\", \"LR\", \"MLP\", \"Decision Tree\", \"CGN_3_layer_64_channel_emb_32_dropout\"],\n",
    "                   'num_genes': [10.0, 10.0, 10.0, 10.0, 510.0, 510.0, 510.0, 510.0, 1010.0, 1010.0, 1010.0, 1010.0, 1510.0, 1510.0, 1510.0, 1510.0, 2010.0, 2010.0, 2010.0, 2010.0, 2510.0, 2510.0, 2510.0, 2510.0, 3010.0, 3010.0, 3010.0, 3010.0],\n",
    "#                  'gene_name': [\"RPL5\", \"RPL5\"],\n",
    "                   'auc': [0.57, 0.56, 0.55, 0.64, 0.81, 0.83, .79, .94, .81, .80, .78, .94, .80, .74, .77, .93, .78, .79, .78, .92, .77, .77, .76, .92, .76, .71, .76, .92],\n",
    "                   'std': [0.01, 0.04, 0.03, 0.01, 0.02, 0.01, 0.03, 0.00, 0.01, 0.03, 0.02, 0.01, 0.03, 0.12, 0.02, 0.00, 0.03, 0.02, 0.03, 0.01, 0.02, 0.05, 0.04, 0.01, 0.02 ,0.11, 0.02, 0.00]}, index=range(0, 28))\n",
    "plt.figure()\n",
    "titles = []\n",
    "for model in [\n",
    "    {'key': 'LR', 'method': lr},\n",
    "    {'key': 'MLP', 'method': mlp},\n",
    "    {'key': 'Decision Tree', 'method': decision_tree},\n",
    "    {'key': 'CGN_3_layer_64_channel_emb_32_dropout', 'method': cgn_loop, 'num_channel': 64, 'num_layer': 3, 'add_emb': 32, 'use_gate': False, 'dropout': True, 'cuda': True},\n",
    "    ]:\n",
    "    temp_results = results_df.loc[results_df['model'] == model['key']].reset_index(drop=True)\n",
    "    lines.append(plt.errorbar(temp_results.index, temp_results['auc'], xerr=0, yerr=temp_results['std'])[0])\n",
    "    titles.append(model['key'])\n",
    "    plt.xticks(list(temp_results.index), temp_results['num_genes'], rotation=70)\n",
    "width = 0.2\n",
    "plt.title(\"Inferring the value of RPL5 with varying numbers of genes\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlabel(\"# genes\")\n",
    "plt.legend(lines, titles, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results of adding Nodes\n",
    "plt.figure()\n",
    "\n",
    "#full_results.loc[full_results['samples'] == 100]\n",
    "\n",
    "line1 = plt.errorbar(lr_results.index, lr_results['auc'], xerr=0, yerr=lr_results['std'])\n",
    "line2 = plt.errorbar(cgn_results.index, cgn_results['auc'], xerr=0, yerr=cgn_results['std'])\n",
    "\n",
    "width = 0.2\n",
    "plt.xticks(list(lr_results.iloc[::5, :].index), lr_results.iloc[::5, :]['num_genes'], rotation=70)\n",
    "plt.title(\"Gene Inference with varying numbers of nodes\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlabel(\"number of nodes\")\n",
    "plt.legend((line1[0], line2[0]), ('LR', \"CGN\"), bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict a gene from a growing number of Nodes\n",
    "lr_results = pd.DataFrame([])\n",
    "mlp_results = pd.DataFrame([])\n",
    "cgn_results = pd.DataFrame([])\n",
    "gene = \"RPL5\"\n",
    "max_samples = 200\n",
    "reload(data)\n",
    "reload(models)\n",
    "tcgatissue = data.gene_datasets.TCGATissue(data_dir='./genomics/TCGA/', data_file='TCGA_tissue_ppi.hdf5')\n",
    "\n",
    "for num_samples in range(10, max_samples, 20):\n",
    "    lr_row = infer_gene(lr, tcgatissue, \"RPL5\", train_size=num_samples, test_size=200, trials=3, penalty=True)\n",
    "    lr_results = lr_results.append(lr_row).reset_index(drop=True)\n",
    "    lr_results.loc[lr_results.index[-1], 'num_samples'] = num_samples\n",
    "    cgn_row = infer_gene(cgn, tcgatissue, \"RPL5\", train_size=num_samples, test_size=200, trials=3, penalty=True)\n",
    "    cgn_results = cgn_results.append(cgn_row).reset_index(drop=True)\n",
    "    cgn_results.loc[lr_results.index[-1], 'num_samples'] = num_samples\n",
    "    print num_genes\n",
    "    print cgn_results\n",
    "    print lr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results of adding Nodes\n",
    "plt.figure()\n",
    "\n",
    "#full_results.loc[full_results['samples'] == 100]\n",
    "\n",
    "line1 = plt.errorbar(lr_results.index, lr_results['auc'], xerr=0, yerr=lr_results['std'])\n",
    "line2 = plt.errorbar(cgn_results.index, cgn_results['auc'], xerr=0, yerr=cgn_results['std'])\n",
    "\n",
    "width = 0.2\n",
    "plt.xticks(list(lr_results.iloc[::5, :].index), lr_results.iloc[::5, :]['num_samples'], rotation=70)\n",
    "plt.title(\"Gene Inference with varying numbers of samples\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlabel(\"number of samples\")\n",
    "plt.legend((line1[0], line2[0]), ('LR', \"CGN\"), bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
