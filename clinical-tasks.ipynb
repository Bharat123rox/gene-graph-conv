{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import sklearn\n",
    "import torch\n",
    "import datetime\n",
    "import matplotlib, matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from models.model_wrapper import MLP\n",
    "from data import datasets\n",
    "from data.gene_graphs import GeneManiaGraph, RegNetGraph\n",
    "from data.utils import record_result\n",
    "from data.clinical.datasets import TCGADataset, Task\n",
    "from data.clinical import taskloader\n",
    "from data.clinical import split_dataset\n",
    "\n",
    "from models.model_wrapper import MLP, GCN, SLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>auc</th>\n",
       "      <th>gene</th>\n",
       "      <th>model</th>\n",
       "      <th>graph</th>\n",
       "      <th>seed</th>\n",
       "      <th>train_size</th>\n",
       "      <th>optimize_graph_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_EVENT-BRCA</td>\n",
       "      <td>0.503511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GCN_lay20_chan32_emb32_dropout_pool_kmeans</td>\n",
       "      <td>genemania</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_EVENT-BRCA</td>\n",
       "      <td>0.527005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GCN_lay20_chan32_emb32_dropout_pool_kmeans</td>\n",
       "      <td>genemania</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_EVENT-BRCA</td>\n",
       "      <td>0.507555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GCN_lay20_chan32_emb32_dropout_pool_kmeans</td>\n",
       "      <td>genemania</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          task       auc  gene                                       model  \\\n",
       "0  _EVENT-BRCA  0.503511   NaN  GCN_lay20_chan32_emb32_dropout_pool_kmeans   \n",
       "1  _EVENT-BRCA  0.527005   NaN  GCN_lay20_chan32_emb32_dropout_pool_kmeans   \n",
       "2  _EVENT-BRCA  0.507555   NaN  GCN_lay20_chan32_emb32_dropout_pool_kmeans   \n",
       "\n",
       "       graph seed train_size optimize_graph_results  \n",
       "0  genemania    0         50                   None  \n",
       "1  genemania    1         50                   None  \n",
       "2  genemania    2         50                   None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torrent name: TCGA_tissue_ppi.hdf5, Size: 1748.32MB\n"
     ]
    }
   ],
   "source": [
    "tcga = TCGADataset()\n",
    "task_id = \"_EVENT-BRCA\"\n",
    "tasks = [Task(tcga, task_id, limit=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torrent name: genemania.pkl, Size: 9.61MB\n",
      "Checking for pieces on disk: |██████████████████████████████████████████████████| 100.0% \n",
      "Found 294 finished pieces out of 294 total pieces.\n",
      "Found dataset at /home/martin_clyde_weiss/.academictorrents-datastore/genemania.pkl\n"
     ]
    }
   ],
   "source": [
    "graphs = {\"genemania\": GeneManiaGraph()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Checkpointed Results\n"
     ]
    }
   ],
   "source": [
    "# Setup the results dictionary\n",
    "filename = \"experiments/results/graph-gen-clinical.pkl\"\n",
    "try:\n",
    "    results = pickle.load(open(filename, \"rb\"), encoding='latin1')\n",
    "    print(\"Loaded Checkpointed Results\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    results = pd.DataFrame(columns=['task', 'auc', 'gene', 'model', 'graph', 'seed', 'train_size', 'optimize_graph_results'])\n",
    "    print(\"Created a New Results Dictionary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 50\n",
    "test_size = 500\n",
    "trials = 3\n",
    "cuda = False\n",
    "models = [           \n",
    "              GCN(name=\"GCN_lay20_chan32_emb32_dropout_pool_kmeans\", cuda=cuda, num_layer=4, channels=32, embedding=32, prepool_extralayers=5, pooling=\"kmeans\"),\n",
    "              GCN(name=\"GCN_lay20_chan32_emb32_dropout_pool_hierarchy\", cuda=cuda, num_layer=4, channels=32, embedding=32, prepool_extralayers=5, pooling=\"hierarchy\"),\n",
    "              GCN(name=\"GCN_lay20_chan32_emb32_dropout_pool_random\", cuda=cuda, num_layer=4, channels=32, embedding=32, prepool_extralayers=5, pooling=\"random\"),\n",
    "              MLP(name=\"MLP_lay2_chan512_dropout\", cuda=cuda, dropout=True, num_layer=2, channels=512),\n",
    "              MLP(name=\"MLP_lay2_chan512\", cuda=cuda, dropout=False, num_layer=2, channels=512),\n",
    "              SLR(name=\"SLR_lambda1_l11\", cuda=cuda)\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todo: 18\n",
      "done: 0\n"
     ]
    }
   ],
   "source": [
    "# Create the set of all experiment ids and see which are left to do\n",
    "columns = [\"task\", \"graph\", \"model\", \"seed\", \"train_size\"]\n",
    "all_exp_ids = [x for x in itertools.product(tasks, graphs.keys(), models, range(trials), [train_size])]\n",
    "all_exp_ids = pd.DataFrame(all_exp_ids, columns=columns)\n",
    "all_exp_ids.index = [\"-\".join(map(str, tup[1:])) for tup in all_exp_ids.itertuples(name=None)]\n",
    "results_exp_ids = results[columns].copy()\n",
    "results_exp_ids.index = [\"-\".join(map(str, tup[1:])) for tup in results_exp_ids.itertuples(name=None)]\n",
    "intersection_ids = all_exp_ids.index.intersection(results_exp_ids.index)\n",
    "todo = all_exp_ids.drop(intersection_ids).to_dict(orient=\"records\")\n",
    "\n",
    "print(\"todo: \" + str(len(todo)))\n",
    "print(\"done: \" + str(len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_graph(model, gene_graph, gene, X_train, X_test, y_train, y_test):\n",
    "    neighbors = list(gene_graph.first_degree(gene)[0])\n",
    "    neighbors = [n for n in neighbors if n in X_train.columns.values]\n",
    "    res = {}\n",
    "    for neighbor in neighbors:\n",
    "        candidate_nodes = neighbors if gene == neighbor else set(neighbors) - set(neighbor)\n",
    "        x_train = X_train.loc[:, candidate_nodes].copy()\n",
    "        x_test = X_test.loc[:, candidate_nodes].copy()\n",
    "        x_train[gene] = 1\n",
    "        x_test[gene] = 1\n",
    "\n",
    "        try:\n",
    "            model.fit(x_train, y_train)\n",
    "            x_test = Variable(torch.FloatTensor(np.expand_dims(x_test.values, axis=2)), requires_grad=False).float()\n",
    "            if cuda:\n",
    "                x_test = x_test.cuda()\n",
    "            y_hat = model.predict(x_test)[:, 1].data.cpu().numpy()\n",
    "            auc = sklearn.metrics.roc_auc_score(y_test, np.asarray(y_hat).flatten())\n",
    "            res[neighbor] = auc\n",
    "            model.best_model = None # cleanup\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "optimize_graph_results = []\n",
    "\n",
    "for row in todo:\n",
    "    if len(results) % 10 == 0:\n",
    "        print(len(results))\n",
    "    task = row[\"task\"]\n",
    "    graph_name = row[\"graph\"]\n",
    "    seed = row[\"seed\"]\n",
    "    model = row[\"model\"]\n",
    "\n",
    "    experiment = {\n",
    "        \"task\": task.id,\n",
    "        \"model\": model.name,\n",
    "        \"graph\": graph_name,\n",
    "        \"seed\": seed,\n",
    "        \"train_size\": train_size,\n",
    "        \"optimize_graph_results\": None,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = sklearn.model_selection.\\\n",
    "            train_test_split(task.data, task.labels, stratify=task.labels, \n",
    "                             train_size=train_size, test_size=test_size)\n",
    "    except ValueError:\n",
    "        import pdb; pdb.set_trace()\n",
    "        results = record_result(results, experiment, filename)\n",
    "        continue\n",
    "\n",
    "    X_train = X_train.copy()\n",
    "    X_test = X_test.copy()\n",
    "\n",
    "    try:\n",
    "        gene_graph = graphs[graph_name]\n",
    "        adj = np.asarray(nx.to_numpy_matrix(gene_graph.nx_graph))\n",
    "        model.fit(X_train, y_train.astype(\"uint8\"), adj=adj)\n",
    "\n",
    "        x_test = Variable(torch.FloatTensor(np.expand_dims(X_test.values, axis=2)), requires_grad=False).float()\n",
    "        if cuda:\n",
    "            x_test = x_test.cuda()\n",
    "        y_hat = model.predict(x_test)[:, 1].data.cpu().numpy()\n",
    "        auc = sklearn.metrics.roc_auc_score(y_test.astype(\"uint8\"), np.asarray(y_hat).flatten())\n",
    "        model.best_model = None # cleanup\n",
    "        experiment[\"auc\"] = auc\n",
    "    except Exception as e:\n",
    "        import pdb; pdb.set_trace()\n",
    "        print(e)\n",
    "        \n",
    "    results = record_result(results, experiment, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "adj = np.asarray(nx.to_numpy_matrix((graphs[\"genemania\"].nx_graph)))\n",
    "ids = KMeans(n_clusters=1000, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=-1, algorithm='auto').fit(adj[:2000, :2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = KMeans(n_clusters=1000, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=-1, algorithm='auto').fit(adj[:2000, :2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin_clyde_weiss/gene-graph-conv/venv/lib/python3.5/site-packages/sklearn/cluster/hierarchical.py:244: UserWarning: the number of connected components of the connectivity matrix is 94 > 1. Completing it to avoid stopping the tree early.\n",
      "  affinity='euclidean')\n"
     ]
    }
   ],
   "source": [
    "ids = sklearn.cluster.AgglomerativeClustering(n_clusters=50, affinity='euclidean',\n",
    "                                                     memory='.cache', connectivity=(adj[:100, :100] > 0.).astype(int),\n",
    "                                                     compute_full_tree='auto', linkage='ward').fit_predict(adj[:100, :100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  6,  6,  6,  1,  1,  1, 31,  1,  2, 39,  2,  2,  2,  0,  0,  0,\n",
       "        0, 49, 49, 29, 29, 48, 48, 30, 30, 23, 23, 45, 45, 46, 46, 14, 14,\n",
       "       22, 22, 28, 28, 35, 44, 44, 13, 13, 21, 21, 10, 10, 42, 42, 24, 24,\n",
       "       41, 41, 32, 32, 40, 40, 26, 26, 19, 19, 15, 15, 38, 38, 12, 12, 37,\n",
       "       27, 33, 37, 11, 11, 36, 47, 25, 36, 20, 20, 17, 17,  9,  9, 34, 34,\n",
       "       18, 18, 16, 16,  4, 43,  4,  7,  7,  8,  8,  3,  3,  5,  5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
