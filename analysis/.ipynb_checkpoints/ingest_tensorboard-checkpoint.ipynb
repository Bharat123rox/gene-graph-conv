{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# walk the experiment directory\n",
    "all_experiments = {}\n",
    "for root, dirs, files in os.walk('../experiments/experiments'):\n",
    "    experiment = defaultdict(dict)\n",
    "    for f in files:\n",
    "        key = '/'.join(root.split('/')[1:-1])    \n",
    "        trial = root.split('/')[-1]\n",
    "        if f == \"options.pkl\":\n",
    "            opts = vars(pickle.load(open(os.path.join(root, f), 'rb')))\n",
    "            experiment = all_experiments.get(key, defaultdict(dict))\n",
    "            experiment[trial]['opts'] = opts\n",
    "            all_experiments[key] = experiment\n",
    "        elif f.startswith(\"event\"):\n",
    "            experiment = all_experiments.get(key, defaultdict(dict))\n",
    "            experiment[trial]['event_accumulator'] = EventAccumulator(os.path.join(root, f))\n",
    "            all_experiments[key] = experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_experiments(experiments):\n",
    "    accumulators = []\n",
    "    for exp in experiments.values():\n",
    "        if exp.values()[0].get('event_accumulator') is not None:\n",
    "            accumulators.append(exp)\n",
    "    return accumulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiments = filter_experiments(all_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_trial_df(trial):\n",
    "    scalar_tags = trial['event_accumulator'].Reload().Tags()['scalars']\n",
    "    opt_tags = trial['opts'].keys()\n",
    "    my_tags = ['auc_train', 'auc_valid', 'auc_test', 'acc_train', 'acc_valid', 'acc_test']\n",
    "    df = pd.DataFrame(columns=opt_tags + my_tags)\n",
    "    event_accumulator = trial['event_accumulator'].Reload()\n",
    "    for tag in my_tags:\n",
    "        # scalars = np.array(map(lambda x: x.value, events))\n",
    "        print len(event_accumulator.Scalars(tag))\n",
    "        df.loc[0, tag] = event_accumulator.Scalars(tag)[0].value\n",
    "    for tag in opt_tags:\n",
    "        df.loc[0, tag] = trial['opts'][tag]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-57-2018531d84ea>(6)<module>()->None\n",
      "-> if exp_df is not None:\n",
      "(Pdb) c\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "> <ipython-input-57-2018531d84ea>(5)<module>()->None\n",
      "-> import pdb; pdb.set_trace()\n",
      "(Pdb) c\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "> <ipython-input-57-2018531d84ea>(6)<module>()->None\n",
      "-> if exp_df is not None:\n",
      "(Pdb) c\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "> <ipython-input-57-2018531d84ea>(5)<module>()->None\n",
      "-> import pdb; pdb.set_trace()\n",
      "(Pdb) c\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "> <ipython-input-57-2018531d84ea>(6)<module>()->None\n",
      "-> if exp_df is not None:\n",
      "(Pdb) c\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "> <ipython-input-57-2018531d84ea>(5)<module>()->None\n",
      "-> import pdb; pdb.set_trace()\n",
      "(Pdb) c\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "> <ipython-input-57-2018531d84ea>(6)<module>()->None\n",
      "-> if exp_df is not None:\n",
      "(Pdb) c\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "> <ipython-input-57-2018531d84ea>(5)<module>()->None\n",
      "-> import pdb; pdb.set_trace()\n",
      "(Pdb) c\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "> <ipython-input-57-2018531d84ea>(6)<module>()->None\n",
      "-> if exp_df is not None:\n",
      "(Pdb) c\n",
      "16\n",
      "16\n",
      "15\n",
      "16\n",
      "16\n",
      "15\n",
      "> <ipython-input-57-2018531d84ea>(5)<module>()->None\n",
      "-> import pdb; pdb.set_trace()\n",
      "(Pdb) raw_df\n",
      "           acc_test         acc_train         acc_valid add_connectivity  \\\n",
      "0             [0.5]             [0.5]             [0.5]          [False]   \n",
      "0             [0.5]             [0.5]             [0.5]          [False]   \n",
      "0             [0.5]             [0.5]             [0.5]          [False]   \n",
      "0             [0.5]             [0.5]             [0.5]          [False]   \n",
      "0  [0.809751451015]  [0.812749028206]  [0.801147222519]          [False]   \n",
      "0  [0.568181812763]  [0.640151500702]  [0.693181812763]          [False]   \n",
      "0  [0.534090936184]  [0.681818187237]   [0.54545456171]          [False]   \n",
      "0  [0.853728473186]  [0.857370495796]  [0.854206502438]          [False]   \n",
      "0  [0.823135733604]  [0.821035861969]  [0.809751451015]          [False]   \n",
      "\n",
      "  add_self approx_nb_edges attention_layer          auc_test  \\\n",
      "0   [True]           [100]             [0]  [0.769999980927]   \n",
      "0   [True]           [100]             [0]  [0.660000026226]   \n",
      "0   [True]           [100]             [0]  [0.550000011921]   \n",
      "0   [True]           [100]             [0]  [0.579999983311]   \n",
      "0   [True]           [100]             [0]  [0.895529270172]   \n",
      "0   [True]           [100]             [0]  [0.597916662693]   \n",
      "0   [True]           [100]             [0]  [0.494791656733]   \n",
      "0   [True]           [100]             [0]  [0.903011262417]   \n",
      "0   [True]           [100]             [0]  [0.886131167412]   \n",
      "\n",
      "          auc_train         auc_valid     ...        pool_graph scale_free  \\\n",
      "0   [0.79777777195]  [0.449999988079]     ...       [hierarchy]    [False]   \n",
      "0  [0.916666686535]  [0.469999998808]     ...       [hierarchy]    [False]   \n",
      "0  [0.889999985695]  [0.519999980927]     ...       [hierarchy]    [False]   \n",
      "0  [0.938888907433]  [0.519999980927]     ...       [hierarchy]    [False]   \n",
      "0  [0.894950389862]  [0.891105175018]     ...            [None]    [False]   \n",
      "0  [0.654824674129]  [0.623211443424]     ...            [None]    [False]   \n",
      "0  [0.648565649986]  [0.569157421589]     ...            [None]    [False]   \n",
      "0  [0.909482777119]  [0.919162809849]     ...            [None]    [False]   \n",
      "0  [0.893820464611]  [0.879856228828]     ...            [None]    [False]   \n",
      "\n",
      "     seed size_perc               tensorboard_dir train_ratio trial_number  \\\n",
      "0     [1]       [4]  [./experiments/experiments/]       [0.6]          [1]   \n",
      "0  [1993]       [4]  [./experiments/experiments/]       [0.6]          [1]   \n",
      "0     [2]       [4]  [./experiments/experiments/]       [0.6]          [1]   \n",
      "0     [3]       [4]  [./experiments/experiments/]       [0.6]          [1]   \n",
      "0  [1993]       [4]  [./experiments/experiments/]       [0.6]          [1]   \n",
      "0  [1993]       [4]  [./experiments/experiments/]       [0.6]          [1]   \n",
      "0  [1993]       [4]  [./experiments/experiments/]       [0.6]          [1]   \n",
      "0  [1993]       [4]  [./experiments/experiments/]       [0.6]          [1]   \n",
      "0  [1993]       [4]  [./experiments/experiments/]       [0.6]          [1]   \n",
      "\n",
      "  use_emb use_gate weight_decay  \n",
      "0    [16]    [0.0]        [0.0]  \n",
      "0    [16]    [0.0]        [0.0]  \n",
      "0    [16]    [0.0]        [0.0]  \n",
      "0    [16]    [0.0]        [0.0]  \n",
      "0  [None]    [0.0]        [0.0]  \n",
      "0  [None]    [0.0]        [0.0]  \n",
      "0  [None]    [0.0]        [0.0]  \n",
      "0  [None]    [0.0]        [0.0]  \n",
      "0  [None]    [0.0]        [0.0]  \n",
      "\n",
      "[9 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "raw_df = None\n",
    "for exp in experiments:\n",
    "    exp_df = None\n",
    "    for key, trial in exp.iteritems():\n",
    "        import pdb; pdb.set_trace()\n",
    "        if exp_df is not None:\n",
    "            exp_df = exp_df.append(make_trial_df(trial))\n",
    "        else:\n",
    "            exp_df = make_trial_df(trial)\n",
    "    if raw_df is not None:   \n",
    "        raw_df = raw_df.append(exp_df)\n",
    "    else:\n",
    "        raw_df = exp_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [acc_test, acc_train, acc_valid, add_connectivity, add_self, approx_nb_edges, attention_layer, auc_test, auc_train, auc_valid, batch_size, center, clinical_file, clinical_label, cuda, dataset, disconnected, dropout, epoch, extra_cn, extra_ucn, graph, l1_loss_lambda, load_checkpoint, load_folder, log, lr, model, model_reg_lambda, momentum, name, nb_attention_head, nb_class, nb_examples, nb_nodes, nb_per_class, neighborhood, norm_adj, num_channel, num_layer, percentile, pool_graph, scale_free, seed, semi_mse_lambda, size_perc, tensorboard_dir, train_ratio, training_mode, trial_number, use_emb, use_gate, weight_decay]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "print raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def take_mean(events):\n",
    "    print events\n",
    "    mean = np.array([e.value() for e in events]).mean()\n",
    "    import pdb; pdb.set_trace()\n",
    "    print mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /Tmp/lisa/os_v5/anaconda/lib/python2.7/site-packages/IPython/core/displayhook.py(236)__call__()\n",
      "-> def __call__(self, result=None):\n",
      "(Pdb) auc\n",
      "*** NameError: name 'auc' is not defined\n",
      "(Pdb) print auc\n",
      "*** NameError: name 'auc' is not defined\n",
      "(Pdb) print e\n",
      "*** NameError: name 'e' is not defined\n",
      "(Pdb) q\n"
     ]
    }
   ],
   "source": [
    "e = trial['event_accumulator']\n",
    "auc = e.Scalars('auc_train')\n",
    "take_mean(auc)\n",
    "import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trial = experiments.values()[0].values()[0]\n",
    "scalar_tags = trial['event_accumulator'].Reload().Tags()['scalars']\n",
    "opt_tags = trial['opts'].keys()\n",
    "df = pd.DataFrame(columns=opt_tags + scalar_tags)\n",
    "exp_df = pd.DataFrame(columns=opt_tags + scalar_tags)\n",
    "for path, experiment in experiments.iteritems():\n",
    "    for number, trial in experiment.iteritems():\n",
    "        import pdb; pdb.set_trace()\n",
    "\n",
    "        event_accumulator = trial['event_accumulator'].Reload()\n",
    "        for tag in scalar_tags:\n",
    "            events = event_accumulator.Scalars(tag)\n",
    "            scalars = np.array(map(lambda x: x.value, events))\n",
    "            df.loc[:, tag] = scalars\n",
    "        for tag in opt_tags:\n",
    "            df.loc[:, tag] = [trial['opts'][tag]]\n",
    "        exp_df = exp_df.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for path, experiment in experiments.iteritems():\n",
    "    for number, trial in experiment.iteritems():\n",
    "        print trial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
