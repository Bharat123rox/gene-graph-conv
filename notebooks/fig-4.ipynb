{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This file generates the data for Figure #4 from the paper https://arxiv.org/pdf/1806.06975.pdf\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import argparse\n",
    "import networkx as nx\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import sklearn\n",
    "import torch\n",
    "import datetime\n",
    "import matplotlib, matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from models.mlp import MLP\n",
    "from data import datasets\n",
    "from data.gene_graphs import GeneManiaGraph, RegNetGraph\n",
    "from data.utils import record_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting one-hot labels to integers\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.TCGADataset()\n",
    "dataset.df = dataset.df - dataset.df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = {\"regnet\": RegNetGraph(), \"genemania\": GeneManiaGraph()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Checkpointed Results\n"
     ]
    }
   ],
   "source": [
    "# Setup the results dictionary\n",
    "filename = \"../experiments/results/fig-4.pkl\"\n",
    "try:\n",
    "    results = pickle.load(open(filename, \"rb\"), encoding='latin1')\n",
    "    print(\"Loaded Checkpointed Results\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    results = pd.DataFrame(columns=['auc', 'gene', 'model', 'graph', 'is_first_degree', 'seed', 'train_size'])\n",
    "    print(\"Created a New Results Dictionary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping metric is accuracy_score\n"
     ]
    }
   ],
   "source": [
    "train_size = 50\n",
    "test_size = 1000\n",
    "trials = 3\n",
    "cuda = torch.cuda.is_available()\n",
    "models = {\"BasicMLP\": MLP(column_names=dataset.df.columns, dropout=False, cuda=cuda)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todo: 195582\n",
      "done: 33\n"
     ]
    }
   ],
   "source": [
    "# Create the set of all experiment ids and see which are left to do\n",
    "columns = [\"gene\", \"graph\", \"model\", \"seed\", \"is_first_degree\", \"train_size\"]\n",
    "all_exp_ids = [x for x in itertools.product(dataset.df.columns, graphs.keys(), models.keys(), range(trials), [True, False], [train_size])]\n",
    "all_exp_ids = pd.DataFrame(all_exp_ids, columns=columns)\n",
    "all_exp_ids.index = [\"-\".join(map(str, tup[1:])) for tup in all_exp_ids.itertuples(name=None)]\n",
    "results_exp_ids = results[columns].copy()\n",
    "results_exp_ids.index = [\"-\".join(map(str, tup[1:])) for tup in results_exp_ids.itertuples(name=None)]\n",
    "intersection_ids = all_exp_ids.index.intersection(results_exp_ids.index)\n",
    "todo = all_exp_ids.drop(intersection_ids).to_dict(orient=\"records\")\n",
    "\n",
    "print(\"todo: \" + str(len(todo)))\n",
    "print(\"done: \" + str(len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch (0/40), train loss:0.7389\n",
      "  batch (10/40), train loss:0.7404\n",
      "  batch (20/40), train loss:0.6998\n",
      "  batch (30/40), train loss:0.7252\n",
      "epoch: 0, time: 0.00, valid_metric: 0.40, train_metric: 0.35\n",
      "  batch (0/40), train loss:0.7368\n",
      "  batch (10/40), train loss:0.7388\n",
      "  batch (20/40), train loss:0.6981\n",
      "  batch (30/40), train loss:0.7242\n",
      "epoch: 1, time: 0.00, valid_metric: 0.40, train_metric: 0.35\n",
      "  batch (0/40), train loss:0.7353\n",
      "  batch (10/40), train loss:0.7374\n",
      "  batch (20/40), train loss:0.6965\n",
      "  batch (30/40), train loss:0.7232\n",
      "epoch: 2, time: 0.00, valid_metric: 0.40, train_metric: 0.35\n",
      "  batch (0/40), train loss:0.7338\n",
      "  batch (10/40), train loss:0.7360\n",
      "  batch (20/40), train loss:0.6949\n",
      "  batch (30/40), train loss:0.7221\n",
      "epoch: 3, time: 0.00, valid_metric: 0.40, train_metric: 0.38\n",
      "  batch (0/40), train loss:0.7323\n",
      "  batch (10/40), train loss:0.7347\n",
      "  batch (20/40), train loss:0.6933\n",
      "  batch (30/40), train loss:0.7209\n",
      "epoch: 4, time: 0.00, valid_metric: 0.40, train_metric: 0.38\n",
      "  batch (0/40), train loss:0.7309\n",
      "  batch (10/40), train loss:0.7333\n",
      "  batch (20/40), train loss:0.6917\n",
      "  batch (30/40), train loss:0.7198\n",
      "epoch: 5, time: 0.00, valid_metric: 0.40, train_metric: 0.38\n",
      "  batch (0/40), train loss:0.7295\n",
      "  batch (10/40), train loss:0.7320\n",
      "  batch (20/40), train loss:0.6902\n",
      "  batch (30/40), train loss:0.7187\n",
      "epoch: 6, time: 0.00, valid_metric: 0.40, train_metric: 0.40\n",
      "  batch (0/40), train loss:0.7281\n",
      "  batch (10/40), train loss:0.7307\n",
      "  batch (20/40), train loss:0.6888\n",
      "  batch (30/40), train loss:0.7175\n",
      "epoch: 7, time: 0.00, valid_metric: 0.40, train_metric: 0.40\n",
      "  batch (0/40), train loss:0.7268\n",
      "  batch (10/40), train loss:0.7294\n",
      "  batch (20/40), train loss:0.6873\n",
      "  batch (30/40), train loss:0.7164\n",
      "epoch: 8, time: 0.00, valid_metric: 0.40, train_metric: 0.40\n",
      "  batch (0/40), train loss:0.7254\n",
      "  batch (10/40), train loss:0.7281\n",
      "  batch (20/40), train loss:0.6858\n",
      "  batch (30/40), train loss:0.7153\n",
      "epoch: 9, time: 0.00, valid_metric: 0.40, train_metric: 0.40\n",
      "  batch (0/40), train loss:0.7241\n",
      "  batch (10/40), train loss:0.7268\n",
      "  batch (20/40), train loss:0.6844\n",
      "  batch (30/40), train loss:0.7143\n",
      "epoch: 10, time: 0.00, valid_metric: 0.40, train_metric: 0.42\n",
      "  batch (0/40), train loss:0.7228\n",
      "  batch (10/40), train loss:0.7256\n",
      "  batch (20/40), train loss:0.6830\n",
      "  batch (30/40), train loss:0.7133\n",
      "epoch: 11, time: 0.00, valid_metric: 0.40, train_metric: 0.40\n",
      "  batch (0/40), train loss:0.7216\n",
      "  batch (10/40), train loss:0.7243\n",
      "  batch (20/40), train loss:0.6816\n",
      "  batch (30/40), train loss:0.7124\n",
      "epoch: 12, time: 0.00, valid_metric: 0.40, train_metric: 0.40\n",
      "  batch (0/40), train loss:0.7204\n",
      "  batch (10/40), train loss:0.7231\n",
      "  batch (20/40), train loss:0.6802\n",
      "  batch (30/40), train loss:0.7114\n",
      "epoch: 13, time: 0.00, valid_metric: 0.40, train_metric: 0.40\n",
      "  batch (0/40), train loss:0.7192\n",
      "  batch (10/40), train loss:0.7221\n",
      "  batch (20/40), train loss:0.6788\n",
      "  batch (30/40), train loss:0.7105\n",
      "epoch: 14, time: 0.00, valid_metric: 0.40, train_metric: 0.42\n",
      "  batch (0/40), train loss:0.7180\n",
      "  batch (10/40), train loss:0.7210\n",
      "  batch (20/40), train loss:0.6775\n",
      "  batch (30/40), train loss:0.7096\n",
      "epoch: 15, time: 0.00, valid_metric: 0.40, train_metric: 0.42\n",
      "  batch (0/40), train loss:0.7169\n",
      "  batch (10/40), train loss:0.7200\n",
      "  batch (20/40), train loss:0.6761\n",
      "  batch (30/40), train loss:0.7087\n",
      "total train time:0.09 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.6667\n",
      "  batch (10/40), train loss:0.6663\n",
      "  batch (20/40), train loss:0.6916\n",
      "  batch (30/40), train loss:0.6485\n",
      "epoch: 0, time: 0.00, valid_metric: 0.60, train_metric: 0.75\n",
      "  batch (0/40), train loss:0.5570\n",
      "  batch (10/40), train loss:0.5184\n",
      "  batch (20/40), train loss:0.5840\n",
      "  batch (30/40), train loss:0.5408\n",
      "epoch: 1, time: 0.00, valid_metric: 0.80, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.4953\n",
      "  batch (10/40), train loss:0.4224\n",
      "  batch (20/40), train loss:0.5010\n",
      "  batch (30/40), train loss:0.4544\n",
      "epoch: 2, time: 0.00, valid_metric: 0.80, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.4366\n",
      "  batch (10/40), train loss:0.3458\n",
      "  batch (20/40), train loss:0.4209\n",
      "  batch (30/40), train loss:0.3842\n",
      "epoch: 3, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.3796\n",
      "  batch (10/40), train loss:0.2833\n",
      "  batch (20/40), train loss:0.3517\n",
      "  batch (30/40), train loss:0.3290\n",
      "epoch: 4, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.3336\n",
      "  batch (10/40), train loss:0.2343\n",
      "  batch (20/40), train loss:0.2959\n",
      "  batch (30/40), train loss:0.2852\n",
      "epoch: 5, time: 0.00, valid_metric: 0.90, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2954\n",
      "  batch (10/40), train loss:0.1939\n",
      "  batch (20/40), train loss:0.2485\n",
      "  batch (30/40), train loss:0.2506\n",
      "epoch: 6, time: 0.00, valid_metric: 0.90, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2628\n",
      "  batch (10/40), train loss:0.1620\n",
      "  batch (20/40), train loss:0.2100\n",
      "  batch (30/40), train loss:0.2233\n",
      "epoch: 7, time: 0.00, valid_metric: 0.90, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2333\n",
      "  batch (10/40), train loss:0.1355\n",
      "  batch (20/40), train loss:0.1776\n",
      "  batch (30/40), train loss:0.2006\n",
      "epoch: 8, time: 0.00, valid_metric: 0.90, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2087\n",
      "  batch (10/40), train loss:0.1145\n",
      "  batch (20/40), train loss:0.1512\n",
      "  batch (30/40), train loss:0.1822\n",
      "epoch: 9, time: 0.00, valid_metric: 0.90, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1854\n",
      "  batch (10/40), train loss:0.0968\n",
      "  batch (20/40), train loss:0.1296\n",
      "  batch (30/40), train loss:0.1666\n",
      "epoch: 10, time: 0.00, valid_metric: 0.90, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1637\n",
      "  batch (10/40), train loss:0.0823\n",
      "  batch (20/40), train loss:0.1121\n",
      "  batch (30/40), train loss:0.1524\n",
      "epoch: 11, time: 0.00, valid_metric: 0.90, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1426\n",
      "  batch (10/40), train loss:0.0705\n",
      "  batch (20/40), train loss:0.0981\n",
      "  batch (30/40), train loss:0.1427\n",
      "epoch: 12, time: 0.00, valid_metric: 0.90, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1243\n",
      "  batch (10/40), train loss:0.0611\n",
      "  batch (20/40), train loss:0.0865\n",
      "  batch (30/40), train loss:0.1348\n",
      "epoch: 13, time: 0.00, valid_metric: 0.90, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1087\n",
      "  batch (10/40), train loss:0.0536\n",
      "  batch (20/40), train loss:0.0767\n",
      "  batch (30/40), train loss:0.1283\n",
      "epoch: 14, time: 0.00, valid_metric: 0.90, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0958\n",
      "  batch (10/40), train loss:0.0473\n",
      "  batch (20/40), train loss:0.0686\n",
      "  batch (30/40), train loss:0.1225\n",
      "epoch: 15, time: 0.00, valid_metric: 0.90, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0850\n",
      "  batch (10/40), train loss:0.0421\n",
      "  batch (20/40), train loss:0.0617\n",
      "  batch (30/40), train loss:0.1175\n",
      "total train time:0.31 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.7064\n",
      "  batch (10/40), train loss:0.7316\n",
      "  batch (20/40), train loss:0.6732\n",
      "  batch (30/40), train loss:0.7204\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.40\n",
      "  batch (0/40), train loss:0.7044\n",
      "  batch (10/40), train loss:0.7295\n",
      "  batch (20/40), train loss:0.6721\n",
      "  batch (30/40), train loss:0.7189\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.40\n",
      "  batch (0/40), train loss:0.7030\n",
      "  batch (10/40), train loss:0.7274\n",
      "  batch (20/40), train loss:0.6709\n",
      "  batch (30/40), train loss:0.7174\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.40\n",
      "  batch (0/40), train loss:0.7016\n",
      "  batch (10/40), train loss:0.7255\n",
      "  batch (20/40), train loss:0.6698\n",
      "  batch (30/40), train loss:0.7159\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.40\n",
      "  batch (0/40), train loss:0.7002\n",
      "  batch (10/40), train loss:0.7235\n",
      "  batch (20/40), train loss:0.6686\n",
      "  batch (30/40), train loss:0.7144\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.42\n",
      "  batch (0/40), train loss:0.6988\n",
      "  batch (10/40), train loss:0.7216\n",
      "  batch (20/40), train loss:0.6675\n",
      "  batch (30/40), train loss:0.7130\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.6974\n",
      "  batch (10/40), train loss:0.7197\n",
      "  batch (20/40), train loss:0.6664\n",
      "  batch (30/40), train loss:0.7116\n",
      "epoch: 6, time: 0.00, valid_metric: 0.50, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.6961\n",
      "  batch (10/40), train loss:0.7178\n",
      "  batch (20/40), train loss:0.6653\n",
      "  batch (30/40), train loss:0.7102\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.6947\n",
      "  batch (10/40), train loss:0.7160\n",
      "  batch (20/40), train loss:0.6642\n",
      "  batch (30/40), train loss:0.7088\n",
      "epoch: 8, time: 0.00, valid_metric: 0.50, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.6933\n",
      "  batch (10/40), train loss:0.7142\n",
      "  batch (20/40), train loss:0.6631\n",
      "  batch (30/40), train loss:0.7073\n",
      "epoch: 9, time: 0.00, valid_metric: 0.50, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.6919\n",
      "  batch (10/40), train loss:0.7124\n",
      "  batch (20/40), train loss:0.6620\n",
      "  batch (30/40), train loss:0.7059\n",
      "epoch: 10, time: 0.00, valid_metric: 0.50, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.6905\n",
      "  batch (10/40), train loss:0.7106\n",
      "  batch (20/40), train loss:0.6610\n",
      "  batch (30/40), train loss:0.7045\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.6891\n",
      "  batch (10/40), train loss:0.7088\n",
      "  batch (20/40), train loss:0.6600\n",
      "  batch (30/40), train loss:0.7030\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.6876\n",
      "  batch (10/40), train loss:0.7070\n",
      "  batch (20/40), train loss:0.6590\n",
      "  batch (30/40), train loss:0.7016\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.6860\n",
      "  batch (10/40), train loss:0.7053\n",
      "  batch (20/40), train loss:0.6580\n",
      "  batch (30/40), train loss:0.7002\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.6845\n",
      "  batch (10/40), train loss:0.7036\n",
      "  batch (20/40), train loss:0.6570\n",
      "  batch (30/40), train loss:0.6988\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.6830\n",
      "  batch (10/40), train loss:0.7019\n",
      "  batch (20/40), train loss:0.6560\n",
      "  batch (30/40), train loss:0.6974\n",
      "total train time:0.18 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.6743\n",
      "  batch (10/40), train loss:0.6631\n",
      "  batch (20/40), train loss:0.7182\n",
      "  batch (30/40), train loss:0.6488\n",
      "epoch: 0, time: 0.00, valid_metric: 0.30, train_metric: 0.85\n",
      "  batch (0/40), train loss:0.5943\n",
      "  batch (10/40), train loss:0.4807\n",
      "  batch (20/40), train loss:0.5803\n",
      "  batch (30/40), train loss:0.5466\n",
      "epoch: 1, time: 0.00, valid_metric: 0.60, train_metric: 0.90\n",
      "  batch (0/40), train loss:0.5357\n",
      "  batch (10/40), train loss:0.3583\n",
      "  batch (20/40), train loss:0.4922\n",
      "  batch (30/40), train loss:0.4664\n",
      "epoch: 2, time: 0.00, valid_metric: 0.90, train_metric: 0.90\n",
      "  batch (0/40), train loss:0.4817\n",
      "  batch (10/40), train loss:0.2718\n",
      "  batch (20/40), train loss:0.4138\n",
      "  batch (30/40), train loss:0.3982\n",
      "epoch: 3, time: 0.00, valid_metric: 0.90, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.4178\n",
      "  batch (10/40), train loss:0.2072\n",
      "  batch (20/40), train loss:0.3476\n",
      "  batch (30/40), train loss:0.3450\n",
      "epoch: 4, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.3473\n",
      "  batch (10/40), train loss:0.1604\n",
      "  batch (20/40), train loss:0.2933\n",
      "  batch (30/40), train loss:0.3007\n",
      "epoch: 5, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2999\n",
      "  batch (10/40), train loss:0.1250\n",
      "  batch (20/40), train loss:0.2499\n",
      "  batch (30/40), train loss:0.2630\n",
      "epoch: 6, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2587\n",
      "  batch (10/40), train loss:0.0989\n",
      "  batch (20/40), train loss:0.2139\n",
      "  batch (30/40), train loss:0.2323\n",
      "epoch: 7, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2203\n",
      "  batch (10/40), train loss:0.0798\n",
      "  batch (20/40), train loss:0.1847\n",
      "  batch (30/40), train loss:0.2066\n",
      "epoch: 8, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1897\n",
      "  batch (10/40), train loss:0.0655\n",
      "  batch (20/40), train loss:0.1608\n",
      "  batch (30/40), train loss:0.1841\n",
      "epoch: 9, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1664\n",
      "  batch (10/40), train loss:0.0547\n",
      "  batch (20/40), train loss:0.1417\n",
      "  batch (30/40), train loss:0.1629\n",
      "epoch: 10, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1478\n",
      "  batch (10/40), train loss:0.0467\n",
      "  batch (20/40), train loss:0.1289\n",
      "  batch (30/40), train loss:0.1451\n",
      "epoch: 11, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1325\n",
      "  batch (10/40), train loss:0.0405\n",
      "  batch (20/40), train loss:0.1153\n",
      "  batch (30/40), train loss:0.1311\n",
      "epoch: 12, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1202\n",
      "  batch (10/40), train loss:0.0353\n",
      "  batch (20/40), train loss:0.1030\n",
      "  batch (30/40), train loss:0.1189\n",
      "epoch: 13, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1088\n",
      "  batch (10/40), train loss:0.0311\n",
      "  batch (20/40), train loss:0.0933\n",
      "  batch (30/40), train loss:0.1064\n",
      "epoch: 14, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0998\n",
      "  batch (10/40), train loss:0.0276\n",
      "  batch (20/40), train loss:0.0852\n",
      "  batch (30/40), train loss:0.0966\n",
      "epoch: 15, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0916\n",
      "  batch (10/40), train loss:0.0247\n",
      "  batch (20/40), train loss:0.0776\n",
      "  batch (30/40), train loss:0.0886\n",
      "total train time:0.32 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.7103\n",
      "  batch (10/40), train loss:0.7141\n",
      "  batch (20/40), train loss:0.7061\n",
      "  batch (30/40), train loss:0.6939\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.7080\n",
      "  batch (10/40), train loss:0.7128\n",
      "  batch (20/40), train loss:0.7045\n",
      "  batch (30/40), train loss:0.6934\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.7063\n",
      "  batch (10/40), train loss:0.7117\n",
      "  batch (20/40), train loss:0.7031\n",
      "  batch (30/40), train loss:0.6929\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.7048\n",
      "  batch (10/40), train loss:0.7106\n",
      "  batch (20/40), train loss:0.7017\n",
      "  batch (30/40), train loss:0.6923\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.7032\n",
      "  batch (10/40), train loss:0.7096\n",
      "  batch (20/40), train loss:0.7003\n",
      "  batch (30/40), train loss:0.6918\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.7017\n",
      "  batch (10/40), train loss:0.7085\n",
      "  batch (20/40), train loss:0.6989\n",
      "  batch (30/40), train loss:0.6912\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.7002\n",
      "  batch (10/40), train loss:0.7075\n",
      "  batch (20/40), train loss:0.6974\n",
      "  batch (30/40), train loss:0.6906\n",
      "epoch: 6, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6987\n",
      "  batch (10/40), train loss:0.7064\n",
      "  batch (20/40), train loss:0.6960\n",
      "  batch (30/40), train loss:0.6901\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6972\n",
      "  batch (10/40), train loss:0.7054\n",
      "  batch (20/40), train loss:0.6947\n",
      "  batch (30/40), train loss:0.6895\n",
      "epoch: 8, time: 0.00, valid_metric: 0.50, train_metric: 0.50\n",
      "  batch (0/40), train loss:0.6958\n",
      "  batch (10/40), train loss:0.7043\n",
      "  batch (20/40), train loss:0.6934\n",
      "  batch (30/40), train loss:0.6889\n",
      "epoch: 9, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.6943\n",
      "  batch (10/40), train loss:0.7033\n",
      "  batch (20/40), train loss:0.6921\n",
      "  batch (30/40), train loss:0.6884\n",
      "epoch: 10, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.6927\n",
      "  batch (10/40), train loss:0.7023\n",
      "  batch (20/40), train loss:0.6909\n",
      "  batch (30/40), train loss:0.6878\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.6912\n",
      "  batch (10/40), train loss:0.7013\n",
      "  batch (20/40), train loss:0.6896\n",
      "  batch (30/40), train loss:0.6872\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.6897\n",
      "  batch (10/40), train loss:0.7003\n",
      "  batch (20/40), train loss:0.6883\n",
      "  batch (30/40), train loss:0.6867\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.53\n",
      "  batch (0/40), train loss:0.6881\n",
      "  batch (10/40), train loss:0.6993\n",
      "  batch (20/40), train loss:0.6871\n",
      "  batch (30/40), train loss:0.6861\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6866\n",
      "  batch (10/40), train loss:0.6983\n",
      "  batch (20/40), train loss:0.6858\n",
      "  batch (30/40), train loss:0.6855\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.55\n",
      "  batch (0/40), train loss:0.6850\n",
      "  batch (10/40), train loss:0.6974\n",
      "  batch (20/40), train loss:0.6845\n",
      "  batch (30/40), train loss:0.6850\n",
      "total train time:0.09 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "40\n",
      "  batch (0/40), train loss:0.6840\n",
      "  batch (10/40), train loss:0.6772\n",
      "  batch (20/40), train loss:0.7388\n",
      "  batch (30/40), train loss:0.6466\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.80\n",
      "  batch (0/40), train loss:0.5601\n",
      "  batch (10/40), train loss:0.5781\n",
      "  batch (20/40), train loss:0.6560\n",
      "  batch (30/40), train loss:0.5594\n",
      "epoch: 1, time: 0.00, valid_metric: 0.90, train_metric: 0.90\n",
      "  batch (0/40), train loss:0.4796\n",
      "  batch (10/40), train loss:0.5085\n",
      "  batch (20/40), train loss:0.5926\n",
      "  batch (30/40), train loss:0.4882\n",
      "epoch: 2, time: 0.00, valid_metric: 0.90, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.4171\n",
      "  batch (10/40), train loss:0.4405\n",
      "  batch (20/40), train loss:0.5323\n",
      "  batch (30/40), train loss:0.4275\n",
      "epoch: 3, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.3600\n",
      "  batch (10/40), train loss:0.3800\n",
      "  batch (20/40), train loss:0.4681\n",
      "  batch (30/40), train loss:0.3655\n",
      "epoch: 4, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.3092\n",
      "  batch (10/40), train loss:0.3277\n",
      "  batch (20/40), train loss:0.4100\n",
      "  batch (30/40), train loss:0.3152\n",
      "epoch: 5, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2643\n",
      "  batch (10/40), train loss:0.2801\n",
      "  batch (20/40), train loss:0.3593\n",
      "  batch (30/40), train loss:0.2689\n",
      "epoch: 6, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2264\n",
      "  batch (10/40), train loss:0.2388\n",
      "  batch (20/40), train loss:0.3177\n",
      "  batch (30/40), train loss:0.2275\n",
      "epoch: 7, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1932\n",
      "  batch (10/40), train loss:0.2040\n",
      "  batch (20/40), train loss:0.2781\n",
      "  batch (30/40), train loss:0.1940\n",
      "epoch: 8, time: 0.01, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1648\n",
      "  batch (10/40), train loss:0.1758\n",
      "  batch (20/40), train loss:0.2421\n",
      "  batch (30/40), train loss:0.1675\n",
      "epoch: 9, time: 0.01, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1406\n",
      "  batch (10/40), train loss:0.1511\n",
      "  batch (20/40), train loss:0.2133\n",
      "  batch (30/40), train loss:0.1468\n",
      "epoch: 10, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1208\n",
      "  batch (10/40), train loss:0.1313\n",
      "  batch (20/40), train loss:0.1873\n",
      "  batch (30/40), train loss:0.1295\n",
      "epoch: 11, time: 0.01, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1053\n",
      "  batch (10/40), train loss:0.1149\n",
      "  batch (20/40), train loss:0.1651\n",
      "  batch (30/40), train loss:0.1156\n",
      "epoch: 12, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0921\n",
      "  batch (10/40), train loss:0.1012\n",
      "  batch (20/40), train loss:0.1465\n",
      "  batch (30/40), train loss:0.1027\n",
      "epoch: 13, time: 0.01, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0813\n",
      "  batch (10/40), train loss:0.0902\n",
      "  batch (20/40), train loss:0.1313\n",
      "  batch (30/40), train loss:0.0919\n",
      "epoch: 14, time: 0.01, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0723\n",
      "  batch (10/40), train loss:0.0800\n",
      "  batch (20/40), train loss:0.1194\n",
      "  batch (30/40), train loss:0.0828\n",
      "epoch: 15, time: 0.00, valid_metric: 1.00, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0644\n",
      "  batch (10/40), train loss:0.0719\n",
      "  batch (20/40), train loss:0.1083\n",
      "  batch (30/40), train loss:0.0753\n",
      "total train time:0.41 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.7345\n",
      "  batch (10/40), train loss:0.6952\n",
      "  batch (20/40), train loss:0.7460\n",
      "  batch (30/40), train loss:0.7327\n",
      "epoch: 0, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7321\n",
      "  batch (10/40), train loss:0.6950\n",
      "  batch (20/40), train loss:0.7428\n",
      "  batch (30/40), train loss:0.7303\n",
      "epoch: 1, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7296\n",
      "  batch (10/40), train loss:0.6948\n",
      "  batch (20/40), train loss:0.7397\n",
      "  batch (30/40), train loss:0.7278\n",
      "epoch: 2, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7272\n",
      "  batch (10/40), train loss:0.6946\n",
      "  batch (20/40), train loss:0.7365\n",
      "  batch (30/40), train loss:0.7254\n",
      "epoch: 3, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7248\n",
      "  batch (10/40), train loss:0.6944\n",
      "  batch (20/40), train loss:0.7333\n",
      "  batch (30/40), train loss:0.7230\n",
      "epoch: 4, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7224\n",
      "  batch (10/40), train loss:0.6942\n",
      "  batch (20/40), train loss:0.7302\n",
      "  batch (30/40), train loss:0.7206\n",
      "epoch: 5, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7200\n",
      "  batch (10/40), train loss:0.6940\n",
      "  batch (20/40), train loss:0.7271\n",
      "  batch (30/40), train loss:0.7182\n",
      "epoch: 6, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7176\n",
      "  batch (10/40), train loss:0.6939\n",
      "  batch (20/40), train loss:0.7240\n",
      "  batch (30/40), train loss:0.7159\n",
      "epoch: 7, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7153\n",
      "  batch (10/40), train loss:0.6938\n",
      "  batch (20/40), train loss:0.7209\n",
      "  batch (30/40), train loss:0.7135\n",
      "epoch: 8, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7130\n",
      "  batch (10/40), train loss:0.6936\n",
      "  batch (20/40), train loss:0.7179\n",
      "  batch (30/40), train loss:0.7112\n",
      "epoch: 9, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7107\n",
      "  batch (10/40), train loss:0.6935\n",
      "  batch (20/40), train loss:0.7149\n",
      "  batch (30/40), train loss:0.7089\n",
      "epoch: 10, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7084\n",
      "  batch (10/40), train loss:0.6934\n",
      "  batch (20/40), train loss:0.7119\n",
      "  batch (30/40), train loss:0.7067\n",
      "epoch: 11, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7061\n",
      "  batch (10/40), train loss:0.6934\n",
      "  batch (20/40), train loss:0.7089\n",
      "  batch (30/40), train loss:0.7044\n",
      "epoch: 12, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7039\n",
      "  batch (10/40), train loss:0.6933\n",
      "  batch (20/40), train loss:0.7059\n",
      "  batch (30/40), train loss:0.7022\n",
      "epoch: 13, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7016\n",
      "  batch (10/40), train loss:0.6932\n",
      "  batch (20/40), train loss:0.7030\n",
      "  batch (30/40), train loss:0.7000\n",
      "epoch: 14, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.6994\n",
      "  batch (10/40), train loss:0.6932\n",
      "  batch (20/40), train loss:0.7001\n",
      "  batch (30/40), train loss:0.6978\n",
      "epoch: 15, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.6973\n",
      "  batch (10/40), train loss:0.6932\n",
      "  batch (20/40), train loss:0.6972\n",
      "  batch (30/40), train loss:0.6957\n",
      "total train time:0.10 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.7647\n",
      "  batch (10/40), train loss:0.6960\n",
      "  batch (20/40), train loss:0.7539\n",
      "  batch (30/40), train loss:0.6849\n",
      "epoch: 0, time: 0.00, valid_metric: 0.60, train_metric: 0.75\n",
      "  batch (0/40), train loss:0.6581\n",
      "  batch (10/40), train loss:0.5632\n",
      "  batch (20/40), train loss:0.6214\n",
      "  batch (30/40), train loss:0.5494\n",
      "epoch: 1, time: 0.01, valid_metric: 0.60, train_metric: 0.80\n",
      "  batch (0/40), train loss:0.5875\n",
      "  batch (10/40), train loss:0.4866\n",
      "  batch (20/40), train loss:0.5283\n",
      "  batch (30/40), train loss:0.4461\n",
      "epoch: 2, time: 0.00, valid_metric: 0.70, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.5356\n",
      "  batch (10/40), train loss:0.4235\n",
      "  batch (20/40), train loss:0.4442\n",
      "  batch (30/40), train loss:0.3669\n",
      "epoch: 3, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.4761\n",
      "  batch (10/40), train loss:0.3710\n",
      "  batch (20/40), train loss:0.3757\n",
      "  batch (30/40), train loss:0.3063\n",
      "epoch: 4, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.4259\n",
      "  batch (10/40), train loss:0.3280\n",
      "  batch (20/40), train loss:0.3168\n",
      "  batch (30/40), train loss:0.2552\n",
      "epoch: 5, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.3838\n",
      "  batch (10/40), train loss:0.2902\n",
      "  batch (20/40), train loss:0.2677\n",
      "  batch (30/40), train loss:0.2169\n",
      "epoch: 6, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.3480\n",
      "  batch (10/40), train loss:0.2549\n",
      "  batch (20/40), train loss:0.2250\n",
      "  batch (30/40), train loss:0.1854\n",
      "epoch: 7, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.3166\n",
      "  batch (10/40), train loss:0.2234\n",
      "  batch (20/40), train loss:0.1896\n",
      "  batch (30/40), train loss:0.1610\n",
      "epoch: 8, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2882\n",
      "  batch (10/40), train loss:0.1961\n",
      "  batch (20/40), train loss:0.1600\n",
      "  batch (30/40), train loss:0.1381\n",
      "epoch: 9, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2662\n",
      "  batch (10/40), train loss:0.1730\n",
      "  batch (20/40), train loss:0.1367\n",
      "  batch (30/40), train loss:0.1204\n",
      "epoch: 10, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2425\n",
      "  batch (10/40), train loss:0.1541\n",
      "  batch (20/40), train loss:0.1175\n",
      "  batch (30/40), train loss:0.1052\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2227\n",
      "  batch (10/40), train loss:0.1362\n",
      "  batch (20/40), train loss:0.1015\n",
      "  batch (30/40), train loss:0.0921\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2056\n",
      "  batch (10/40), train loss:0.1206\n",
      "  batch (20/40), train loss:0.0883\n",
      "  batch (30/40), train loss:0.0823\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1908\n",
      "  batch (10/40), train loss:0.1077\n",
      "  batch (20/40), train loss:0.0772\n",
      "  batch (30/40), train loss:0.0727\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1729\n",
      "  batch (10/40), train loss:0.0960\n",
      "  batch (20/40), train loss:0.0679\n",
      "  batch (30/40), train loss:0.0654\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1584\n",
      "  batch (10/40), train loss:0.0857\n",
      "  batch (20/40), train loss:0.0604\n",
      "  batch (30/40), train loss:0.0588\n",
      "total train time:0.36 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.7345\n",
      "  batch (10/40), train loss:0.6952\n",
      "  batch (20/40), train loss:0.7460\n",
      "  batch (30/40), train loss:0.7327\n",
      "epoch: 0, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7321\n",
      "  batch (10/40), train loss:0.6950\n",
      "  batch (20/40), train loss:0.7428\n",
      "  batch (30/40), train loss:0.7303\n",
      "epoch: 1, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7296\n",
      "  batch (10/40), train loss:0.6948\n",
      "  batch (20/40), train loss:0.7397\n",
      "  batch (30/40), train loss:0.7278\n",
      "epoch: 2, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7272\n",
      "  batch (10/40), train loss:0.6946\n",
      "  batch (20/40), train loss:0.7365\n",
      "  batch (30/40), train loss:0.7254\n",
      "epoch: 3, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7248\n",
      "  batch (10/40), train loss:0.6944\n",
      "  batch (20/40), train loss:0.7333\n",
      "  batch (30/40), train loss:0.7230\n",
      "epoch: 4, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7224\n",
      "  batch (10/40), train loss:0.6942\n",
      "  batch (20/40), train loss:0.7302\n",
      "  batch (30/40), train loss:0.7206\n",
      "epoch: 5, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7200\n",
      "  batch (10/40), train loss:0.6940\n",
      "  batch (20/40), train loss:0.7271\n",
      "  batch (30/40), train loss:0.7182\n",
      "epoch: 6, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7176\n",
      "  batch (10/40), train loss:0.6939\n",
      "  batch (20/40), train loss:0.7240\n",
      "  batch (30/40), train loss:0.7159\n",
      "epoch: 7, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7153\n",
      "  batch (10/40), train loss:0.6938\n",
      "  batch (20/40), train loss:0.7209\n",
      "  batch (30/40), train loss:0.7135\n",
      "epoch: 8, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7130\n",
      "  batch (10/40), train loss:0.6936\n",
      "  batch (20/40), train loss:0.7179\n",
      "  batch (30/40), train loss:0.7112\n",
      "epoch: 9, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7107\n",
      "  batch (10/40), train loss:0.6935\n",
      "  batch (20/40), train loss:0.7149\n",
      "  batch (30/40), train loss:0.7089\n",
      "epoch: 10, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7084\n",
      "  batch (10/40), train loss:0.6934\n",
      "  batch (20/40), train loss:0.7119\n",
      "  batch (30/40), train loss:0.7067\n",
      "epoch: 11, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7061\n",
      "  batch (10/40), train loss:0.6934\n",
      "  batch (20/40), train loss:0.7089\n",
      "  batch (30/40), train loss:0.7044\n",
      "epoch: 12, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7039\n",
      "  batch (10/40), train loss:0.6933\n",
      "  batch (20/40), train loss:0.7059\n",
      "  batch (30/40), train loss:0.7022\n",
      "epoch: 13, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7016\n",
      "  batch (10/40), train loss:0.6932\n",
      "  batch (20/40), train loss:0.7030\n",
      "  batch (30/40), train loss:0.7000\n",
      "epoch: 14, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.6994\n",
      "  batch (10/40), train loss:0.6932\n",
      "  batch (20/40), train loss:0.7001\n",
      "  batch (30/40), train loss:0.6978\n",
      "epoch: 15, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.6973\n",
      "  batch (10/40), train loss:0.6932\n",
      "  batch (20/40), train loss:0.6972\n",
      "  batch (30/40), train loss:0.6957\n",
      "total train time:0.10 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.7256\n",
      "  batch (10/40), train loss:0.7070\n",
      "  batch (20/40), train loss:0.7604\n",
      "  batch (30/40), train loss:0.7486\n",
      "epoch: 0, time: 0.00, valid_metric: 0.40, train_metric: 0.60\n",
      "  batch (0/40), train loss:0.6150\n",
      "  batch (10/40), train loss:0.6064\n",
      "  batch (20/40), train loss:0.6559\n",
      "  batch (30/40), train loss:0.6456\n",
      "epoch: 1, time: 0.00, valid_metric: 0.30, train_metric: 0.68\n",
      "  batch (0/40), train loss:0.5511\n",
      "  batch (10/40), train loss:0.5330\n",
      "  batch (20/40), train loss:0.5965\n",
      "  batch (30/40), train loss:0.5703\n",
      "epoch: 2, time: 0.00, valid_metric: 0.30, train_metric: 0.72\n",
      "  batch (0/40), train loss:0.5002\n",
      "  batch (10/40), train loss:0.4782\n",
      "  batch (20/40), train loss:0.5327\n",
      "  batch (30/40), train loss:0.5157\n",
      "epoch: 3, time: 0.00, valid_metric: 0.30, train_metric: 0.75\n",
      "  batch (0/40), train loss:0.4582\n",
      "  batch (10/40), train loss:0.4291\n",
      "  batch (20/40), train loss:0.4912\n",
      "  batch (30/40), train loss:0.4729\n",
      "epoch: 4, time: 0.00, valid_metric: 0.30, train_metric: 0.75\n",
      "  batch (0/40), train loss:0.4216\n",
      "  batch (10/40), train loss:0.3876\n",
      "  batch (20/40), train loss:0.4556\n",
      "  batch (30/40), train loss:0.4337\n",
      "epoch: 5, time: 0.00, valid_metric: 0.30, train_metric: 0.78\n",
      "  batch (0/40), train loss:0.3919\n",
      "  batch (10/40), train loss:0.3489\n",
      "  batch (20/40), train loss:0.4232\n",
      "  batch (30/40), train loss:0.4059\n",
      "epoch: 6, time: 0.00, valid_metric: 0.40, train_metric: 0.82\n",
      "  batch (0/40), train loss:0.3592\n",
      "  batch (10/40), train loss:0.3191\n",
      "  batch (20/40), train loss:0.3903\n",
      "  batch (30/40), train loss:0.3796\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.82\n",
      "  batch (0/40), train loss:0.3331\n",
      "  batch (10/40), train loss:0.2938\n",
      "  batch (20/40), train loss:0.3600\n",
      "  batch (30/40), train loss:0.3451\n",
      "epoch: 8, time: 0.00, valid_metric: 0.50, train_metric: 0.85\n",
      "  batch (0/40), train loss:0.3077\n",
      "  batch (10/40), train loss:0.2740\n",
      "  batch (20/40), train loss:0.3308\n",
      "  batch (30/40), train loss:0.3075\n",
      "epoch: 9, time: 0.00, valid_metric: 0.50, train_metric: 0.88\n",
      "  batch (0/40), train loss:0.2890\n",
      "  batch (10/40), train loss:0.2527\n",
      "  batch (20/40), train loss:0.3050\n",
      "  batch (30/40), train loss:0.2735\n",
      "epoch: 10, time: 0.00, valid_metric: 0.50, train_metric: 0.88\n",
      "  batch (0/40), train loss:0.2727\n",
      "  batch (10/40), train loss:0.2325\n",
      "  batch (20/40), train loss:0.2782\n",
      "  batch (30/40), train loss:0.2480\n",
      "epoch: 11, time: 0.00, valid_metric: 0.60, train_metric: 0.90\n",
      "  batch (0/40), train loss:0.2559\n",
      "  batch (10/40), train loss:0.2188\n",
      "  batch (20/40), train loss:0.2508\n",
      "  batch (30/40), train loss:0.2244\n",
      "epoch: 12, time: 0.00, valid_metric: 0.60, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.2379\n",
      "  batch (10/40), train loss:0.2002\n",
      "  batch (20/40), train loss:0.2197\n",
      "  batch (30/40), train loss:0.2031\n",
      "epoch: 13, time: 0.01, valid_metric: 0.60, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.2217\n",
      "  batch (10/40), train loss:0.1809\n",
      "  batch (20/40), train loss:0.1975\n",
      "  batch (30/40), train loss:0.1859\n",
      "epoch: 14, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.2075\n",
      "  batch (10/40), train loss:0.1651\n",
      "  batch (20/40), train loss:0.1787\n",
      "  batch (30/40), train loss:0.1712\n",
      "epoch: 15, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.1956\n",
      "  batch (10/40), train loss:0.1499\n",
      "  batch (20/40), train loss:0.1627\n",
      "  batch (30/40), train loss:0.1584\n",
      "epoch: 16, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1820\n",
      "  batch (10/40), train loss:0.1349\n",
      "  batch (20/40), train loss:0.1490\n",
      "  batch (30/40), train loss:0.1469\n",
      "epoch: 17, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1696\n",
      "  batch (10/40), train loss:0.1217\n",
      "  batch (20/40), train loss:0.1397\n",
      "  batch (30/40), train loss:0.1363\n",
      "epoch: 18, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1608\n",
      "  batch (10/40), train loss:0.1102\n",
      "  batch (20/40), train loss:0.1276\n",
      "  batch (30/40), train loss:0.1266\n",
      "epoch: 19, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1506\n",
      "  batch (10/40), train loss:0.1018\n",
      "  batch (20/40), train loss:0.1195\n",
      "  batch (30/40), train loss:0.1189\n",
      "epoch: 20, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1418\n",
      "  batch (10/40), train loss:0.0923\n",
      "  batch (20/40), train loss:0.1121\n",
      "  batch (30/40), train loss:0.1078\n",
      "total train time:0.47 for epochs: 21\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.7345\n",
      "  batch (10/40), train loss:0.6952\n",
      "  batch (20/40), train loss:0.7460\n",
      "  batch (30/40), train loss:0.7327\n",
      "epoch: 0, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7321\n",
      "  batch (10/40), train loss:0.6950\n",
      "  batch (20/40), train loss:0.7428\n",
      "  batch (30/40), train loss:0.7303\n",
      "epoch: 1, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7296\n",
      "  batch (10/40), train loss:0.6948\n",
      "  batch (20/40), train loss:0.7397\n",
      "  batch (30/40), train loss:0.7278\n",
      "epoch: 2, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7272\n",
      "  batch (10/40), train loss:0.6946\n",
      "  batch (20/40), train loss:0.7365\n",
      "  batch (30/40), train loss:0.7254\n",
      "epoch: 3, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7248\n",
      "  batch (10/40), train loss:0.6944\n",
      "  batch (20/40), train loss:0.7333\n",
      "  batch (30/40), train loss:0.7230\n",
      "epoch: 4, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7224\n",
      "  batch (10/40), train loss:0.6942\n",
      "  batch (20/40), train loss:0.7302\n",
      "  batch (30/40), train loss:0.7206\n",
      "epoch: 5, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7200\n",
      "  batch (10/40), train loss:0.6940\n",
      "  batch (20/40), train loss:0.7271\n",
      "  batch (30/40), train loss:0.7182\n",
      "epoch: 6, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7176\n",
      "  batch (10/40), train loss:0.6939\n",
      "  batch (20/40), train loss:0.7240\n",
      "  batch (30/40), train loss:0.7159\n",
      "epoch: 7, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7153\n",
      "  batch (10/40), train loss:0.6938\n",
      "  batch (20/40), train loss:0.7209\n",
      "  batch (30/40), train loss:0.7135\n",
      "epoch: 8, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7130\n",
      "  batch (10/40), train loss:0.6936\n",
      "  batch (20/40), train loss:0.7179\n",
      "  batch (30/40), train loss:0.7112\n",
      "epoch: 9, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7107\n",
      "  batch (10/40), train loss:0.6935\n",
      "  batch (20/40), train loss:0.7149\n",
      "  batch (30/40), train loss:0.7089\n",
      "epoch: 10, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7084\n",
      "  batch (10/40), train loss:0.6934\n",
      "  batch (20/40), train loss:0.7119\n",
      "  batch (30/40), train loss:0.7067\n",
      "epoch: 11, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7061\n",
      "  batch (10/40), train loss:0.6934\n",
      "  batch (20/40), train loss:0.7089\n",
      "  batch (30/40), train loss:0.7044\n",
      "epoch: 12, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7039\n",
      "  batch (10/40), train loss:0.6933\n",
      "  batch (20/40), train loss:0.7059\n",
      "  batch (30/40), train loss:0.7022\n",
      "epoch: 13, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7016\n",
      "  batch (10/40), train loss:0.6932\n",
      "  batch (20/40), train loss:0.7030\n",
      "  batch (30/40), train loss:0.7000\n",
      "epoch: 14, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.6994\n",
      "  batch (10/40), train loss:0.6932\n",
      "  batch (20/40), train loss:0.7001\n",
      "  batch (30/40), train loss:0.6978\n",
      "epoch: 15, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.6973\n",
      "  batch (10/40), train loss:0.6932\n",
      "  batch (20/40), train loss:0.6972\n",
      "  batch (30/40), train loss:0.6957\n",
      "total train time:0.10 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.7206\n",
      "  batch (10/40), train loss:0.6507\n",
      "  batch (20/40), train loss:0.7376\n",
      "  batch (30/40), train loss:0.7513\n",
      "epoch: 0, time: 0.00, valid_metric: 0.70, train_metric: 0.65\n",
      "  batch (0/40), train loss:0.5390\n",
      "  batch (10/40), train loss:0.5436\n",
      "  batch (20/40), train loss:0.6001\n",
      "  batch (30/40), train loss:0.6425\n",
      "epoch: 1, time: 0.00, valid_metric: 0.70, train_metric: 0.78\n",
      "  batch (0/40), train loss:0.4278\n",
      "  batch (10/40), train loss:0.4805\n",
      "  batch (20/40), train loss:0.5059\n",
      "  batch (30/40), train loss:0.5802\n",
      "epoch: 2, time: 0.00, valid_metric: 0.60, train_metric: 0.82\n",
      "  batch (0/40), train loss:0.3512\n",
      "  batch (10/40), train loss:0.4200\n",
      "  batch (20/40), train loss:0.4260\n",
      "  batch (30/40), train loss:0.5425\n",
      "epoch: 3, time: 0.00, valid_metric: 0.60, train_metric: 0.85\n",
      "  batch (0/40), train loss:0.2971\n",
      "  batch (10/40), train loss:0.3648\n",
      "  batch (20/40), train loss:0.3687\n",
      "  batch (30/40), train loss:0.5089\n",
      "epoch: 4, time: 0.00, valid_metric: 0.60, train_metric: 0.88\n",
      "  batch (0/40), train loss:0.2565\n",
      "  batch (10/40), train loss:0.3146\n",
      "  batch (20/40), train loss:0.3213\n",
      "  batch (30/40), train loss:0.4780\n",
      "epoch: 5, time: 0.00, valid_metric: 0.60, train_metric: 0.88\n",
      "  batch (0/40), train loss:0.2265\n",
      "  batch (10/40), train loss:0.2689\n",
      "  batch (20/40), train loss:0.2840\n",
      "  batch (30/40), train loss:0.4530\n",
      "epoch: 6, time: 0.00, valid_metric: 0.60, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.2010\n",
      "  batch (10/40), train loss:0.2275\n",
      "  batch (20/40), train loss:0.2571\n",
      "  batch (30/40), train loss:0.4149\n",
      "epoch: 7, time: 0.00, valid_metric: 0.70, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.1813\n",
      "  batch (10/40), train loss:0.1918\n",
      "  batch (20/40), train loss:0.2383\n",
      "  batch (30/40), train loss:0.3802\n",
      "epoch: 8, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1649\n",
      "  batch (10/40), train loss:0.1652\n",
      "  batch (20/40), train loss:0.2173\n",
      "  batch (30/40), train loss:0.3509\n",
      "epoch: 9, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1513\n",
      "  batch (10/40), train loss:0.1461\n",
      "  batch (20/40), train loss:0.1986\n",
      "  batch (30/40), train loss:0.3260\n",
      "epoch: 10, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1391\n",
      "  batch (10/40), train loss:0.1309\n",
      "  batch (20/40), train loss:0.1817\n",
      "  batch (30/40), train loss:0.3057\n",
      "epoch: 11, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1279\n",
      "  batch (10/40), train loss:0.1179\n",
      "  batch (20/40), train loss:0.1664\n",
      "  batch (30/40), train loss:0.2902\n",
      "epoch: 12, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1179\n",
      "  batch (10/40), train loss:0.1062\n",
      "  batch (20/40), train loss:0.1533\n",
      "  batch (30/40), train loss:0.2775\n",
      "epoch: 13, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1082\n",
      "  batch (10/40), train loss:0.0949\n",
      "  batch (20/40), train loss:0.1424\n",
      "  batch (30/40), train loss:0.2661\n",
      "epoch: 14, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0997\n",
      "  batch (10/40), train loss:0.0854\n",
      "  batch (20/40), train loss:0.1319\n",
      "  batch (30/40), train loss:0.2550\n",
      "epoch: 15, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0919\n",
      "  batch (10/40), train loss:0.0776\n",
      "  batch (20/40), train loss:0.1219\n",
      "  batch (30/40), train loss:0.2458\n",
      "epoch: 16, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0848\n",
      "  batch (10/40), train loss:0.0714\n",
      "  batch (20/40), train loss:0.1124\n",
      "  batch (30/40), train loss:0.2357\n",
      "total train time:0.36 for epochs: 17\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.7218\n",
      "  batch (10/40), train loss:0.7157\n",
      "  batch (20/40), train loss:0.7442\n",
      "  batch (30/40), train loss:0.6980\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7208\n",
      "  batch (10/40), train loss:0.7155\n",
      "  batch (20/40), train loss:0.7430\n",
      "  batch (30/40), train loss:0.6971\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7198\n",
      "  batch (10/40), train loss:0.7154\n",
      "  batch (20/40), train loss:0.7418\n",
      "  batch (30/40), train loss:0.6961\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7189\n",
      "  batch (10/40), train loss:0.7153\n",
      "  batch (20/40), train loss:0.7406\n",
      "  batch (30/40), train loss:0.6951\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7179\n",
      "  batch (10/40), train loss:0.7152\n",
      "  batch (20/40), train loss:0.7394\n",
      "  batch (30/40), train loss:0.6942\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7169\n",
      "  batch (10/40), train loss:0.7151\n",
      "  batch (20/40), train loss:0.7382\n",
      "  batch (30/40), train loss:0.6932\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7160\n",
      "  batch (10/40), train loss:0.7150\n",
      "  batch (20/40), train loss:0.7370\n",
      "  batch (30/40), train loss:0.6922\n",
      "epoch: 6, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7150\n",
      "  batch (10/40), train loss:0.7149\n",
      "  batch (20/40), train loss:0.7358\n",
      "  batch (30/40), train loss:0.6913\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7140\n",
      "  batch (10/40), train loss:0.7148\n",
      "  batch (20/40), train loss:0.7346\n",
      "  batch (30/40), train loss:0.6903\n",
      "epoch: 8, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7130\n",
      "  batch (10/40), train loss:0.7147\n",
      "  batch (20/40), train loss:0.7334\n",
      "  batch (30/40), train loss:0.6893\n",
      "epoch: 9, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7121\n",
      "  batch (10/40), train loss:0.7146\n",
      "  batch (20/40), train loss:0.7322\n",
      "  batch (30/40), train loss:0.6883\n",
      "epoch: 10, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7111\n",
      "  batch (10/40), train loss:0.7145\n",
      "  batch (20/40), train loss:0.7310\n",
      "  batch (30/40), train loss:0.6873\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7101\n",
      "  batch (10/40), train loss:0.7145\n",
      "  batch (20/40), train loss:0.7298\n",
      "  batch (30/40), train loss:0.6864\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7092\n",
      "  batch (10/40), train loss:0.7144\n",
      "  batch (20/40), train loss:0.7286\n",
      "  batch (30/40), train loss:0.6854\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7082\n",
      "  batch (10/40), train loss:0.7143\n",
      "  batch (20/40), train loss:0.7275\n",
      "  batch (30/40), train loss:0.6845\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7072\n",
      "  batch (10/40), train loss:0.7142\n",
      "  batch (20/40), train loss:0.7263\n",
      "  batch (30/40), train loss:0.6835\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7063\n",
      "  batch (10/40), train loss:0.7141\n",
      "  batch (20/40), train loss:0.7251\n",
      "  batch (30/40), train loss:0.6826\n",
      "total train time:0.09 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.7744\n",
      "  batch (10/40), train loss:0.6852\n",
      "  batch (20/40), train loss:0.7960\n",
      "  batch (30/40), train loss:0.7448\n",
      "epoch: 0, time: 0.00, valid_metric: 0.40, train_metric: 0.45\n",
      "  batch (0/40), train loss:0.6701\n",
      "  batch (10/40), train loss:0.5846\n",
      "  batch (20/40), train loss:0.6889\n",
      "  batch (30/40), train loss:0.6876\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.80\n",
      "  batch (0/40), train loss:0.5922\n",
      "  batch (10/40), train loss:0.5007\n",
      "  batch (20/40), train loss:0.5906\n",
      "  batch (30/40), train loss:0.6252\n",
      "epoch: 2, time: 0.00, valid_metric: 0.70, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.5228\n",
      "  batch (10/40), train loss:0.4322\n",
      "  batch (20/40), train loss:0.5069\n",
      "  batch (30/40), train loss:0.5626\n",
      "epoch: 3, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.4615\n",
      "  batch (10/40), train loss:0.3788\n",
      "  batch (20/40), train loss:0.4320\n",
      "  batch (30/40), train loss:0.4999\n",
      "epoch: 4, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.4030\n",
      "  batch (10/40), train loss:0.3272\n",
      "  batch (20/40), train loss:0.3710\n",
      "  batch (30/40), train loss:0.4424\n",
      "epoch: 5, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.3511\n",
      "  batch (10/40), train loss:0.2817\n",
      "  batch (20/40), train loss:0.3208\n",
      "  batch (30/40), train loss:0.3859\n",
      "epoch: 6, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.3067\n",
      "  batch (10/40), train loss:0.2445\n",
      "  batch (20/40), train loss:0.2748\n",
      "  batch (30/40), train loss:0.3347\n",
      "epoch: 7, time: 0.00, valid_metric: 0.90, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2687\n",
      "  batch (10/40), train loss:0.2158\n",
      "  batch (20/40), train loss:0.2347\n",
      "  batch (30/40), train loss:0.2889\n",
      "epoch: 8, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2357\n",
      "  batch (10/40), train loss:0.1871\n",
      "  batch (20/40), train loss:0.1997\n",
      "  batch (30/40), train loss:0.2515\n",
      "epoch: 9, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2073\n",
      "  batch (10/40), train loss:0.1658\n",
      "  batch (20/40), train loss:0.1717\n",
      "  batch (30/40), train loss:0.2209\n",
      "epoch: 10, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1824\n",
      "  batch (10/40), train loss:0.1484\n",
      "  batch (20/40), train loss:0.1506\n",
      "  batch (30/40), train loss:0.1960\n",
      "epoch: 11, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1603\n",
      "  batch (10/40), train loss:0.1324\n",
      "  batch (20/40), train loss:0.1302\n",
      "  batch (30/40), train loss:0.1758\n",
      "epoch: 12, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1410\n",
      "  batch (10/40), train loss:0.1181\n",
      "  batch (20/40), train loss:0.1148\n",
      "  batch (30/40), train loss:0.1590\n",
      "epoch: 13, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1245\n",
      "  batch (10/40), train loss:0.1055\n",
      "  batch (20/40), train loss:0.1014\n",
      "  batch (30/40), train loss:0.1452\n",
      "epoch: 14, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1108\n",
      "  batch (10/40), train loss:0.0956\n",
      "  batch (20/40), train loss:0.0900\n",
      "  batch (30/40), train loss:0.1330\n",
      "epoch: 15, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0990\n",
      "  batch (10/40), train loss:0.0884\n",
      "  batch (20/40), train loss:0.0799\n",
      "  batch (30/40), train loss:0.1226\n",
      "total train time:0.31 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.7289\n",
      "  batch (10/40), train loss:0.6976\n",
      "  batch (20/40), train loss:0.7469\n",
      "  batch (30/40), train loss:0.7339\n",
      "epoch: 0, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7279\n",
      "  batch (10/40), train loss:0.6975\n",
      "  batch (20/40), train loss:0.7456\n",
      "  batch (30/40), train loss:0.7329\n",
      "epoch: 1, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7270\n",
      "  batch (10/40), train loss:0.6974\n",
      "  batch (20/40), train loss:0.7444\n",
      "  batch (30/40), train loss:0.7320\n",
      "epoch: 2, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7260\n",
      "  batch (10/40), train loss:0.6973\n",
      "  batch (20/40), train loss:0.7430\n",
      "  batch (30/40), train loss:0.7311\n",
      "epoch: 3, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7250\n",
      "  batch (10/40), train loss:0.6972\n",
      "  batch (20/40), train loss:0.7417\n",
      "  batch (30/40), train loss:0.7302\n",
      "epoch: 4, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7240\n",
      "  batch (10/40), train loss:0.6971\n",
      "  batch (20/40), train loss:0.7404\n",
      "  batch (30/40), train loss:0.7293\n",
      "epoch: 5, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7230\n",
      "  batch (10/40), train loss:0.6970\n",
      "  batch (20/40), train loss:0.7391\n",
      "  batch (30/40), train loss:0.7283\n",
      "epoch: 6, time: 0.00, valid_metric: 0.30, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7220\n",
      "  batch (10/40), train loss:0.6969\n",
      "  batch (20/40), train loss:0.7378\n",
      "  batch (30/40), train loss:0.7274\n",
      "epoch: 7, time: 0.00, valid_metric: 0.40, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7210\n",
      "  batch (10/40), train loss:0.6968\n",
      "  batch (20/40), train loss:0.7365\n",
      "  batch (30/40), train loss:0.7265\n",
      "epoch: 8, time: 0.00, valid_metric: 0.40, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7200\n",
      "  batch (10/40), train loss:0.6967\n",
      "  batch (20/40), train loss:0.7352\n",
      "  batch (30/40), train loss:0.7256\n",
      "epoch: 9, time: 0.00, valid_metric: 0.40, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7191\n",
      "  batch (10/40), train loss:0.6966\n",
      "  batch (20/40), train loss:0.7339\n",
      "  batch (30/40), train loss:0.7247\n",
      "epoch: 10, time: 0.00, valid_metric: 0.40, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7181\n",
      "  batch (10/40), train loss:0.6965\n",
      "  batch (20/40), train loss:0.7325\n",
      "  batch (30/40), train loss:0.7238\n",
      "epoch: 11, time: 0.00, valid_metric: 0.40, train_metric: 0.28\n",
      "  batch (0/40), train loss:0.7171\n",
      "  batch (10/40), train loss:0.6963\n",
      "  batch (20/40), train loss:0.7312\n",
      "  batch (30/40), train loss:0.7228\n",
      "epoch: 12, time: 0.00, valid_metric: 0.40, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7161\n",
      "  batch (10/40), train loss:0.6962\n",
      "  batch (20/40), train loss:0.7298\n",
      "  batch (30/40), train loss:0.7219\n",
      "epoch: 13, time: 0.00, valid_metric: 0.40, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7151\n",
      "  batch (10/40), train loss:0.6961\n",
      "  batch (20/40), train loss:0.7285\n",
      "  batch (30/40), train loss:0.7209\n",
      "epoch: 14, time: 0.00, valid_metric: 0.40, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7141\n",
      "  batch (10/40), train loss:0.6959\n",
      "  batch (20/40), train loss:0.7271\n",
      "  batch (30/40), train loss:0.7200\n",
      "epoch: 15, time: 0.00, valid_metric: 0.40, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7131\n",
      "  batch (10/40), train loss:0.6958\n",
      "  batch (20/40), train loss:0.7257\n",
      "  batch (30/40), train loss:0.7190\n",
      "epoch: 16, time: 0.00, valid_metric: 0.40, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7121\n",
      "  batch (10/40), train loss:0.6957\n",
      "  batch (20/40), train loss:0.7243\n",
      "  batch (30/40), train loss:0.7181\n",
      "total train time:0.10 for epochs: 17\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "50\n",
      "  batch (0/40), train loss:0.7383\n",
      "  batch (10/40), train loss:0.6817\n",
      "  batch (20/40), train loss:0.7356\n",
      "  batch (30/40), train loss:0.7730\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.5974\n",
      "  batch (10/40), train loss:0.5739\n",
      "  batch (20/40), train loss:0.6179\n",
      "  batch (30/40), train loss:0.6859\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.68\n",
      "  batch (0/40), train loss:0.5200\n",
      "  batch (10/40), train loss:0.5217\n",
      "  batch (20/40), train loss:0.5417\n",
      "  batch (30/40), train loss:0.6103\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.70\n",
      "  batch (0/40), train loss:0.4586\n",
      "  batch (10/40), train loss:0.4724\n",
      "  batch (20/40), train loss:0.4855\n",
      "  batch (30/40), train loss:0.5304\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.82\n",
      "  batch (0/40), train loss:0.4058\n",
      "  batch (10/40), train loss:0.4208\n",
      "  batch (20/40), train loss:0.4321\n",
      "  batch (30/40), train loss:0.4593\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.3525\n",
      "  batch (10/40), train loss:0.3843\n",
      "  batch (20/40), train loss:0.3773\n",
      "  batch (30/40), train loss:0.3863\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.3192\n",
      "  batch (10/40), train loss:0.3403\n",
      "  batch (20/40), train loss:0.3383\n",
      "  batch (30/40), train loss:0.3272\n",
      "epoch: 6, time: 0.00, valid_metric: 0.60, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.2792\n",
      "  batch (10/40), train loss:0.3050\n",
      "  batch (20/40), train loss:0.3073\n",
      "  batch (30/40), train loss:0.2779\n",
      "epoch: 7, time: 0.00, valid_metric: 0.60, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.2398\n",
      "  batch (10/40), train loss:0.2717\n",
      "  batch (20/40), train loss:0.2747\n",
      "  batch (30/40), train loss:0.2384\n",
      "epoch: 8, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.2086\n",
      "  batch (10/40), train loss:0.2465\n",
      "  batch (20/40), train loss:0.2458\n",
      "  batch (30/40), train loss:0.2075\n",
      "epoch: 9, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.1805\n",
      "  batch (10/40), train loss:0.2230\n",
      "  batch (20/40), train loss:0.2213\n",
      "  batch (30/40), train loss:0.1845\n",
      "epoch: 10, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.1569\n",
      "  batch (10/40), train loss:0.2044\n",
      "  batch (20/40), train loss:0.2031\n",
      "  batch (30/40), train loss:0.1638\n",
      "epoch: 11, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.1417\n",
      "  batch (10/40), train loss:0.1897\n",
      "  batch (20/40), train loss:0.1884\n",
      "  batch (30/40), train loss:0.1474\n",
      "epoch: 12, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.1242\n",
      "  batch (10/40), train loss:0.1807\n",
      "  batch (20/40), train loss:0.1763\n",
      "  batch (30/40), train loss:0.1345\n",
      "epoch: 13, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.1113\n",
      "  batch (10/40), train loss:0.1629\n",
      "  batch (20/40), train loss:0.1660\n",
      "  batch (30/40), train loss:0.1238\n",
      "epoch: 14, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.1001\n",
      "  batch (10/40), train loss:0.1524\n",
      "  batch (20/40), train loss:0.1569\n",
      "  batch (30/40), train loss:0.1131\n",
      "epoch: 15, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.0901\n",
      "  batch (10/40), train loss:0.1467\n",
      "  batch (20/40), train loss:0.1488\n",
      "  batch (30/40), train loss:0.1043\n",
      "total train time:0.32 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.7325\n",
      "  batch (10/40), train loss:0.6992\n",
      "  batch (20/40), train loss:0.7443\n",
      "  batch (30/40), train loss:0.7366\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.23\n",
      "  batch (0/40), train loss:0.7316\n",
      "  batch (10/40), train loss:0.6990\n",
      "  batch (20/40), train loss:0.7430\n",
      "  batch (30/40), train loss:0.7357\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.23\n",
      "  batch (0/40), train loss:0.7306\n",
      "  batch (10/40), train loss:0.6988\n",
      "  batch (20/40), train loss:0.7417\n",
      "  batch (30/40), train loss:0.7348\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.23\n",
      "  batch (0/40), train loss:0.7297\n",
      "  batch (10/40), train loss:0.6986\n",
      "  batch (20/40), train loss:0.7404\n",
      "  batch (30/40), train loss:0.7338\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.23\n",
      "  batch (0/40), train loss:0.7287\n",
      "  batch (10/40), train loss:0.6985\n",
      "  batch (20/40), train loss:0.7391\n",
      "  batch (30/40), train loss:0.7329\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.23\n",
      "  batch (0/40), train loss:0.7278\n",
      "  batch (10/40), train loss:0.6983\n",
      "  batch (20/40), train loss:0.7378\n",
      "  batch (30/40), train loss:0.7319\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.23\n",
      "  batch (0/40), train loss:0.7268\n",
      "  batch (10/40), train loss:0.6982\n",
      "  batch (20/40), train loss:0.7365\n",
      "  batch (30/40), train loss:0.7309\n",
      "epoch: 6, time: 0.00, valid_metric: 0.50, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7259\n",
      "  batch (10/40), train loss:0.6980\n",
      "  batch (20/40), train loss:0.7352\n",
      "  batch (30/40), train loss:0.7300\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7249\n",
      "  batch (10/40), train loss:0.6979\n",
      "  batch (20/40), train loss:0.7339\n",
      "  batch (30/40), train loss:0.7291\n",
      "epoch: 8, time: 0.00, valid_metric: 0.50, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7240\n",
      "  batch (10/40), train loss:0.6977\n",
      "  batch (20/40), train loss:0.7326\n",
      "  batch (30/40), train loss:0.7281\n",
      "epoch: 9, time: 0.00, valid_metric: 0.50, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7230\n",
      "  batch (10/40), train loss:0.6975\n",
      "  batch (20/40), train loss:0.7313\n",
      "  batch (30/40), train loss:0.7272\n",
      "epoch: 10, time: 0.00, valid_metric: 0.50, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7221\n",
      "  batch (10/40), train loss:0.6974\n",
      "  batch (20/40), train loss:0.7300\n",
      "  batch (30/40), train loss:0.7263\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7211\n",
      "  batch (10/40), train loss:0.6972\n",
      "  batch (20/40), train loss:0.7287\n",
      "  batch (30/40), train loss:0.7254\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7202\n",
      "  batch (10/40), train loss:0.6971\n",
      "  batch (20/40), train loss:0.7274\n",
      "  batch (30/40), train loss:0.7244\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7192\n",
      "  batch (10/40), train loss:0.6969\n",
      "  batch (20/40), train loss:0.7261\n",
      "  batch (30/40), train loss:0.7235\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7182\n",
      "  batch (10/40), train loss:0.6968\n",
      "  batch (20/40), train loss:0.7248\n",
      "  batch (30/40), train loss:0.7226\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.25\n",
      "  batch (0/40), train loss:0.7173\n",
      "  batch (10/40), train loss:0.6967\n",
      "  batch (20/40), train loss:0.7235\n",
      "  batch (30/40), train loss:0.7217\n",
      "total train time:0.10 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.7585\n",
      "  batch (10/40), train loss:0.6945\n",
      "  batch (20/40), train loss:0.7234\n",
      "  batch (30/40), train loss:0.7782\n",
      "epoch: 0, time: 0.00, valid_metric: 0.30, train_metric: 0.57\n",
      "  batch (0/40), train loss:0.6256\n",
      "  batch (10/40), train loss:0.6147\n",
      "  batch (20/40), train loss:0.5899\n",
      "  batch (30/40), train loss:0.7017\n",
      "epoch: 1, time: 0.00, valid_metric: 0.20, train_metric: 0.85\n",
      "  batch (0/40), train loss:0.5780\n",
      "  batch (10/40), train loss:0.5483\n",
      "  batch (20/40), train loss:0.5049\n",
      "  batch (30/40), train loss:0.6221\n",
      "epoch: 2, time: 0.00, valid_metric: 0.40, train_metric: 0.88\n",
      "  batch (0/40), train loss:0.5403\n",
      "  batch (10/40), train loss:0.4915\n",
      "  batch (20/40), train loss:0.4372\n",
      "  batch (30/40), train loss:0.5593\n",
      "epoch: 3, time: 0.00, valid_metric: 0.30, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.5048\n",
      "  batch (10/40), train loss:0.4397\n",
      "  batch (20/40), train loss:0.3836\n",
      "  batch (30/40), train loss:0.5053\n",
      "epoch: 4, time: 0.00, valid_metric: 0.30, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.4706\n",
      "  batch (10/40), train loss:0.3975\n",
      "  batch (20/40), train loss:0.3414\n",
      "  batch (30/40), train loss:0.4558\n",
      "epoch: 5, time: 0.00, valid_metric: 0.20, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.4361\n",
      "  batch (10/40), train loss:0.3596\n",
      "  batch (20/40), train loss:0.3038\n",
      "  batch (30/40), train loss:0.4082\n",
      "epoch: 6, time: 0.00, valid_metric: 0.30, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.4011\n",
      "  batch (10/40), train loss:0.3244\n",
      "  batch (20/40), train loss:0.2727\n",
      "  batch (30/40), train loss:0.3635\n",
      "epoch: 7, time: 0.00, valid_metric: 0.30, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.3665\n",
      "  batch (10/40), train loss:0.2869\n",
      "  batch (20/40), train loss:0.2463\n",
      "  batch (30/40), train loss:0.3306\n",
      "epoch: 8, time: 0.00, valid_metric: 0.30, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.3338\n",
      "  batch (10/40), train loss:0.2522\n",
      "  batch (20/40), train loss:0.2239\n",
      "  batch (30/40), train loss:0.2930\n",
      "epoch: 9, time: 0.01, valid_metric: 0.30, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.3031\n",
      "  batch (10/40), train loss:0.2226\n",
      "  batch (20/40), train loss:0.2045\n",
      "  batch (30/40), train loss:0.2613\n",
      "epoch: 10, time: 0.00, valid_metric: 0.40, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2761\n",
      "  batch (10/40), train loss:0.1977\n",
      "  batch (20/40), train loss:0.1868\n",
      "  batch (30/40), train loss:0.2325\n",
      "epoch: 11, time: 0.00, valid_metric: 0.40, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2507\n",
      "  batch (10/40), train loss:0.1801\n",
      "  batch (20/40), train loss:0.1713\n",
      "  batch (30/40), train loss:0.2089\n",
      "epoch: 12, time: 0.00, valid_metric: 0.40, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2276\n",
      "  batch (10/40), train loss:0.1602\n",
      "  batch (20/40), train loss:0.1573\n",
      "  batch (30/40), train loss:0.1886\n",
      "epoch: 13, time: 0.00, valid_metric: 0.40, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2069\n",
      "  batch (10/40), train loss:0.1454\n",
      "  batch (20/40), train loss:0.1443\n",
      "  batch (30/40), train loss:0.1717\n",
      "epoch: 14, time: 0.00, valid_metric: 0.40, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1877\n",
      "  batch (10/40), train loss:0.1320\n",
      "  batch (20/40), train loss:0.1329\n",
      "  batch (30/40), train loss:0.1562\n",
      "epoch: 15, time: 0.00, valid_metric: 0.40, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1690\n",
      "  batch (10/40), train loss:0.1213\n",
      "  batch (20/40), train loss:0.1233\n",
      "  batch (30/40), train loss:0.1410\n",
      "epoch: 16, time: 0.00, valid_metric: 0.50, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1530\n",
      "  batch (10/40), train loss:0.1122\n",
      "  batch (20/40), train loss:0.1135\n",
      "  batch (30/40), train loss:0.1282\n",
      "epoch: 17, time: 0.00, valid_metric: 0.50, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1381\n",
      "  batch (10/40), train loss:0.1030\n",
      "  batch (20/40), train loss:0.1024\n",
      "  batch (30/40), train loss:0.1171\n",
      "epoch: 18, time: 0.00, valid_metric: 0.50, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1248\n",
      "  batch (10/40), train loss:0.0944\n",
      "  batch (20/40), train loss:0.0922\n",
      "  batch (30/40), train loss:0.1075\n",
      "epoch: 19, time: 0.00, valid_metric: 0.50, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1147\n",
      "  batch (10/40), train loss:0.0874\n",
      "  batch (20/40), train loss:0.0847\n",
      "  batch (30/40), train loss:0.0985\n",
      "epoch: 20, time: 0.00, valid_metric: 0.50, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1044\n",
      "  batch (10/40), train loss:0.0805\n",
      "  batch (20/40), train loss:0.0783\n",
      "  batch (30/40), train loss:0.0906\n",
      "epoch: 21, time: 0.00, valid_metric: 0.50, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0947\n",
      "  batch (10/40), train loss:0.0764\n",
      "  batch (20/40), train loss:0.0716\n",
      "  batch (30/40), train loss:0.0835\n",
      "epoch: 22, time: 0.00, valid_metric: 0.50, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0865\n",
      "  batch (10/40), train loss:0.0715\n",
      "  batch (20/40), train loss:0.0660\n",
      "  batch (30/40), train loss:0.0771\n",
      "epoch: 23, time: 0.00, valid_metric: 0.50, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0785\n",
      "  batch (10/40), train loss:0.0668\n",
      "  batch (20/40), train loss:0.0619\n",
      "  batch (30/40), train loss:0.0714\n",
      "epoch: 24, time: 0.00, valid_metric: 0.50, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0723\n",
      "  batch (10/40), train loss:0.0624\n",
      "  batch (20/40), train loss:0.0572\n",
      "  batch (30/40), train loss:0.0663\n",
      "epoch: 25, time: 0.00, valid_metric: 0.50, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0677\n",
      "  batch (10/40), train loss:0.0582\n",
      "  batch (20/40), train loss:0.0515\n",
      "  batch (30/40), train loss:0.0617\n",
      "total train time:0.50 for epochs: 26\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.6686\n",
      "  batch (10/40), train loss:0.7107\n",
      "  batch (20/40), train loss:0.7764\n",
      "  batch (30/40), train loss:0.6701\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6680\n",
      "  batch (10/40), train loss:0.7100\n",
      "  batch (20/40), train loss:0.7757\n",
      "  batch (30/40), train loss:0.6696\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6676\n",
      "  batch (10/40), train loss:0.7094\n",
      "  batch (20/40), train loss:0.7750\n",
      "  batch (30/40), train loss:0.6691\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6672\n",
      "  batch (10/40), train loss:0.7088\n",
      "  batch (20/40), train loss:0.7744\n",
      "  batch (30/40), train loss:0.6685\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6669\n",
      "  batch (10/40), train loss:0.7083\n",
      "  batch (20/40), train loss:0.7738\n",
      "  batch (30/40), train loss:0.6680\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6665\n",
      "  batch (10/40), train loss:0.7078\n",
      "  batch (20/40), train loss:0.7732\n",
      "  batch (30/40), train loss:0.6674\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6662\n",
      "  batch (10/40), train loss:0.7073\n",
      "  batch (20/40), train loss:0.7726\n",
      "  batch (30/40), train loss:0.6669\n",
      "epoch: 6, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6659\n",
      "  batch (10/40), train loss:0.7067\n",
      "  batch (20/40), train loss:0.7720\n",
      "  batch (30/40), train loss:0.6663\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6655\n",
      "  batch (10/40), train loss:0.7062\n",
      "  batch (20/40), train loss:0.7713\n",
      "  batch (30/40), train loss:0.6658\n",
      "epoch: 8, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6652\n",
      "  batch (10/40), train loss:0.7056\n",
      "  batch (20/40), train loss:0.7707\n",
      "  batch (30/40), train loss:0.6652\n",
      "epoch: 9, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6649\n",
      "  batch (10/40), train loss:0.7051\n",
      "  batch (20/40), train loss:0.7700\n",
      "  batch (30/40), train loss:0.6647\n",
      "epoch: 10, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6645\n",
      "  batch (10/40), train loss:0.7045\n",
      "  batch (20/40), train loss:0.7694\n",
      "  batch (30/40), train loss:0.6641\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6642\n",
      "  batch (10/40), train loss:0.7039\n",
      "  batch (20/40), train loss:0.7688\n",
      "  batch (30/40), train loss:0.6635\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6639\n",
      "  batch (10/40), train loss:0.7034\n",
      "  batch (20/40), train loss:0.7681\n",
      "  batch (30/40), train loss:0.6629\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6635\n",
      "  batch (10/40), train loss:0.7028\n",
      "  batch (20/40), train loss:0.7674\n",
      "  batch (30/40), train loss:0.6623\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6632\n",
      "  batch (10/40), train loss:0.7023\n",
      "  batch (20/40), train loss:0.7667\n",
      "  batch (30/40), train loss:0.6618\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6628\n",
      "  batch (10/40), train loss:0.7017\n",
      "  batch (20/40), train loss:0.7659\n",
      "  batch (30/40), train loss:0.6612\n",
      "total train time:0.09 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.6992\n",
      "  batch (10/40), train loss:0.7034\n",
      "  batch (20/40), train loss:0.7735\n",
      "  batch (30/40), train loss:0.7029\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.72\n",
      "  batch (0/40), train loss:0.5695\n",
      "  batch (10/40), train loss:0.6256\n",
      "  batch (20/40), train loss:0.6159\n",
      "  batch (30/40), train loss:0.6217\n",
      "epoch: 1, time: 0.00, valid_metric: 0.60, train_metric: 0.80\n",
      "  batch (0/40), train loss:0.5118\n",
      "  batch (10/40), train loss:0.5657\n",
      "  batch (20/40), train loss:0.5259\n",
      "  batch (30/40), train loss:0.5420\n",
      "epoch: 2, time: 0.00, valid_metric: 0.70, train_metric: 0.85\n",
      "  batch (0/40), train loss:0.4591\n",
      "  batch (10/40), train loss:0.5034\n",
      "  batch (20/40), train loss:0.4636\n",
      "  batch (30/40), train loss:0.4722\n",
      "epoch: 3, time: 0.00, valid_metric: 0.70, train_metric: 0.85\n",
      "  batch (0/40), train loss:0.4139\n",
      "  batch (10/40), train loss:0.4448\n",
      "  batch (20/40), train loss:0.4214\n",
      "  batch (30/40), train loss:0.4124\n",
      "epoch: 4, time: 0.00, valid_metric: 0.70, train_metric: 0.88\n",
      "  batch (0/40), train loss:0.3668\n",
      "  batch (10/40), train loss:0.3917\n",
      "  batch (20/40), train loss:0.3723\n",
      "  batch (30/40), train loss:0.3621\n",
      "epoch: 5, time: 0.00, valid_metric: 0.70, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.3273\n",
      "  batch (10/40), train loss:0.3439\n",
      "  batch (20/40), train loss:0.3294\n",
      "  batch (30/40), train loss:0.3173\n",
      "epoch: 6, time: 0.00, valid_metric: 0.70, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.2910\n",
      "  batch (10/40), train loss:0.3043\n",
      "  batch (20/40), train loss:0.2932\n",
      "  batch (30/40), train loss:0.2844\n",
      "epoch: 7, time: 0.00, valid_metric: 0.70, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.2576\n",
      "  batch (10/40), train loss:0.2698\n",
      "  batch (20/40), train loss:0.2645\n",
      "  batch (30/40), train loss:0.2504\n",
      "epoch: 8, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.2309\n",
      "  batch (10/40), train loss:0.2392\n",
      "  batch (20/40), train loss:0.2424\n",
      "  batch (30/40), train loss:0.2302\n",
      "epoch: 9, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.2071\n",
      "  batch (10/40), train loss:0.2133\n",
      "  batch (20/40), train loss:0.2185\n",
      "  batch (30/40), train loss:0.2049\n",
      "epoch: 10, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1869\n",
      "  batch (10/40), train loss:0.1905\n",
      "  batch (20/40), train loss:0.1945\n",
      "  batch (30/40), train loss:0.1821\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1683\n",
      "  batch (10/40), train loss:0.1702\n",
      "  batch (20/40), train loss:0.1735\n",
      "  batch (30/40), train loss:0.1645\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1513\n",
      "  batch (10/40), train loss:0.1529\n",
      "  batch (20/40), train loss:0.1567\n",
      "  batch (30/40), train loss:0.1551\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1334\n",
      "  batch (10/40), train loss:0.1378\n",
      "  batch (20/40), train loss:0.1424\n",
      "  batch (30/40), train loss:0.1458\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1192\n",
      "  batch (10/40), train loss:0.1249\n",
      "  batch (20/40), train loss:0.1295\n",
      "  batch (30/40), train loss:0.1357\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1065\n",
      "  batch (10/40), train loss:0.1143\n",
      "  batch (20/40), train loss:0.1182\n",
      "  batch (30/40), train loss:0.1299\n",
      "total train time:0.30 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.6666\n",
      "  batch (10/40), train loss:0.6990\n",
      "  batch (20/40), train loss:0.7860\n",
      "  batch (30/40), train loss:0.6797\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6657\n",
      "  batch (10/40), train loss:0.6984\n",
      "  batch (20/40), train loss:0.7855\n",
      "  batch (30/40), train loss:0.6792\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6652\n",
      "  batch (10/40), train loss:0.6979\n",
      "  batch (20/40), train loss:0.7849\n",
      "  batch (30/40), train loss:0.6787\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6647\n",
      "  batch (10/40), train loss:0.6974\n",
      "  batch (20/40), train loss:0.7843\n",
      "  batch (30/40), train loss:0.6782\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6642\n",
      "  batch (10/40), train loss:0.6969\n",
      "  batch (20/40), train loss:0.7837\n",
      "  batch (30/40), train loss:0.6777\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6637\n",
      "  batch (10/40), train loss:0.6964\n",
      "  batch (20/40), train loss:0.7831\n",
      "  batch (30/40), train loss:0.6772\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6632\n",
      "  batch (10/40), train loss:0.6960\n",
      "  batch (20/40), train loss:0.7826\n",
      "  batch (30/40), train loss:0.6767\n",
      "epoch: 6, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6627\n",
      "  batch (10/40), train loss:0.6955\n",
      "  batch (20/40), train loss:0.7820\n",
      "  batch (30/40), train loss:0.6762\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6622\n",
      "  batch (10/40), train loss:0.6950\n",
      "  batch (20/40), train loss:0.7815\n",
      "  batch (30/40), train loss:0.6757\n",
      "epoch: 8, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6617\n",
      "  batch (10/40), train loss:0.6946\n",
      "  batch (20/40), train loss:0.7809\n",
      "  batch (30/40), train loss:0.6752\n",
      "epoch: 9, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6612\n",
      "  batch (10/40), train loss:0.6941\n",
      "  batch (20/40), train loss:0.7804\n",
      "  batch (30/40), train loss:0.6747\n",
      "epoch: 10, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6607\n",
      "  batch (10/40), train loss:0.6936\n",
      "  batch (20/40), train loss:0.7798\n",
      "  batch (30/40), train loss:0.6742\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6602\n",
      "  batch (10/40), train loss:0.6932\n",
      "  batch (20/40), train loss:0.7793\n",
      "  batch (30/40), train loss:0.6738\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6597\n",
      "  batch (10/40), train loss:0.6927\n",
      "  batch (20/40), train loss:0.7788\n",
      "  batch (30/40), train loss:0.6733\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6592\n",
      "  batch (10/40), train loss:0.6922\n",
      "  batch (20/40), train loss:0.7782\n",
      "  batch (30/40), train loss:0.6728\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6587\n",
      "  batch (10/40), train loss:0.6918\n",
      "  batch (20/40), train loss:0.7777\n",
      "  batch (30/40), train loss:0.6723\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6582\n",
      "  batch (10/40), train loss:0.6913\n",
      "  batch (20/40), train loss:0.7772\n",
      "  batch (30/40), train loss:0.6718\n",
      "total train time:0.09 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.6511\n",
      "  batch (10/40), train loss:0.6850\n",
      "  batch (20/40), train loss:0.7444\n",
      "  batch (30/40), train loss:0.6236\n",
      "epoch: 0, time: 0.00, valid_metric: 0.70, train_metric: 0.68\n",
      "  batch (0/40), train loss:0.5311\n",
      "  batch (10/40), train loss:0.5712\n",
      "  batch (20/40), train loss:0.6587\n",
      "  batch (30/40), train loss:0.5102\n",
      "epoch: 1, time: 0.00, valid_metric: 0.70, train_metric: 0.82\n",
      "  batch (0/40), train loss:0.4378\n",
      "  batch (10/40), train loss:0.5031\n",
      "  batch (20/40), train loss:0.5969\n",
      "  batch (30/40), train loss:0.4426\n",
      "epoch: 2, time: 0.00, valid_metric: 0.80, train_metric: 0.85\n",
      "  batch (0/40), train loss:0.3731\n",
      "  batch (10/40), train loss:0.4433\n",
      "  batch (20/40), train loss:0.5431\n",
      "  batch (30/40), train loss:0.3914\n",
      "epoch: 3, time: 0.00, valid_metric: 0.80, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.3208\n",
      "  batch (10/40), train loss:0.3812\n",
      "  batch (20/40), train loss:0.4978\n",
      "  batch (30/40), train loss:0.3508\n",
      "epoch: 4, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2749\n",
      "  batch (10/40), train loss:0.3340\n",
      "  batch (20/40), train loss:0.4536\n",
      "  batch (30/40), train loss:0.3130\n",
      "epoch: 5, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2372\n",
      "  batch (10/40), train loss:0.2985\n",
      "  batch (20/40), train loss:0.4145\n",
      "  batch (30/40), train loss:0.2810\n",
      "epoch: 6, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2063\n",
      "  batch (10/40), train loss:0.2665\n",
      "  batch (20/40), train loss:0.3761\n",
      "  batch (30/40), train loss:0.2521\n",
      "epoch: 7, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1804\n",
      "  batch (10/40), train loss:0.2416\n",
      "  batch (20/40), train loss:0.3399\n",
      "  batch (30/40), train loss:0.2235\n",
      "epoch: 8, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1561\n",
      "  batch (10/40), train loss:0.2201\n",
      "  batch (20/40), train loss:0.3093\n",
      "  batch (30/40), train loss:0.1961\n",
      "epoch: 9, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1373\n",
      "  batch (10/40), train loss:0.1993\n",
      "  batch (20/40), train loss:0.2847\n",
      "  batch (30/40), train loss:0.1703\n",
      "epoch: 10, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1218\n",
      "  batch (10/40), train loss:0.1835\n",
      "  batch (20/40), train loss:0.2622\n",
      "  batch (30/40), train loss:0.1484\n",
      "epoch: 11, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.1080\n",
      "  batch (10/40), train loss:0.1694\n",
      "  batch (20/40), train loss:0.2437\n",
      "  batch (30/40), train loss:0.1307\n",
      "epoch: 12, time: 0.00, valid_metric: 0.80, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.0970\n",
      "  batch (10/40), train loss:0.1577\n",
      "  batch (20/40), train loss:0.2222\n",
      "  batch (30/40), train loss:0.1163\n",
      "epoch: 13, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0870\n",
      "  batch (10/40), train loss:0.1479\n",
      "  batch (20/40), train loss:0.2042\n",
      "  batch (30/40), train loss:0.1038\n",
      "epoch: 14, time: 0.01, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0785\n",
      "  batch (10/40), train loss:0.1398\n",
      "  batch (20/40), train loss:0.1920\n",
      "  batch (30/40), train loss:0.0934\n",
      "epoch: 15, time: 0.01, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0712\n",
      "  batch (10/40), train loss:0.1338\n",
      "  batch (20/40), train loss:0.1711\n",
      "  batch (30/40), train loss:0.0845\n",
      "total train time:0.37 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.6636\n",
      "  batch (10/40), train loss:0.7011\n",
      "  batch (20/40), train loss:0.7784\n",
      "  batch (30/40), train loss:0.6667\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6629\n",
      "  batch (10/40), train loss:0.7004\n",
      "  batch (20/40), train loss:0.7777\n",
      "  batch (30/40), train loss:0.6663\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6625\n",
      "  batch (10/40), train loss:0.6997\n",
      "  batch (20/40), train loss:0.7771\n",
      "  batch (30/40), train loss:0.6658\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6621\n",
      "  batch (10/40), train loss:0.6991\n",
      "  batch (20/40), train loss:0.7765\n",
      "  batch (30/40), train loss:0.6653\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6617\n",
      "  batch (10/40), train loss:0.6985\n",
      "  batch (20/40), train loss:0.7759\n",
      "  batch (30/40), train loss:0.6649\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6613\n",
      "  batch (10/40), train loss:0.6979\n",
      "  batch (20/40), train loss:0.7753\n",
      "  batch (30/40), train loss:0.6644\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6609\n",
      "  batch (10/40), train loss:0.6973\n",
      "  batch (20/40), train loss:0.7746\n",
      "  batch (30/40), train loss:0.6639\n",
      "epoch: 6, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6606\n",
      "  batch (10/40), train loss:0.6967\n",
      "  batch (20/40), train loss:0.7740\n",
      "  batch (30/40), train loss:0.6634\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6603\n",
      "  batch (10/40), train loss:0.6961\n",
      "  batch (20/40), train loss:0.7734\n",
      "  batch (30/40), train loss:0.6629\n",
      "epoch: 8, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6600\n",
      "  batch (10/40), train loss:0.6954\n",
      "  batch (20/40), train loss:0.7729\n",
      "  batch (30/40), train loss:0.6624\n",
      "epoch: 9, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6597\n",
      "  batch (10/40), train loss:0.6948\n",
      "  batch (20/40), train loss:0.7723\n",
      "  batch (30/40), train loss:0.6620\n",
      "epoch: 10, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6593\n",
      "  batch (10/40), train loss:0.6942\n",
      "  batch (20/40), train loss:0.7718\n",
      "  batch (30/40), train loss:0.6615\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6590\n",
      "  batch (10/40), train loss:0.6936\n",
      "  batch (20/40), train loss:0.7712\n",
      "  batch (30/40), train loss:0.6610\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6587\n",
      "  batch (10/40), train loss:0.6930\n",
      "  batch (20/40), train loss:0.7707\n",
      "  batch (30/40), train loss:0.6605\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6583\n",
      "  batch (10/40), train loss:0.6924\n",
      "  batch (20/40), train loss:0.7702\n",
      "  batch (30/40), train loss:0.6600\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6579\n",
      "  batch (10/40), train loss:0.6918\n",
      "  batch (20/40), train loss:0.7697\n",
      "  batch (30/40), train loss:0.6596\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6576\n",
      "  batch (10/40), train loss:0.6911\n",
      "  batch (20/40), train loss:0.7692\n",
      "  batch (30/40), train loss:0.6591\n",
      "total train time:0.09 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.6541\n",
      "  batch (10/40), train loss:0.6882\n",
      "  batch (20/40), train loss:0.7551\n",
      "  batch (30/40), train loss:0.6512\n",
      "epoch: 0, time: 0.01, valid_metric: 0.60, train_metric: 0.85\n",
      "  batch (0/40), train loss:0.5615\n",
      "  batch (10/40), train loss:0.6239\n",
      "  batch (20/40), train loss:0.5959\n",
      "  batch (30/40), train loss:0.5464\n",
      "epoch: 1, time: 0.01, valid_metric: 0.60, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.4736\n",
      "  batch (10/40), train loss:0.5822\n",
      "  batch (20/40), train loss:0.5017\n",
      "  batch (30/40), train loss:0.4701\n",
      "epoch: 2, time: 0.01, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.4218\n",
      "  batch (10/40), train loss:0.5465\n",
      "  batch (20/40), train loss:0.4247\n",
      "  batch (30/40), train loss:0.4109\n",
      "epoch: 3, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.3767\n",
      "  batch (10/40), train loss:0.4984\n",
      "  batch (20/40), train loss:0.3621\n",
      "  batch (30/40), train loss:0.3600\n",
      "epoch: 4, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.3323\n",
      "  batch (10/40), train loss:0.4529\n",
      "  batch (20/40), train loss:0.3105\n",
      "  batch (30/40), train loss:0.3153\n",
      "epoch: 5, time: 0.00, valid_metric: 0.60, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2904\n",
      "  batch (10/40), train loss:0.4100\n",
      "  batch (20/40), train loss:0.2690\n",
      "  batch (30/40), train loss:0.2767\n",
      "epoch: 6, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2554\n",
      "  batch (10/40), train loss:0.3718\n",
      "  batch (20/40), train loss:0.2352\n",
      "  batch (30/40), train loss:0.2452\n",
      "epoch: 7, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2243\n",
      "  batch (10/40), train loss:0.3361\n",
      "  batch (20/40), train loss:0.2069\n",
      "  batch (30/40), train loss:0.2175\n",
      "epoch: 8, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1998\n",
      "  batch (10/40), train loss:0.3054\n",
      "  batch (20/40), train loss:0.1829\n",
      "  batch (30/40), train loss:0.1956\n",
      "epoch: 9, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1793\n",
      "  batch (10/40), train loss:0.2780\n",
      "  batch (20/40), train loss:0.1612\n",
      "  batch (30/40), train loss:0.1756\n",
      "epoch: 10, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1595\n",
      "  batch (10/40), train loss:0.2548\n",
      "  batch (20/40), train loss:0.1435\n",
      "  batch (30/40), train loss:0.1590\n",
      "epoch: 11, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1417\n",
      "  batch (10/40), train loss:0.2314\n",
      "  batch (20/40), train loss:0.1283\n",
      "  batch (30/40), train loss:0.1455\n",
      "epoch: 12, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1271\n",
      "  batch (10/40), train loss:0.2110\n",
      "  batch (20/40), train loss:0.1154\n",
      "  batch (30/40), train loss:0.1326\n",
      "epoch: 13, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1147\n",
      "  batch (10/40), train loss:0.1921\n",
      "  batch (20/40), train loss:0.1034\n",
      "  batch (30/40), train loss:0.1221\n",
      "epoch: 14, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1036\n",
      "  batch (10/40), train loss:0.1758\n",
      "  batch (20/40), train loss:0.0927\n",
      "  batch (30/40), train loss:0.1129\n",
      "epoch: 15, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0933\n",
      "  batch (10/40), train loss:0.1615\n",
      "  batch (20/40), train loss:0.0836\n",
      "  batch (30/40), train loss:0.1056\n",
      "epoch: 16, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0843\n",
      "  batch (10/40), train loss:0.1468\n",
      "  batch (20/40), train loss:0.0764\n",
      "  batch (30/40), train loss:0.0989\n",
      "epoch: 17, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0769\n",
      "  batch (10/40), train loss:0.1343\n",
      "  batch (20/40), train loss:0.0701\n",
      "  batch (30/40), train loss:0.0936\n",
      "epoch: 18, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0704\n",
      "  batch (10/40), train loss:0.1233\n",
      "  batch (20/40), train loss:0.0641\n",
      "  batch (30/40), train loss:0.0872\n",
      "epoch: 19, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0645\n",
      "  batch (10/40), train loss:0.1142\n",
      "  batch (20/40), train loss:0.0589\n",
      "  batch (30/40), train loss:0.0819\n",
      "epoch: 20, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0595\n",
      "  batch (10/40), train loss:0.1059\n",
      "  batch (20/40), train loss:0.0539\n",
      "  batch (30/40), train loss:0.0774\n",
      "epoch: 21, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0554\n",
      "  batch (10/40), train loss:0.0987\n",
      "  batch (20/40), train loss:0.0495\n",
      "  batch (30/40), train loss:0.0733\n",
      "epoch: 22, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0512\n",
      "  batch (10/40), train loss:0.0911\n",
      "  batch (20/40), train loss:0.0459\n",
      "  batch (30/40), train loss:0.0697\n",
      "epoch: 23, time: 0.01, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0477\n",
      "  batch (10/40), train loss:0.0844\n",
      "  batch (20/40), train loss:0.0426\n",
      "  batch (30/40), train loss:0.0660\n",
      "epoch: 24, time: 0.00, valid_metric: 0.80, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.0444\n",
      "  batch (10/40), train loss:0.0785\n",
      "  batch (20/40), train loss:0.0397\n",
      "  batch (30/40), train loss:0.0626\n",
      "total train time:0.57 for epochs: 25\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.6284\n",
      "  batch (10/40), train loss:0.6996\n",
      "  batch (20/40), train loss:0.8224\n",
      "  batch (30/40), train loss:0.6485\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6271\n",
      "  batch (10/40), train loss:0.6980\n",
      "  batch (20/40), train loss:0.8202\n",
      "  batch (30/40), train loss:0.6480\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6265\n",
      "  batch (10/40), train loss:0.6966\n",
      "  batch (20/40), train loss:0.8180\n",
      "  batch (30/40), train loss:0.6474\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6259\n",
      "  batch (10/40), train loss:0.6953\n",
      "  batch (20/40), train loss:0.8158\n",
      "  batch (30/40), train loss:0.6468\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6254\n",
      "  batch (10/40), train loss:0.6940\n",
      "  batch (20/40), train loss:0.8137\n",
      "  batch (30/40), train loss:0.6462\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6249\n",
      "  batch (10/40), train loss:0.6927\n",
      "  batch (20/40), train loss:0.8116\n",
      "  batch (30/40), train loss:0.6455\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6244\n",
      "  batch (10/40), train loss:0.6914\n",
      "  batch (20/40), train loss:0.8097\n",
      "  batch (30/40), train loss:0.6450\n",
      "epoch: 6, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6239\n",
      "  batch (10/40), train loss:0.6901\n",
      "  batch (20/40), train loss:0.8077\n",
      "  batch (30/40), train loss:0.6444\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6234\n",
      "  batch (10/40), train loss:0.6888\n",
      "  batch (20/40), train loss:0.8057\n",
      "  batch (30/40), train loss:0.6438\n",
      "epoch: 8, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6229\n",
      "  batch (10/40), train loss:0.6875\n",
      "  batch (20/40), train loss:0.8037\n",
      "  batch (30/40), train loss:0.6432\n",
      "epoch: 9, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6225\n",
      "  batch (10/40), train loss:0.6863\n",
      "  batch (20/40), train loss:0.8018\n",
      "  batch (30/40), train loss:0.6426\n",
      "epoch: 10, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6221\n",
      "  batch (10/40), train loss:0.6850\n",
      "  batch (20/40), train loss:0.8000\n",
      "  batch (30/40), train loss:0.6421\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6216\n",
      "  batch (10/40), train loss:0.6837\n",
      "  batch (20/40), train loss:0.7981\n",
      "  batch (30/40), train loss:0.6416\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6212\n",
      "  batch (10/40), train loss:0.6825\n",
      "  batch (20/40), train loss:0.7963\n",
      "  batch (30/40), train loss:0.6411\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6207\n",
      "  batch (10/40), train loss:0.6813\n",
      "  batch (20/40), train loss:0.7945\n",
      "  batch (30/40), train loss:0.6406\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6203\n",
      "  batch (10/40), train loss:0.6800\n",
      "  batch (20/40), train loss:0.7927\n",
      "  batch (30/40), train loss:0.6401\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6198\n",
      "  batch (10/40), train loss:0.6788\n",
      "  batch (20/40), train loss:0.7909\n",
      "  batch (30/40), train loss:0.6395\n",
      "total train time:0.15 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "60\n",
      "  batch (0/40), train loss:0.6733\n",
      "  batch (10/40), train loss:0.7027\n",
      "  batch (20/40), train loss:0.7523\n",
      "  batch (30/40), train loss:0.6776\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.68\n",
      "  batch (0/40), train loss:0.5989\n",
      "  batch (10/40), train loss:0.6191\n",
      "  batch (20/40), train loss:0.6160\n",
      "  batch (30/40), train loss:0.6083\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.82\n",
      "  batch (0/40), train loss:0.5605\n",
      "  batch (10/40), train loss:0.5439\n",
      "  batch (20/40), train loss:0.5133\n",
      "  batch (30/40), train loss:0.5475\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.90\n",
      "  batch (0/40), train loss:0.5112\n",
      "  batch (10/40), train loss:0.4950\n",
      "  batch (20/40), train loss:0.4378\n",
      "  batch (30/40), train loss:0.4993\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.4596\n",
      "  batch (10/40), train loss:0.4542\n",
      "  batch (20/40), train loss:0.3777\n",
      "  batch (30/40), train loss:0.4545\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.4191\n",
      "  batch (10/40), train loss:0.4160\n",
      "  batch (20/40), train loss:0.3311\n",
      "  batch (30/40), train loss:0.4104\n",
      "epoch: 5, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.3793\n",
      "  batch (10/40), train loss:0.3825\n",
      "  batch (20/40), train loss:0.2852\n",
      "  batch (30/40), train loss:0.3713\n",
      "epoch: 6, time: 0.00, valid_metric: 0.60, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.3460\n",
      "  batch (10/40), train loss:0.3456\n",
      "  batch (20/40), train loss:0.2483\n",
      "  batch (30/40), train loss:0.3380\n",
      "epoch: 7, time: 0.00, valid_metric: 0.70, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.3129\n",
      "  batch (10/40), train loss:0.3142\n",
      "  batch (20/40), train loss:0.2183\n",
      "  batch (30/40), train loss:0.3072\n",
      "epoch: 8, time: 0.00, valid_metric: 0.70, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.2822\n",
      "  batch (10/40), train loss:0.2861\n",
      "  batch (20/40), train loss:0.1924\n",
      "  batch (30/40), train loss:0.2781\n",
      "epoch: 9, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2551\n",
      "  batch (10/40), train loss:0.2537\n",
      "  batch (20/40), train loss:0.1697\n",
      "  batch (30/40), train loss:0.2543\n",
      "epoch: 10, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2332\n",
      "  batch (10/40), train loss:0.2195\n",
      "  batch (20/40), train loss:0.1499\n",
      "  batch (30/40), train loss:0.2325\n",
      "epoch: 11, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2109\n",
      "  batch (10/40), train loss:0.1917\n",
      "  batch (20/40), train loss:0.1340\n",
      "  batch (30/40), train loss:0.1992\n",
      "epoch: 12, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1899\n",
      "  batch (10/40), train loss:0.1733\n",
      "  batch (20/40), train loss:0.1223\n",
      "  batch (30/40), train loss:0.1560\n",
      "epoch: 13, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1725\n",
      "  batch (10/40), train loss:0.1514\n",
      "  batch (20/40), train loss:0.1096\n",
      "  batch (30/40), train loss:0.1345\n",
      "epoch: 14, time: 0.00, valid_metric: 0.60, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1580\n",
      "  batch (10/40), train loss:0.1334\n",
      "  batch (20/40), train loss:0.0984\n",
      "  batch (30/40), train loss:0.1148\n",
      "epoch: 15, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1437\n",
      "  batch (10/40), train loss:0.1192\n",
      "  batch (20/40), train loss:0.0889\n",
      "  batch (30/40), train loss:0.1003\n",
      "epoch: 16, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1323\n",
      "  batch (10/40), train loss:0.1052\n",
      "  batch (20/40), train loss:0.0802\n",
      "  batch (30/40), train loss:0.0880\n",
      "total train time:0.34 for epochs: 17\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.6553\n",
      "  batch (10/40), train loss:0.7178\n",
      "  batch (20/40), train loss:0.8494\n",
      "  batch (30/40), train loss:0.6590\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6541\n",
      "  batch (10/40), train loss:0.7165\n",
      "  batch (20/40), train loss:0.8469\n",
      "  batch (30/40), train loss:0.6584\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6535\n",
      "  batch (10/40), train loss:0.7154\n",
      "  batch (20/40), train loss:0.8444\n",
      "  batch (30/40), train loss:0.6578\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6530\n",
      "  batch (10/40), train loss:0.7143\n",
      "  batch (20/40), train loss:0.8420\n",
      "  batch (30/40), train loss:0.6571\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6525\n",
      "  batch (10/40), train loss:0.7134\n",
      "  batch (20/40), train loss:0.8395\n",
      "  batch (30/40), train loss:0.6564\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6521\n",
      "  batch (10/40), train loss:0.7124\n",
      "  batch (20/40), train loss:0.8372\n",
      "  batch (30/40), train loss:0.6558\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6517\n",
      "  batch (10/40), train loss:0.7114\n",
      "  batch (20/40), train loss:0.8351\n",
      "  batch (30/40), train loss:0.6551\n",
      "epoch: 6, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6513\n",
      "  batch (10/40), train loss:0.7105\n",
      "  batch (20/40), train loss:0.8329\n",
      "  batch (30/40), train loss:0.6544\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6509\n",
      "  batch (10/40), train loss:0.7096\n",
      "  batch (20/40), train loss:0.8309\n",
      "  batch (30/40), train loss:0.6538\n",
      "epoch: 8, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6505\n",
      "  batch (10/40), train loss:0.7086\n",
      "  batch (20/40), train loss:0.8288\n",
      "  batch (30/40), train loss:0.6531\n",
      "epoch: 9, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6501\n",
      "  batch (10/40), train loss:0.7077\n",
      "  batch (20/40), train loss:0.8268\n",
      "  batch (30/40), train loss:0.6525\n",
      "epoch: 10, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6497\n",
      "  batch (10/40), train loss:0.7068\n",
      "  batch (20/40), train loss:0.8247\n",
      "  batch (30/40), train loss:0.6518\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6493\n",
      "  batch (10/40), train loss:0.7059\n",
      "  batch (20/40), train loss:0.8227\n",
      "  batch (30/40), train loss:0.6512\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6489\n",
      "  batch (10/40), train loss:0.7050\n",
      "  batch (20/40), train loss:0.8206\n",
      "  batch (30/40), train loss:0.6506\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6485\n",
      "  batch (10/40), train loss:0.7041\n",
      "  batch (20/40), train loss:0.8186\n",
      "  batch (30/40), train loss:0.6499\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6480\n",
      "  batch (10/40), train loss:0.7033\n",
      "  batch (20/40), train loss:0.8166\n",
      "  batch (30/40), train loss:0.6493\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6477\n",
      "  batch (10/40), train loss:0.7024\n",
      "  batch (20/40), train loss:0.8146\n",
      "  batch (30/40), train loss:0.6487\n",
      "total train time:0.10 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.6960\n",
      "  batch (10/40), train loss:0.7025\n",
      "  batch (20/40), train loss:0.7404\n",
      "  batch (30/40), train loss:0.6688\n",
      "epoch: 0, time: 0.00, valid_metric: 0.60, train_metric: 0.68\n",
      "  batch (0/40), train loss:0.6064\n",
      "  batch (10/40), train loss:0.6565\n",
      "  batch (20/40), train loss:0.6468\n",
      "  batch (30/40), train loss:0.5996\n",
      "epoch: 1, time: 0.00, valid_metric: 0.70, train_metric: 0.78\n",
      "  batch (0/40), train loss:0.5342\n",
      "  batch (10/40), train loss:0.6097\n",
      "  batch (20/40), train loss:0.5792\n",
      "  batch (30/40), train loss:0.5442\n",
      "epoch: 2, time: 0.00, valid_metric: 0.70, train_metric: 0.88\n",
      "  batch (0/40), train loss:0.4970\n",
      "  batch (10/40), train loss:0.5734\n",
      "  batch (20/40), train loss:0.5152\n",
      "  batch (30/40), train loss:0.4981\n",
      "epoch: 3, time: 0.00, valid_metric: 0.80, train_metric: 0.90\n",
      "  batch (0/40), train loss:0.4544\n",
      "  batch (10/40), train loss:0.5355\n",
      "  batch (20/40), train loss:0.4627\n",
      "  batch (30/40), train loss:0.4620\n",
      "epoch: 4, time: 0.00, valid_metric: 0.80, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.4159\n",
      "  batch (10/40), train loss:0.4869\n",
      "  batch (20/40), train loss:0.4156\n",
      "  batch (30/40), train loss:0.4228\n",
      "epoch: 5, time: 0.00, valid_metric: 0.70, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.3797\n",
      "  batch (10/40), train loss:0.4473\n",
      "  batch (20/40), train loss:0.3770\n",
      "  batch (30/40), train loss:0.3907\n",
      "epoch: 6, time: 0.01, valid_metric: 0.70, train_metric: 0.93\n",
      "  batch (0/40), train loss:0.3458\n",
      "  batch (10/40), train loss:0.4127\n",
      "  batch (20/40), train loss:0.3427\n",
      "  batch (30/40), train loss:0.3640\n",
      "epoch: 7, time: 0.00, valid_metric: 0.70, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.3164\n",
      "  batch (10/40), train loss:0.3773\n",
      "  batch (20/40), train loss:0.3125\n",
      "  batch (30/40), train loss:0.3387\n",
      "epoch: 8, time: 0.00, valid_metric: 0.70, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.2903\n",
      "  batch (10/40), train loss:0.3456\n",
      "  batch (20/40), train loss:0.2852\n",
      "  batch (30/40), train loss:0.3176\n",
      "epoch: 9, time: 0.00, valid_metric: 0.70, train_metric: 0.95\n",
      "  batch (0/40), train loss:0.2683\n",
      "  batch (10/40), train loss:0.3203\n",
      "  batch (20/40), train loss:0.2608\n",
      "  batch (30/40), train loss:0.2941\n",
      "epoch: 10, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2471\n",
      "  batch (10/40), train loss:0.2932\n",
      "  batch (20/40), train loss:0.2388\n",
      "  batch (30/40), train loss:0.2768\n",
      "epoch: 11, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.2274\n",
      "  batch (10/40), train loss:0.2696\n",
      "  batch (20/40), train loss:0.2190\n",
      "  batch (30/40), train loss:0.2588\n",
      "epoch: 12, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2124\n",
      "  batch (10/40), train loss:0.2484\n",
      "  batch (20/40), train loss:0.2020\n",
      "  batch (30/40), train loss:0.2453\n",
      "epoch: 13, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1941\n",
      "  batch (10/40), train loss:0.2285\n",
      "  batch (20/40), train loss:0.1867\n",
      "  batch (30/40), train loss:0.2313\n",
      "epoch: 14, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1739\n",
      "  batch (10/40), train loss:0.2080\n",
      "  batch (20/40), train loss:0.1720\n",
      "  batch (30/40), train loss:0.2174\n",
      "epoch: 15, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1567\n",
      "  batch (10/40), train loss:0.1909\n",
      "  batch (20/40), train loss:0.1597\n",
      "  batch (30/40), train loss:0.2012\n",
      "total train time:0.36 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.6368\n",
      "  batch (10/40), train loss:0.7096\n",
      "  batch (20/40), train loss:0.8033\n",
      "  batch (30/40), train loss:0.6832\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6351\n",
      "  batch (10/40), train loss:0.7085\n",
      "  batch (20/40), train loss:0.8013\n",
      "  batch (30/40), train loss:0.6821\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6339\n",
      "  batch (10/40), train loss:0.7075\n",
      "  batch (20/40), train loss:0.7992\n",
      "  batch (30/40), train loss:0.6809\n",
      "epoch: 2, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6328\n",
      "  batch (10/40), train loss:0.7065\n",
      "  batch (20/40), train loss:0.7972\n",
      "  batch (30/40), train loss:0.6797\n",
      "epoch: 3, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6317\n",
      "  batch (10/40), train loss:0.7055\n",
      "  batch (20/40), train loss:0.7952\n",
      "  batch (30/40), train loss:0.6785\n",
      "epoch: 4, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6307\n",
      "  batch (10/40), train loss:0.7046\n",
      "  batch (20/40), train loss:0.7932\n",
      "  batch (30/40), train loss:0.6774\n",
      "epoch: 5, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6296\n",
      "  batch (10/40), train loss:0.7037\n",
      "  batch (20/40), train loss:0.7913\n",
      "  batch (30/40), train loss:0.6762\n",
      "epoch: 6, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6286\n",
      "  batch (10/40), train loss:0.7028\n",
      "  batch (20/40), train loss:0.7893\n",
      "  batch (30/40), train loss:0.6750\n",
      "epoch: 7, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6276\n",
      "  batch (10/40), train loss:0.7019\n",
      "  batch (20/40), train loss:0.7875\n",
      "  batch (30/40), train loss:0.6739\n",
      "epoch: 8, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6266\n",
      "  batch (10/40), train loss:0.7011\n",
      "  batch (20/40), train loss:0.7856\n",
      "  batch (30/40), train loss:0.6727\n",
      "epoch: 9, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6256\n",
      "  batch (10/40), train loss:0.7002\n",
      "  batch (20/40), train loss:0.7838\n",
      "  batch (30/40), train loss:0.6716\n",
      "epoch: 10, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6247\n",
      "  batch (10/40), train loss:0.6993\n",
      "  batch (20/40), train loss:0.7820\n",
      "  batch (30/40), train loss:0.6705\n",
      "epoch: 11, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6238\n",
      "  batch (10/40), train loss:0.6984\n",
      "  batch (20/40), train loss:0.7802\n",
      "  batch (30/40), train loss:0.6693\n",
      "epoch: 12, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6229\n",
      "  batch (10/40), train loss:0.6976\n",
      "  batch (20/40), train loss:0.7784\n",
      "  batch (30/40), train loss:0.6682\n",
      "epoch: 13, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6220\n",
      "  batch (10/40), train loss:0.6967\n",
      "  batch (20/40), train loss:0.7767\n",
      "  batch (30/40), train loss:0.6671\n",
      "epoch: 14, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6211\n",
      "  batch (10/40), train loss:0.6958\n",
      "  batch (20/40), train loss:0.7750\n",
      "  batch (30/40), train loss:0.6660\n",
      "epoch: 15, time: 0.00, valid_metric: 0.50, train_metric: 0.47\n",
      "  batch (0/40), train loss:0.6202\n",
      "  batch (10/40), train loss:0.6950\n",
      "  batch (20/40), train loss:0.7733\n",
      "  batch (30/40), train loss:0.6649\n",
      "total train time:0.08 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n",
      "  batch (0/40), train loss:0.6742\n",
      "  batch (10/40), train loss:0.6838\n",
      "  batch (20/40), train loss:0.7932\n",
      "  batch (30/40), train loss:0.6871\n",
      "epoch: 0, time: 0.00, valid_metric: 0.50, train_metric: 0.75\n",
      "  batch (0/40), train loss:0.5850\n",
      "  batch (10/40), train loss:0.5951\n",
      "  batch (20/40), train loss:0.6829\n",
      "  batch (30/40), train loss:0.6329\n",
      "epoch: 1, time: 0.00, valid_metric: 0.50, train_metric: 0.88\n",
      "  batch (0/40), train loss:0.5401\n",
      "  batch (10/40), train loss:0.5382\n",
      "  batch (20/40), train loss:0.6135\n",
      "  batch (30/40), train loss:0.5796\n",
      "epoch: 2, time: 0.00, valid_metric: 0.60, train_metric: 0.90\n",
      "  batch (0/40), train loss:0.4940\n",
      "  batch (10/40), train loss:0.4877\n",
      "  batch (20/40), train loss:0.5556\n",
      "  batch (30/40), train loss:0.5337\n",
      "epoch: 3, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.4549\n",
      "  batch (10/40), train loss:0.4413\n",
      "  batch (20/40), train loss:0.4963\n",
      "  batch (30/40), train loss:0.4933\n",
      "epoch: 4, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.4154\n",
      "  batch (10/40), train loss:0.4003\n",
      "  batch (20/40), train loss:0.4473\n",
      "  batch (30/40), train loss:0.4469\n",
      "epoch: 5, time: 0.00, valid_metric: 0.70, train_metric: 0.97\n",
      "  batch (0/40), train loss:0.3775\n",
      "  batch (10/40), train loss:0.3624\n",
      "  batch (20/40), train loss:0.4029\n",
      "  batch (30/40), train loss:0.4044\n",
      "epoch: 6, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.3418\n",
      "  batch (10/40), train loss:0.3254\n",
      "  batch (20/40), train loss:0.3633\n",
      "  batch (30/40), train loss:0.3655\n",
      "epoch: 7, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.3102\n",
      "  batch (10/40), train loss:0.2929\n",
      "  batch (20/40), train loss:0.3284\n",
      "  batch (30/40), train loss:0.3301\n",
      "epoch: 8, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2813\n",
      "  batch (10/40), train loss:0.2634\n",
      "  batch (20/40), train loss:0.2966\n",
      "  batch (30/40), train loss:0.2976\n",
      "epoch: 9, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2557\n",
      "  batch (10/40), train loss:0.2362\n",
      "  batch (20/40), train loss:0.2674\n",
      "  batch (30/40), train loss:0.2721\n",
      "epoch: 10, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2335\n",
      "  batch (10/40), train loss:0.2112\n",
      "  batch (20/40), train loss:0.2422\n",
      "  batch (30/40), train loss:0.2436\n",
      "epoch: 11, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.2152\n",
      "  batch (10/40), train loss:0.1898\n",
      "  batch (20/40), train loss:0.2204\n",
      "  batch (30/40), train loss:0.2215\n",
      "epoch: 12, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1972\n",
      "  batch (10/40), train loss:0.1712\n",
      "  batch (20/40), train loss:0.2011\n",
      "  batch (30/40), train loss:0.2003\n",
      "epoch: 13, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1810\n",
      "  batch (10/40), train loss:0.1565\n",
      "  batch (20/40), train loss:0.1826\n",
      "  batch (30/40), train loss:0.1829\n",
      "epoch: 14, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1673\n",
      "  batch (10/40), train loss:0.1404\n",
      "  batch (20/40), train loss:0.1677\n",
      "  batch (30/40), train loss:0.1660\n",
      "epoch: 15, time: 0.00, valid_metric: 0.70, train_metric: 1.00\n",
      "  batch (0/40), train loss:0.1553\n",
      "  batch (10/40), train loss:0.1275\n",
      "  batch (20/40), train loss:0.1554\n",
      "  batch (30/40), train loss:0.1506\n",
      "total train time:0.29 for epochs: 16\n",
      "Found input variables with inconsistent numbers of samples: [1000, 2000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c23ee94669ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mgene_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_degree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c23ee94669ac>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mgene_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_degree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for row in todo:\n",
    "    if len(results) % 10 == 0:\n",
    "        print(len(results))\n",
    "    gene = row[\"gene\"]\n",
    "    graph_name = row[\"graph\"]\n",
    "    model_name = row[\"model\"]\n",
    "    seed = row[\"seed\"]\n",
    "    is_first_degree = row[\"is_first_degree\"]\n",
    "    model = models[model_name]\n",
    "\n",
    "    experiment = {\n",
    "        \"gene\": gene,\n",
    "        \"model\": model_name,\n",
    "        \"graph\": graph_name,\n",
    "        \"is_first_degree\": is_first_degree,\n",
    "        \"seed\": seed,\n",
    "        \"train_size\": train_size,\n",
    "    }\n",
    "    dataset.labels = dataset.df[gene].where(dataset.df[gene] > 0).notnull().astype(\"int\")\n",
    "    dataset.labels = dataset.labels.values if type(dataset.labels) == pd.Series else dataset.labels\n",
    "\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = sklearn.model_selection.\\\n",
    "            train_test_split(dataset.df, dataset.labels, stratify=dataset.labels, \n",
    "                             train_size=train_size, test_size=test_size)\n",
    "    except ValueError:\n",
    "        results = record_result(results, experiment, filename)\n",
    "        continue\n",
    "    if is_first_degree:\n",
    "        gene_graph = graphs[graph_name]\n",
    "        neighbors = list(gene_graph.first_degree(gene)[0])\n",
    "        neighbors = [n for n in neighbors if n in X_train.columns.values]\n",
    "        X_train = X_train.loc[:, neighbors].copy()\n",
    "        X_test = X_test.loc[:, neighbors].copy()\n",
    "    else:\n",
    "        X_train = X_train.copy()\n",
    "        X_test = X_test.copy()\n",
    "    X_train[gene] = 1\n",
    "    X_test[gene] = 1\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "        if cuda:\n",
    "            X_test = X_test.cuda()\n",
    "        y_hat = model.predict(X_test)\n",
    "        auc = sklearn.metrics.roc_auc_score(y_test, np.asarray(y_hat).flatten())\n",
    "        model.best_model = None # cleanup\n",
    "        experiment[\"auc\"] = auc\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    results = record_result(results, experiment, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the performance of each graph at predicting their neighbors\n",
    "df = results\n",
    "\n",
    "first_degree = df[df['is_first_degree'] == True][\n",
    "    df['graph'] == 'genemania'].groupby(['gene', 'model', 'train_size'])['auc'].agg(['mean', 'std'])\n",
    "full = df[df['is_first_degree'] == False][\n",
    "    df['graph'] == 'genemania'].groupby(['gene','model', 'train_size'])['auc'].agg(['mean', 'std'])\n",
    "genemania_df = first_degree.sub(full).sort_values('mean', ascending=False)\n",
    "\n",
    "first_degree = df[df['is_first_degree'] == True][\n",
    "    df['graph'] == 'regnet'].groupby(['gene', 'model', 'train_size'])['auc'].agg(['mean', 'std'])\n",
    "full = df[df['is_first_degree'] == False][\n",
    "    df['graph'] == 'regnet'].groupby(['gene','model', 'train_size'])['auc'].agg(['mean', 'std'])\n",
    "regnet_df = first_degree.sub(full).sort_values('mean', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/code/academic/gene-graph-conv/venv/lib/python3.5/site-packages/numpy/lib/histograms.py:754: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/home/martin/code/academic/gene-graph-conv/venv/lib/python3.5/site-packages/numpy/lib/histograms.py:755: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "l1 = genemania_df['mean']\n",
    "l2 = regnet_df['mean']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "n1, bins1, patches1 = ax.hist(l1, range=(-.4, .25), bins=100, label=\"Regnet\", \n",
    "                              density=0, alpha=0.55, histtype='step')\n",
    "n1, bins1, patches1 = ax.hist(l2, range=(-.4, .25), bins=100, label=\"GeneMania\", \n",
    "                              density=0, alpha=0.55, histtype='step')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "n1, bins1, patches1 = ax.hist(l1, range=(-.4, .25), bins=100, label=\"Regnet\", \n",
    "                              density=0, alpha=0.55, histtype='step')\n",
    "n1, bins1, patches1 = ax.hist(l2, range=(-.4, .25), bins=100, label=\"GeneMania\", \n",
    "                              density=0, alpha=0.55, histtype='step')\n",
    "\n",
    "plt.title(\"First Degree Neighbors vs Full Gene Set\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"% AUC Improvement\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
