{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on those articles/blog:\n",
    "# pytoch implementation of cgn: https://arxiv.org/pdf/1609.02907.pdf\n",
    "# http://tkipf.github.io/graph-convolutional-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a lambda graph with adjancy matrix and stuff.\n",
    "nb_nodes = 10\n",
    "nb_edges = 20\n",
    "\n",
    "def random_adj(nb_nodes, nb_edges):\n",
    "    # nodes\n",
    "    nodes = np.arange(nb_nodes)\n",
    "\n",
    "    # roughly nb_edges edges\n",
    "    edges = np.array([(i, ((((i + np.random.randint(nb_nodes - 1))  % nb_nodes) + 1 ) % nb_nodes ))\n",
    "                      for i in [np.random.randint(nb_nodes) for i in range(nb_edges)]])\n",
    "\n",
    "    # Adding self loop.\n",
    "    edges = np.concatenate((edges, np.array([(i, i) for i in nodes])))\n",
    "\n",
    "\n",
    "    # adjacent matrix\n",
    "    A = np.zeros((nb_nodes, nb_nodes))\n",
    "    A[edges[:, 0], edges[:, 1]] = 1.\n",
    "    A[edges[:, 1], edges[:, 0]] = 1.\n",
    "\n",
    "    # Degree matrix\n",
    "    D = A.sum(axis=1)\n",
    "    \n",
    "    return A, D\n",
    "\n",
    "A, D = random_adj(nb_nodes, nb_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjency matrix: \n",
      "[[ 1.  0.  0.  1.  1.  0.  0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.  1.  0.  1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.  1.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  1.  1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  0.  1.  1.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  0.  1.  0.  0.  1.  0.  0.  1.]] \n",
      " nb edges: 40.0 \n",
      " Degree: [ 4.  2.  2.  5.  4.  4.  7.  5.  3.  4.] \n"
     ]
    }
   ],
   "source": [
    "print \"Adjency matrix: \\n{} \\n nb edges: {} \\n Degree: {} \".format(A, A.sum(), D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.25  0.    0.    0.22  0.25  0.    0.    0.    0.    0.25]\n",
      " [ 0.    0.5   0.    0.    0.    0.35  0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.5   0.    0.    0.    0.27  0.    0.    0.  ]\n",
      " [ 0.22  0.    0.    0.2   0.22  0.    0.17  0.    0.    0.22]\n",
      " [ 0.25  0.    0.    0.22  0.25  0.    0.    0.22  0.    0.  ]\n",
      " [ 0.    0.35  0.    0.    0.    0.25  0.19  0.22  0.    0.  ]\n",
      " [ 0.    0.    0.27  0.17  0.    0.19  0.14  0.17  0.22  0.19]\n",
      " [ 0.    0.    0.    0.    0.22  0.22  0.17  0.2   0.26  0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.22  0.26  0.33  0.  ]\n",
      " [ 0.25  0.    0.    0.22  0.    0.    0.19  0.    0.    0.25]]\n"
     ]
    }
   ],
   "source": [
    "# Get the Normalized matrix :D^(-1/2)AD^(-1/2)\n",
    "np.set_printoptions(precision=2)\n",
    "D_inv = np.diag(1./np.sqrt(D))\n",
    "norm_transform = D_inv.dot(A).dot(D_inv)\n",
    "print norm_transform\n",
    "# So it's not only an average, it's weighted by something (need to investigate why).\n",
    "# From what I can tell it's kind of a random walk throught the graph. \n",
    "# (i.e. the weights on edges connecting \"popular\" nodes are smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a module for the CGN:\n",
    "class CGN(nn.Module):\n",
    "\n",
    "    def __init__(self, nb_nodes, input_dim, channels, adj, out_dim=None, \n",
    "                ):\n",
    "        super(CGN, self).__init__()\n",
    "\n",
    "        self.my_layers = []\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        self.adj = adj # save our adjacence matrix\n",
    "        self.edges = torch.LongTensor(np.array(np.where(adj))) # The list of edges\n",
    "        self.D_norm = self.compute_D_norm(adj) # The normalization transformation\n",
    "        flat_D_norm = self.D_norm.flatten()[np.where(self.D_norm.flatten())] # get the value\n",
    "        flat_D_norm = torch.FloatTensor(flat_D_norm)\n",
    "        \n",
    "        # Constructing a sparse matrix\n",
    "        self.sparse_D_norm = torch.sparse.FloatTensor(self.edges, flat_D_norm, torch.Size([nb_nodes,nb_nodes])).to_dense()\n",
    "        self.sparse_D_norm = Variable(self.sparse_D_norm).cuda()\n",
    "        \n",
    "        dims = [input_dim] + channels\n",
    "        \n",
    "        layers = []\n",
    "        for c_in, c_out in zip(dims[:-1], dims[1:]):\n",
    "            layer = nn.Conv1d(c_in, c_out, 1, bias=False)\n",
    "            layers.append(layer)\n",
    "        self.my_layers = nn.ModuleList(layers)\n",
    "        \n",
    "        # If we have only one target per graph, we have a linear layer.\n",
    "        if out_dim is not None:\n",
    "            self.last_layer = nn.Linear(nb_nodes * channels[-1], out_dim)\n",
    "        \n",
    "    def compute_D_norm(self, adj):\n",
    "        \n",
    "        D = adj.sum(0)\n",
    "        D_inv = np.diag(1./np.sqrt(D))\n",
    "        norm_transform = D_inv.dot(A).dot(D_inv)\n",
    "        return norm_transform # The normalizing matrix.\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        nb_examples, nb_nodes, nb_channels = x.size() \n",
    "\n",
    "        def batch_mul(x, D):\n",
    "            nb_examples, nb_channels, nb_nodes = x.size()\n",
    "            x = x.view(-1, nb_nodes)\n",
    "            x = x.mm(D)\n",
    "            x = x.view(nb_examples, nb_channels, nb_nodes)\n",
    "            \n",
    "            return x\n",
    "\n",
    "        x = x.permute(0, 2, 1).contiguous()# from ex, node, ch, -> ex, ch, node \n",
    "        \n",
    "        # Do graph convolution for all \n",
    "        for layer in self.my_layers:\n",
    "            x=x.cuda()\n",
    "            \n",
    "            x = batch_mul(x, self.sparse_D_norm)\n",
    "            x = F.tanh(layer(x)) # or relu, sigmoid...\n",
    "            \n",
    "        if self.out_dim is not None:\n",
    "            x = self.last_layer(x.view(nb_examples, -1))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate some random data:\n",
    "nb_examples = 1000 # examples\n",
    "nb_out = 1 # the umber of output (for classification)\n",
    "nb_nodes = 5000\n",
    "nb_edges = 5000\n",
    "A, D =  random_adj(nb_nodes, nb_edges)\n",
    "\n",
    "# Generate random stuff.\n",
    "inputs = Variable(torch.randn((nb_examples, nb_nodes, 1)), requires_grad=False)\n",
    "#targets = Variable(torch.randn((nb_examples, nb_out)), requires_grad=False)\n",
    "targets = Variable(torch.sum(inputs.data, dim=1), requires_grad=False).squeeze() # try to predict the sum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model:\n",
      "CGN (\n",
      "  (my_layers): ModuleList (\n",
      "    (0): Conv1d(1, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (1): Conv1d(16, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (2): Conv1d(16, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "  )\n",
      "  (last_layer): Linear (80000 -> 1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create our model.\n",
    "cgn = CGN(nb_nodes, 1, [16] * 3, A, nb_out)\n",
    "\n",
    "print \"Our model:\"\n",
    "print cgn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done putting everything on cuda.\n"
     ]
    }
   ],
   "source": [
    "# put everything on gpu\n",
    "cgn.cuda()\n",
    "inputs.cuda()\n",
    "targets.cuda()\n",
    "print \"Done putting everything on cuda.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5447.0390625)\n",
      "(50, 38.55936050415039)\n",
      "(100, 0.23164597153663635)\n",
      "(150, 0.0013994588516652584)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-39a450ed13f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mcgn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/dutilfra/.local/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device_id, async)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/dutilfra/.local/lib/python2.7/site-packages/torch/autograd/_functions/tensor.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/u/dutilfra/.local/lib/python2.7/site-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the cgn\n",
    "learning_rate = 1e-4\n",
    "criterion = torch.nn.MSELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(cgn.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "epoch = 500\n",
    "for t in range(epoch):\n",
    "    \n",
    "    targets.cuda()\n",
    "    cgn.cuda()\n",
    "    inputs.cuda()\n",
    "    \n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = cgn(inputs[:500]).cuda()\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, targets[:500].cuda())\n",
    "    \n",
    "    if t % (epoch/10) == 0:\n",
    "        print(t, loss.data[0])\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-55.4393\n",
      " 58.3262\n",
      " -2.5749\n",
      " 13.2410\n",
      "-66.9487\n",
      " 29.8692\n",
      " 53.4250\n",
      " 25.9610\n",
      " -3.2124\n",
      " 56.9583\n",
      "[torch.cuda.FloatTensor of size 10x1 (GPU 0)]\n",
      " Variable containing:\n",
      "-141.5787\n",
      " -19.4537\n",
      "  19.9199\n",
      "  19.1533\n",
      "   0.9837\n",
      "  75.3365\n",
      "  71.9767\n",
      "  11.3443\n",
      "  32.2488\n",
      "  97.9933\n",
      "[torch.FloatTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the results, and compare them\n",
    "outputs = cgn(inputs)\n",
    "print outputs[-10:], targets[-10:]\n",
    "# Good enough for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
