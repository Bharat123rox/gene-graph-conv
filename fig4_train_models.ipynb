{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file generates the data for Figure #4 from the paper https://arxiv.org/pdf/1806.06975.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martinweiss/.pyenv/versions/2.7.13/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import argparse\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import datetime\n",
    "import matplotlib, matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import models, models.models\n",
    "from models.ml_methods import MLMethods\n",
    "import data, data.gene_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting one-hot labels to integers\n"
     ]
    }
   ],
   "source": [
    "# Set the sample path depending on the location of your code and dataset.\n",
    "# If it is unset, the TCGA dataset will be downloaded from Academic Torrents.\n",
    "samples_path = \"/data/lisa/data/genomics/TCGA/TCGA_tissue_ppi.hdf5\"\n",
    "\n",
    "\n",
    "if samples_path:\n",
    "    data_dir = '/'.join(samples_path.split('/')[:-1])\n",
    "    data_file = samples_path.split('/')[-1]\n",
    "    dataset = data.gene_datasets.TCGATissue(data_dir=data_dir, data_file=data_file)\n",
    "else:\n",
    "    dataset = data.gene_datasets.TCGATissue()\n",
    "\n",
    "dataset.df = dataset.df - dataset.df.mean() # Make sure the dataset is normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On which graphs will we run this experiment? Parameterize this. \n",
    "# you will need to add your graph to AcademicTorrents and put the hash into the get_at_hash function in data/graph.py\n",
    "# or simply pass the path directly into graph.load_graph() below.\n",
    "graph_names = [\"regnet\", \"genemania\"]\n",
    "graph_paths = {\"regnet\": \"/data/lisa/data/genomics/graph/kegg.hdf5\", \"genemania\": \"/data/lisa/data/genomics/graph/pancan-tissue-graph.hdf5\"}\n",
    "\n",
    "graphs = {}\n",
    "graph = data.graph.Graph()\n",
    "for graph_name in graph_names:\n",
    "    graph_hash_or_path = data.graph.get_at_hash(graph_name)\n",
    "    # graph_hash_or_path = graph_paths[graph_name]\n",
    "    graph.load_graph(graph_hash_or_path)\n",
    "    nx_graph = nx.from_numpy_matrix(graph.adj)\n",
    "    mapping = dict(zip(range(0, len(dataset.df.columns)), dataset.df.columns))\n",
    "    nx_graph = nx.relabel_nodes(nx_graph, mapping)\n",
    "    graphs[graph_name] = nx_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Checkpointed Results\n",
      "Only 16227 more genes to do...\n"
     ]
    }
   ],
   "source": [
    "# Setup the results dictionary\n",
    "results_file_name = \"experiments/results/fig-4/data.pkl\"\n",
    "try:\n",
    "    results = pickle.load(open(results_file_name, \"r\"))\n",
    "    print \"Loaded Checkpointed Results\"\n",
    "    print (\"Only \" + str(dataset.df.shape[1] - len(results['df']['gene_name'].unique())) + \" more genes to do...\")\n",
    "except Exception as e:\n",
    "    results = {\"df\": pd.DataFrame(columns=['auc', 'gene_name', 'model', 'graph', 'is_first_degree', 'seed', 'train_size'])}\n",
    "    print \"Created a New Results Dictionary\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Helper functions\n",
    "\n",
    "def get_first_degree(gene, nx_graph):\n",
    "    neighbors = set([gene])\n",
    "    try:\n",
    "        neighbors = neighbors.union(set(nx_graph.neighbors(gene)))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    neighborhood = list(np.asarray(nx.to_numpy_matrix(nx.Graph(nx_graph.subgraph(neighbors)))))\n",
    "    return neighbors, neighborhood\n",
    "\n",
    "def check_if_done(df, gene, model_name, graph_name, seed, train_size, is_first_degree):\n",
    "    already_done = results[\"df\"][(results[\"df\"].gene_name == gene) &\n",
    "                                 (results[\"df\"].model == method.model_name) &\n",
    "                                 (results[\"df\"].graph == graph_name) &\n",
    "                                 (results[\"df\"].is_first_degree == is_first_degree) &\n",
    "                                 (results[\"df\"].seed == seed) &\n",
    "                                 (results[\"df\"].train_size == train_size)].shape[0] > 0\n",
    "    return already_done\n",
    "\n",
    "\n",
    "def record_result(results, gene, model_name, graph_name, seed, train_size, auc, results_file_name, is_first_degree=None):\n",
    "    experiment = {\n",
    "        \"gene_name\": gene,\n",
    "        \"model\": model_name,\n",
    "        \"graph\": graph_name,\n",
    "        \"is_first_degree\": is_first_degree,\n",
    "        \"seed\": seed,\n",
    "        \"train_size\": train_size,\n",
    "        \"auc\": auc\n",
    "    }\n",
    "\n",
    "    results[\"df\"] = results[\"df\"].append(experiment, ignore_index=True)\n",
    "    results_dir = \"/\".join(results_file_name.split('/')[0:-1])\n",
    "\n",
    "    if not os.path.isdir(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    pickle.dump(results, open(results_file_name, \"wb\"))\n",
    "\n",
    "def record_failure(results, gene, model_name, graph_name, train_size, results_file_name):\n",
    "    for temp_method in methods:\n",
    "        for temp_seed in range(trials):\n",
    "            record_result(results, gene, temp_method.model_name, graph_name, True, temp_seed, train_size, \"N/A\", results_file_name)\n",
    "            record_result(results, gene, temp_method.model_name, graph_name, False, temp_seed, train_size, \"N/A\", results_file_name)\n",
    "\n",
    "def fit_and_predict(method, X_train, X_test, y_train, y_test):\n",
    "    x_test = Variable(torch.FloatTensor(np.expand_dims(X_test.values, axis=2)), requires_grad=False).float()\n",
    "    method.fit(X_train, y_train)\n",
    "    y_hat = method.predict(x_test)[:,1].data.cpu().numpy()\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, np.asarray(y_hat).flatten())\n",
    "    method.best_model = None # cleanup\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 16225 more genes to do...\n",
      "Only 16225 more genes to do...\n",
      "Only 16225 more genes to do...\n",
      "Only 16225 more genes to do...\n",
      "Only 16225 more genes to do...\n",
      "Only 16225 more genes to do...\n"
     ]
    }
   ],
   "source": [
    "train_size = 50\n",
    "test_size = 1000\n",
    "trials = 3\n",
    "cuda = False\n",
    "methods = [MLMethods(model_name=\"MLP\", column_names=dataset.df.columns, dropout=False, cuda=cuda)]\n",
    "\n",
    "for gene in dataset.df.columns:\n",
    "\n",
    "    num_genes_left = dataset.df.shape[1] - len(results['df']['gene_name'].unique())\n",
    "    gene_expression_mean = dataset.df[gene].mean()\n",
    "    dataset.labels = [1 if x > gene_expression_mean else 0 for x in dataset.df[gene]]\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(dataset.df, dataset.labels, stratify=dataset.labels, train_size=train_size, test_size=test_size)\n",
    "\n",
    "    for graph_name, nx_graph in graphs.items():\n",
    "        neighbors, neighborhood = get_first_degree(gene, nx_graph)\n",
    "\n",
    "        # If we can't make a balanced dataset or we have a problem with the graph,\n",
    "        # record the failure to the results file and continue.\n",
    "        if len(set(y_train)) <= 1 or len(set(y_test)) <= 1 or type(neighborhood) != list:\n",
    "            record_failure(results, gene, method.model_name, graph_name, train_size, results_file_name)\n",
    "            continue\n",
    "\n",
    "        for method in methods: \n",
    "            for seed in range(trials):\n",
    "                already_done = check_if_done(results[\"df\"], gene, method.model_name, graph_name, seed, train_size, True)\n",
    "                if already_done:\n",
    "                    continue\n",
    "\n",
    "                if num_genes_left % 5 == 0:\n",
    "                    print (\"Only \" + str(num_genes_left) + \" more genes to do...\")\n",
    "\n",
    "                X_train_first_degree = X_train[list(neighbors)].copy()\n",
    "                X_train_first_degree[gene] = 1\n",
    "                X_test_first_degree = X_test[list(neighbors)].copy()\n",
    "                X_test_first_degree[gene] = 1\n",
    "                \n",
    "                auc = fit_and_predict(method, X_train_first_degree, X_test_first_degree, y_train, y_test)\n",
    "                record_result(results, gene, method.model_name, graph_name, seed, train_size, auc, results_file_name, is_first_degree=True)\n",
    "\n",
    "                already_done = check_if_done(results[\"df\"], gene, method.model_name, graph_name, seed, train_size, False)\n",
    "                if already_done:\n",
    "                    continue\n",
    "\n",
    "                X_train_full = X_train.copy()\n",
    "                X_train_full[gene] = 1\n",
    "                X_test_full = X_test.copy()\n",
    "                X_test_full[gene] = 1\n",
    "                \n",
    "                auc = fit_and_predict(method, X_train_full, X_test_full, y_train, y_test)\n",
    "                record_result(results, gene, method.model_name, graph_name, seed, train_size, auc, results_file_name, is_first_degree=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the performance of each graph at predicting their neighbors\n",
    "df = results['df']\n",
    "\n",
    "first_degree = df[df['is_first_degree'] == False][df['graph'] == 'genemania'].groupby(['gene_name', 'model', 'train_size'])['auc'].agg(['mean', 'std'])\n",
    "full = df[df['is_first_degree'] == True][df['graph'] == 'genemania'].groupby(['gene_name','model', 'train_size'])['auc'].agg(['mean', 'std'])\n",
    "genemania_df = first_degree.sub(full).sort_values('mean', ascending=False)\n",
    "\n",
    "first_degree = df[df['is_first_degree'] == False][df['graph'] == 'regnet'].groupby(['gene_name', 'model', 'train_size'])['auc'].agg(['mean', 'std'])\n",
    "full = df[df['is_first_degree'] == True][df['graph'] == 'regnet'].groupby(['gene_name','model', 'train_size'])['auc'].agg(['mean', 'std'])\n",
    "regnet_df = first_degree.sub(full).sort_values('mean', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l1 = genemania_df['mean']\n",
    "l2 = regnet_df['mean']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "n1, bins1, patches1 = ax.hist(l1, range=(-.4, .25), bins=100, label=\"Regnet\", density=0, alpha=0.55, histtype='step')\n",
    "n1, bins1, patches1 = ax.hist(l2, range=(-.4, .25), bins=100, label=\"GeneMania\", density=0, alpha=0.55, histtype='step')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "n1, bins1, patches1 = ax.hist(l1, range=(-.4, .25), bins=100, label=\"Regnet\", density=0, alpha=0.55, histtype='step')\n",
    "n1, bins1, patches1 = ax.hist(l2, range=(-.4, .25), bins=100, label=\"GeneMania\", density=0, alpha=0.55, histtype='step')\n",
    "\n",
    "plt.title(\"First Degree Neighbors vs Full Gene Set\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"% AUC Improvement\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
